{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31463a39",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc35ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:27:44.201661Z",
     "start_time": "2025-12-28T23:27:41.269595Z"
    }
   },
   "outputs": [],
   "source": [
    "from DKI_funcs import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d4b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T21:10:11.039327Z",
     "start_time": "2025-12-27T21:10:10.989779Z"
    }
   },
   "outputs": [],
   "source": [
    "Save = False\n",
    "\n",
    "TrainingSamples = 10_000\n",
    "InferSamples    = 500\n",
    "TestSamples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b140d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T21:10:11.478289Z",
     "start_time": "2025-12-27T21:10:11.430848Z"
    }
   },
   "outputs": [],
   "source": [
    "HCP_dir = '../../HCP_data/'\n",
    "MS_dir = '../../HCP_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ad88f",
   "metadata": {},
   "source": [
    "## Load DKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909b834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T21:10:25.661206Z",
     "start_time": "2025-12-27T21:10:12.590738Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "fdwi = HCP_dir+'Pat'+str(i)+'/diff_1k.nii.gz'\n",
    "bvalloc = HCP_dir+'Pat'+str(i)+'/bvals_1k.txt'\n",
    "bvecloc = HCP_dir+'Pat'+str(i)+'/bvecs_1k.txt'\n",
    "\n",
    "fdwi3 = HCP_dir+'Pat'+str(i)+'/diff_3k.nii.gz'\n",
    "bvalloc3 = HCP_dir+'Pat'+str(i)+'/bvals_3k.txt'\n",
    "bvecloc3 = HCP_dir+'Pat'+str(i)+'/bvecs_3k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvals = bvalsHCP, bvecs = bvecsHCP)\n",
    "\n",
    "bvalsHCP3 = np.loadtxt(bvalloc3)\n",
    "bvecsHCP3 = np.loadtxt(bvecloc3)\n",
    "gtabHCP3 = gradient_table(bvals = bvalsHCP3, bvecs = bvecsHCP3)\n",
    "\n",
    "gtabExt  = gradient_table(bvals=np.hstack((bvalsHCP,bvalsHCP3)), bvecs=np.vstack((bvecsHCP,bvecsHCP3)))\n",
    "bvals2 = np.copy(gtabExt.bvals)\n",
    "bvals2[bvals2==3000] = 4000\n",
    "bvals2[bvals2==3000] = 4000\n",
    "gtabExt2  = gradient_table(bvals2, gtabExt.bvecs)\n",
    "\n",
    "data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "data, affine = reslice(data, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "axial_middle = data.shape[2] // 2\n",
    "maskdata, mask = median_otsu(data, vol_idx=range(10, 50), median_radius=3,\n",
    "                             numpass=1, autocrop=False, dilate=2)\n",
    "\n",
    "data3, affine, img = load_nifti(fdwi3, return_img=True)\n",
    "data3, affine = reslice(data3, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "# Get the indices of True values\n",
    "true_indices = np.argwhere(mask)\n",
    "\n",
    "# Determine the minimum and maximum indices along each dimension\n",
    "min_coords = true_indices.min(axis=0)\n",
    "max_coords = true_indices.max(axis=0)\n",
    "\n",
    "maskdata  = maskdata[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "maskdata3 = data3[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "\n",
    "TestData = np.concatenate([maskdata[:, :, axial_middle, :],maskdata3[:, :, axial_middle, :]],axis=-1)\n",
    "FlatTD = TestData.reshape(maskdata.shape[0]*maskdata.shape[1],138)\n",
    "FlatTD = FlatTD[FlatTD[:,:69].sum(axis=-1)>0]\n",
    "FlatTD = FlatTD[~np.array(FlatTD<0).any(axis=-1)]\n",
    "\n",
    "dkimodel = dki.DiffusionKurtosisModel(gtabExt)\n",
    "tenfit = dkimodel.fit(FlatTD)\n",
    "DKIHCP = tenfit.kt\n",
    "DTIHCP = tenfit.lower_triangular()\n",
    "DKIFull = np.array(DKIHCP)\n",
    "DTIFull = np.array(DTIHCP)\n",
    "\n",
    "DTIFilt1 = DTIFull[(abs(DKIFull)<10).all(axis=1)]\n",
    "DKIFilt1 = DKIFull[(abs(DKIFull)<10).all(axis=1)]\n",
    "DTIFilt = DTIFilt1[(DKIFilt1>-3/7).all(axis=1)]\n",
    "DKIFilt = DKIFilt1[(DKIFilt1>-3/7).all(axis=1)]\n",
    "\n",
    "TrueMets = []\n",
    "FA       = []\n",
    "for (dt,kt) in tqdm(zip(DTIFilt,DKIFilt)):\n",
    "    TrueMets.append(DKIMetrics(dt,kt))\n",
    "    FA.append(FracAni(np.linalg.eigh(vals_to_mat(dt))[0],np.mean(np.linalg.eigh(vals_to_mat(dt))[0])))\n",
    "TrueMets = np.array(TrueMets)\n",
    "TrueFA = np.array(FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c91c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T21:10:25.740541Z",
     "start_time": "2025-12-27T21:10:25.662236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Full fit\n",
    "DT1_full,DT2_full = FitDT(DTIFilt,1)\n",
    "x4_full,R1_full,x2_full,R2_full = FitKT(DKIFilt,1)\n",
    "\n",
    "# LowFA Fit\n",
    "DT1_lfa,DT2_lfa = FitDT(DTIFilt[TrueMets[:,-1]<0.3,:],1)\n",
    "x4_lfa,R1_lfa,x2_lfa,R2_lfa = FitKT(DKIFilt[TrueMets[:,-1]<0.3,:],1)\n",
    "\n",
    "# HighFA Fit\n",
    "DT1_hfa,DT2_hfa = FitDT(DTIFilt[TrueMets[:,-1]>0.7,:],1)\n",
    "x4_hfa,R1_hfa,x2_hfa,R2_hfa = FitKT(DKIFilt[TrueMets[:,-1]>0.7,:],1)\n",
    "\n",
    "# UltraLowFA Fit\n",
    "DT1_ulfa,DT2_ulfa = FitDT(DTIFilt[TrueMets[:,-1]<0.1,:],1)\n",
    "x4_ulfa,R1_ulfa,x2_ulfa,R2_ulfa = FitKT(DKIFilt[TrueMets[:,-1]<0.1,:],1)\n",
    "\n",
    "# HigherAK Fit\n",
    "DT1_hak,DT2_hak = FitDT(DTIFilt[TrueMets[:,1]>0.9,:],1)\n",
    "x4_hak,R1_hak,x2_hak,R2_hak = FitKT(DKIFilt[TrueMets[:,1]>0.9,:],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec002e",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4d6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:28:35.919844Z",
     "start_time": "2025-12-28T23:28:35.858301Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(NetworkDir+\"DKI_Network.pickle\"):\n",
    "    with open(NetworkDir+\"DKI_Network.pickle\", \"rb\") as handle:\n",
    "        Network = pickle.load(handle)\n",
    "        print('loaded')\n",
    "else:\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    DT = []\n",
    "    KT = []\n",
    "    S0 = []\n",
    "    DT2,KT2 = GenDTKT([DT1_lfa,DT2_lfa],[x4_lfa,R1_lfa,x2_lfa,R2_lfa],12,int(1300*400))\n",
    "    DT3,KT3 = GenDTKT([DT1_hfa,DT2_hfa],[x4_hfa,R1_hfa,x2_hfa,R2_hfa],12,int(1300*400))\n",
    "    DT5,KT5 = GenDTKT([DT1_hak,DT2_hak],[x4_hak,R1_hak,x2_hak,R2_hak],12,int(2600*400))   \n",
    "\n",
    "    DT = np.vstack([DT2,DT3,DT5])\n",
    "    KT = np.vstack([KT2,KT3,KT5])\n",
    "\n",
    "    S0Dist = BoxUniform(low=torch.tensor([lower_S0]), high=torch.tensor([upper_S0]))\n",
    "\n",
    "    S0 = S0Dist.sample([len(DT)])\n",
    "    bval_choice = np.random.choice([0,1],len(DT),replace=True)\n",
    "    S0 = np.array(S0).reshape(len(S0),1)\n",
    "\n",
    "    indx = np.arange(len(KT))\n",
    "    Obs = np.zeros([len(KT),len(gtabExt.bvecs)])\n",
    "    kk = 0\n",
    "    while len(indx)>0:\n",
    "        for i in tqdm(indx,position=0,leave=True): \n",
    "            gtab = [gtabExt,gtabExt2][bval_choice[i]]\n",
    "            Obs[i] = CustomDKISimulator(DT[i],KT[i],gtab,S0[i],50)\n",
    "\n",
    "        indxNew = []\n",
    "        for i,O in enumerate(Obs):\n",
    "            if (O>4*np.array(S0[i])).any() or (O<0).any():\n",
    "                indxNew.append(i)\n",
    "        KT[indxNew] = KT[indxNew]/2\n",
    "        DT[indxNew] = GenDTKT([DT1_full,DT2_full],[x4_full,R1_full,x2_full,R2_full],kk,1)[0]\n",
    "\n",
    "        indx = indxNew\n",
    "        kk+=1\n",
    "    Par = np.hstack([DT,KT,S0])\n",
    "\n",
    "    GtabChoice = []\n",
    "    for i in range(int(len(DT)*0.8)):\n",
    "        R1 = np.random.choice(np.where(gtabExt.bvals==1000)[0],6,replace=False)\n",
    "        R2 = np.random.choice(np.where(gtabExt.bvals==3000)[0],15,replace=False)\n",
    "        GtabChoice.append(np.hstack([0,R1,R2]))\n",
    "    for i in range(int(len(DT)*0.2)):\n",
    "        R1 = np.random.choice(np.where(gtabExt.bvals==1000)[0],np.random.randint(6,64),replace=False)\n",
    "        R2 = np.random.choice(np.where(gtabExt.bvals==3000)[0],np.random.randint(21,64),replace=False)\n",
    "        GtabChoice.append(np.hstack([0,R1,R2]))\n",
    "    Obs_feats = np.array([DKIFeatures([gtabExt,gtabExt2][b].bvecs[R],[gtabExt,gtabExt2][b].bvals[R],O[R]) for O,R,b in zip(Obs,GtabChoice,bval_choice)])\n",
    "    Obs_feats = torch.tensor(Obs_feats).float()\n",
    "    Par = torch.tensor(Par).float()\n",
    "\n",
    "    inference = SNPE(device='mps')\n",
    "\n",
    "    # generate simulations and pass to the inference object\n",
    "    inference = inference.append_simulations(Par, Obs_feats,data_device='cpu')\n",
    "\n",
    "    # train the density estim ator and build the posterior\n",
    "    density_estimator = inference.train(training_batch_size = 1024)\n",
    "\n",
    "    low = Par.min(axis=0)[0] - 10*torch.sign(Par.min(axis=0)[0])*Par.min(axis=0)[0]\n",
    "    high = Par.max(axis=0)[0] + 10*Par.max(axis=0)[0]\n",
    "\n",
    "    prior_bounds = BoxUniform(low=low, high=high)\n",
    "    Network = DirectPosterior(density_estimator.cpu(), prior=prior_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64432b",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c2fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T21:54:35.877843Z",
     "start_time": "2025-12-28T21:54:35.813805Z"
    }
   },
   "outputs": [],
   "source": [
    "i=3\n",
    "fdwi = HCP_dir + 'Pat'+str(i)+'/diff_1k.nii.gz'\n",
    "bvalloc = HCP_dir + 'Pat'+str(i)+'/bvals_1k.txt'\n",
    "bvecloc = HCP_dir + 'Pat'+str(i)+'/bvecs_1k.txt'\n",
    "\n",
    "fdwi3 = HCP_dir + 'Pat'+str(i)+'/diff_3k.nii.gz'\n",
    "bvalloc3 = HCP_dir + 'Pat'+str(i)+'/bvals_3k.txt'\n",
    "bvecloc3 = HCP_dir + 'Pat'+str(i)+'/bvecs_3k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvals = bvalsHCP, bvecs = bvecsHCP)\n",
    "\n",
    "bvalsHCP3 = np.loadtxt(bvalloc3)\n",
    "bvecsHCP3 = np.loadtxt(bvecloc3)\n",
    "gtabHCP3 = gradient_table(bvals = bvalsHCP3, bvecs = bvecsHCP3)\n",
    "\n",
    "gtabExt  = gradient_table(bvals = np.hstack((bvalsHCP,bvalsHCP3)), bvecs = np.vstack((bvecsHCP,bvecsHCP3)))\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(5):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "selected_indices7 = [0]+selected_indices\n",
    "\n",
    "bvalsHCP7_1 = bvalsHCP[selected_indices7]\n",
    "bvecsHCP7_1 = bvecsHCP[selected_indices7]\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [0]\n",
    "\n",
    "temp_bvecs = bvecsHCP3[bvalsHCP3>0]\n",
    "temp_bvals = bvalsHCP3[bvalsHCP3>0]\n",
    "distance_matrix = squareform(pdist(temp_bvecs))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(14):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(temp_bvecs))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "bvalsHCP7_3 = temp_bvals[selected_indices]\n",
    "bvecsHCP7_3 = temp_bvecs[selected_indices]\n",
    "\n",
    "true_indx = []\n",
    "for b in bvecsHCP7_3:\n",
    "    true_indx.append(np.linalg.norm(b-bvecsHCP3,axis=1).argmin())\n",
    "true_indx = selected_indices7+[t+69 for t in true_indx]\n",
    "gtabHCP7 = gradient_table(bvals = np.hstack((bvalsHCP7_1,bvalsHCP7_3)),bvecs = np.vstack((bvecsHCP7_1,bvecsHCP7_3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb28d9e",
   "metadata": {},
   "source": [
    "## e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe9ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T22:25:00.874437Z",
     "start_time": "2025-12-27T22:25:00.815598Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "j = 1\n",
    "vL = torch.tensor([0.2*j])\n",
    "vS = torch.tensor([0.01*j])  \n",
    "\n",
    "DT,KT = GenDTKT([DT1_full,DT2_full],[x4_full,R1_full,x2_full,R2_full],2,1)\n",
    "\n",
    "tObs = CustomDKISimulator(DT.squeeze(),KT.squeeze(),gtabExt,200,20)\n",
    "tTrue = CustomDKISimulator(DT.squeeze(),KT.squeeze(),gtabExt,200,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f48aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T22:25:01.633261Z",
     "start_time": "2025-12-27T22:25:01.415257Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "posterior_samples_1 = Network.sample((InferSamples,), x=DKIFeatures(gtabExt.bvecs,gtabExt.bvals,tObs),show_progress_bars=True)\n",
    "GuessDKI = posterior_samples_1.mean(axis=0)\n",
    "GuessSig = CustomDKISimulator(GuessDKI[:6],GuessDKI[6:],gtabExt,200)\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(tTrue,lw=2,c='k',label='True signal')\n",
    "plt.plot(GuessSig,lw=2,c=SBIFit,ls='--',label='SBI Recon.')\n",
    "plt.axis('off')\n",
    "legend = plt.legend(ncols=2,loc=1,bbox_to_anchor =  (1,1.95),fontsize=26,columnspacing=0.3,handlelength=0.4,handletextpad=0.1)\n",
    "for handle in legend.get_lines():\n",
    "    handle.set_linewidth(6)  # Set desired linewidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d0924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T22:25:04.273378Z",
     "start_time": "2025-12-27T22:25:04.202792Z"
    }
   },
   "outputs": [],
   "source": [
    "dkimodel = dki.DiffusionKurtosisModel(gtabExt,fit_method='NLLS')\n",
    "tenfit = dkimodel.fit(tObs)\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(tTrue,lw=2,c='k')\n",
    "plt.plot(tenfit.predict(gtabExt,200),lw=2,c=WLSFit,ls='--',label='NLLS Recon.')\n",
    "plt.axis('off')\n",
    "legend = plt.legend(ncols=2,loc=1,bbox_to_anchor =  (0.9,1.95),fontsize=26,columnspacing=0.3,handlelength=0.4,handletextpad=0.1)\n",
    "for handle in legend.get_lines():\n",
    "    handle.set_linewidth(6)  # Set desired linewidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13089c8e",
   "metadata": {},
   "source": [
    "## f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26f981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T22:25:05.769380Z",
     "start_time": "2025-12-27T22:25:05.615448Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "DT2,KT2 = GenDTKT([DT1_lfa,DT2_lfa],[x4_lfa,R1_lfa,x2_lfa,R2_lfa],1,50)\n",
    "DT3,KT3 = GenDTKT([DT1_hfa,DT2_hfa],[x4_hfa,R1_hfa,x2_hfa,R2_hfa],1,50)\n",
    "DT5,KT5 = GenDTKT([DT1_hak,DT2_hak],[x4_hak,R1_hak,x2_hak,R2_hak],12,100)\n",
    "\n",
    "SampsDT = np.vstack([DT2,DT3,DT5])\n",
    "SampsKT = np.vstack([KT2,KT3,KT5])\n",
    "\n",
    "Samples  = []\n",
    "for Sd,Sk in zip(SampsDT,SampsKT):\n",
    "    Samples.append([CustomDKISimulator(Sd,Sk,gtabExt, S0=200,snr=scale) for scale in [20,10,5,2]])\n",
    "\n",
    "Samples = np.array(Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f675a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T22:27:05.133491Z",
     "start_time": "2025-12-27T22:25:06.391397Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "ErrorFull = []\n",
    "for k in tqdm(range(4)):\n",
    "    ErrorN2 = []\n",
    "    ENoise = []\n",
    "    for i in range(200):\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DKIFeatures(gtabExt.bvecs,gtabExt.bvals,Samples[i,k,:]),show_progress_bars=False)\n",
    "        GuessSBI = posterior_samples_1.mean(axis=0)\n",
    "        \n",
    "        ErrorN2.append(DKIErrors(GuessSBI[:6],GuessSBI[6:],SampsDT[i],SampsKT[i]))\n",
    "    ErrorFull.append(ErrorN2)\n",
    "\n",
    "Error_s = []\n",
    "dkimodel = dki.DiffusionKurtosisModel(gtabExt,fit_method='NLLS')\n",
    "\n",
    "for k in tqdm(range(4)):\n",
    "    ErrorN2 = []\n",
    "    ENoise = []\n",
    "    for i in range(200):\n",
    "        tenfit = dkimodel.fit(Samples[i,k,:])\n",
    "        \n",
    "        ErrorN2.append(DKIErrors(tenfit.lower_triangular(),tenfit.kt,SampsDT[i],SampsKT[i]))\n",
    "    Error_s.append(ErrorN2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eea730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:00:28.094608Z",
     "start_time": "2025-12-10T14:00:27.948273Z"
    }
   },
   "outputs": [],
   "source": [
    "ErrorFull = np.array(ErrorFull)\n",
    "Error_s = np.array(Error_s)\n",
    "ErrorNames = ['MK Error', 'AK Error', 'RK Error', 'MKT Error', 'KFA Error']\n",
    "fig,ax = plt.subplots(1,3,figsize=(13.5,3))\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i])\n",
    "    g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "    BoxPlots(ErrorFull[:,:,i],g_pos,colors,colors2,ax[i],widths=0.3,scatter=False)\n",
    "    g_pos = np.array([1,2,3,4])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    BoxPlots(Error_s[:,:,i],g_pos,colors,colors2,ax[i],widths=0.3,scatter=False)\n",
    "    plt.xticks([1.15, 2.15, 3.15, 4.15,],[20,10,5,2],fontsize=32)\n",
    "    plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "    plt.grid(axis='y')\n",
    "    plt.yticks(fontsize=32)\n",
    "    \n",
    "    if(i==0):\n",
    "        handles = [\n",
    "            Line2D([0], [0], color=SBIFit, lw=4, label='SBI'),Line2D([0], [0], color=WLSFit, lw=4, label='NLLS'),  # Adjust color as per the actual plot color\n",
    "        ]\n",
    "        # Add the legenda\n",
    "        plt.legend(handles=handles,loc=2, bbox_to_anchor=(-0.1,1.1),\n",
    "                   fontsize=36,columnspacing=0.3,handlelength=0.6,handletextpad=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9ed4e",
   "metadata": {},
   "source": [
    "## g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361e974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:14:10.774864Z",
     "start_time": "2025-12-10T10:14:10.075222Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "posterior_samples_1 = Network.sample((InferSamples,), x=DKIFeatures(gtabHCP7.bvecs,gtabHCP7.bvals,tObs[true_indx]),show_progress_bars=True)\n",
    "GuessDKI = posterior_samples_1.mean(axis=0)\n",
    "GuessSig = CustomDKISimulator(GuessDKI[:6],GuessDKI[6:],gtabExt,200)\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(tTrue,lw=2,c='k',label='True signal')\n",
    "plt.plot(GuessSig,lw=2,c=SBIFit,ls='--',label='SBI Recon.')\n",
    "plt.axis('off')\n",
    "plt.fill_betweenx(np.arange(0,500,50),0*np.ones(10),7*np.ones(10),color='gray',alpha=0.5)\n",
    "plt.fill_betweenx(np.arange(0,500,50),64*np.ones(10),79*np.ones(10),color='gray',alpha=0.5)\n",
    "plt.ylim(-9.996985449425491, 209.99985644997255)\n",
    "legend = plt.legend(ncols=2,loc=1,bbox_to_anchor =  (1,1.95),fontsize=26,columnspacing=0.3,handlelength=0.4,handletextpad=0.1)\n",
    "for handle in legend.get_lines():\n",
    "    handle.set_linewidth(6)  # Set desired linewidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a82f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:14:13.183124Z",
     "start_time": "2025-12-10T10:14:13.118440Z"
    }
   },
   "outputs": [],
   "source": [
    "dkimodel = dki.DiffusionKurtosisModel(gtabHCP7,fit_method='NLLS')\n",
    "tenfit = dkimodel.fit(tObs[true_indx])\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(tTrue,lw=2,c='k')\n",
    "plt.plot(tenfit.predict(gtabExt,200),lw=2,c=WLSFit,ls='--',label='NLLS Recon.')\n",
    "plt.axis('off')\n",
    "legend = plt.legend(ncols=2,loc=1,bbox_to_anchor =  (0.9,1.95),fontsize=26,columnspacing=0.3,handlelength=0.4,handletextpad=0.1)\n",
    "for handle in legend.get_lines():\n",
    "    handle.set_linewidth(6)  # Set desired linewidth\n",
    "plt.fill_betweenx(np.arange(0,500,50),0*np.ones(10),7*np.ones(10),color='gray',alpha=0.5)\n",
    "plt.fill_betweenx(np.arange(0,500,50),64*np.ones(10),79*np.ones(10),color='gray',alpha=0.5)\n",
    "plt.ylim(-9.996985449425491, 209.99985644997255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac8b28",
   "metadata": {},
   "source": [
    "## h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27681b6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:14:25.741276Z",
     "start_time": "2025-12-10T10:14:25.609480Z"
    }
   },
   "outputs": [],
   "source": [
    "Samples7  = []\n",
    "for Sd,Sk in zip(SampsDT,SampsKT):\n",
    "    Samples7.append([CustomDKISimulator(Sd,Sk,gtabHCP7, S0=200,snr=scale) for scale in [20,10,5,2]])\n",
    "\n",
    "Samples7 = np.array(Samples7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af1fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:22:28.365186Z",
     "start_time": "2025-12-10T10:16:45.854477Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "ErrorMin = []\n",
    "for k in tqdm(range(4)):\n",
    "    ErrorN2 = []\n",
    "    ENoise = []\n",
    "    for i in range(200):\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DKIFeatures(gtabHCP7.bvecs,gtabHCP7.bvals,Samples7[i,k,:]),show_progress_bars=False)\n",
    "        GuessSBI = posterior_samples_1.mean(axis=0)\n",
    "        \n",
    "        ErrorN2.append(DKIErrors(GuessSBI[:6],GuessSBI[6:],SampsDT[i],SampsKT[i]))\n",
    "    ErrorMin.append(ErrorN2)\n",
    "\n",
    "Error_s_min = []\n",
    "dkimodel = dki.DiffusionKurtosisModel(gtabHCP7,fit_method='NLLS')\n",
    "\n",
    "for k in tqdm(range(4)):\n",
    "    ErrorN2 = []\n",
    "    ENoise = []\n",
    "    for i in range(200):\n",
    "        tenfit = dkimodel.fit(Samples7[i,k,:])\n",
    "        \n",
    "        ErrorN2.append(DKIErrors(tenfit.lower_triangular(),tenfit.kt,SampsDT[i],SampsKT[i]))\n",
    "    Error_s_min.append(ErrorN2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1821438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:57:25.895073Z",
     "start_time": "2025-12-10T13:57:25.658244Z"
    }
   },
   "outputs": [],
   "source": [
    "ErrorFull = np.array(ErrorMin)\n",
    "Error_s = np.array(Error_s_min)\n",
    "ErrorNames = ['MK Error', 'AK Error', 'RK Error', 'MKT Error', 'KFA Error']\n",
    "fig,ax = plt.subplots(1,3,figsize=(13.5,3))\n",
    "for i in range(3):\n",
    "    plt.sca(ax[i])\n",
    "    g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "    BoxPlots(ErrorFull[:,:,i],g_pos,colors,colors2,ax[i],widths=0.3,scatter=False)\n",
    "    g_pos = np.array([1,2,3,4])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    BoxPlots(Error_s[:,:,i],g_pos,colors,colors2,ax[i],widths=0.3,scatter=False)\n",
    "    plt.xticks([1.15, 2.15, 3.15, 4.15,],[20,10,5,2],fontsize=32)\n",
    "    plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "    plt.grid(axis='y')\n",
    "    plt.yticks(fontsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98290e0",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81467156",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eef8cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T21:54:49.594272Z",
     "start_time": "2025-12-28T21:54:39.794818Z"
    }
   },
   "outputs": [],
   "source": [
    "i=3\n",
    "fdwi = HCP_dir+'/Pat'+str(i)+'/diff_1k.nii.gz'\n",
    "\n",
    "data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "data, affine = reslice(data, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "maskdata, mask = median_otsu(data, vol_idx=range(10, 50), median_radius=4,\n",
    "                             numpass=1, autocrop=False, dilate=2)\n",
    "_, mask2 = median_otsu(data, vol_idx=range(10, 50), median_radius=4,\n",
    "                             numpass=1, autocrop=True, dilate=2)\n",
    "\n",
    "\n",
    "data3, affine, img = load_nifti(fdwi3, return_img=True)\n",
    "data3, affine = reslice(data3, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "# Get the indices of True values\n",
    "true_indices = np.argwhere(mask)\n",
    "\n",
    "# Determine the minimum and maximum indices along each dimension\n",
    "min_coords = true_indices.min(axis=0)\n",
    "max_coords = true_indices.max(axis=0)\n",
    "\n",
    "maskdata  = maskdata[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "axial_middle = maskdata.shape[2] // 2\n",
    "maskdata3 = data3[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "\n",
    "TestData = np.concatenate([maskdata[:, :, axial_middle, :],maskdata3[:, :, axial_middle, :]],axis=-1)\n",
    "TestData4D = np.concatenate([maskdata,maskdata3],axis=-1)\n",
    "\n",
    "floor = np.clip(TestData4D.min(axis=-1),-np.inf,0)\n",
    "TestData4D_2 = np.copy(TestData4D)\n",
    "TestData4D_2[floor <0 ] = TestData4D[floor < 0] + abs(floor)[floor <0 ,None] + 1e-5\n",
    "\n",
    "cutout = np.sum(TestData4D[:,:,axial_middle,:69], axis=-1) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3403a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T21:55:41.731170Z",
     "start_time": "2025-12-28T21:54:49.595273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(TestData4D_2[:,:,axial_middle,:69], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "def optimize_chunk(pixels):\n",
    "    results = []\n",
    "    for i, j in pixels:\n",
    "        samples = Network.sample((500,), x=DKIFeatures(gtabExt.bvecs,gtabExt.bvals,TestData4D_2[i,j,axial_middle, :]),show_progress_bars=False)\n",
    "        results.append((i, j, samples.mean(axis=0)))\n",
    "    return results\n",
    "\n",
    "chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize NoiseEst with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "\n",
    "NoiseEst = np.zeros([62, 68 ,22])\n",
    "for chunk in tqdm(results,position=0,leave=True):\n",
    "    for i, j, x in chunk:\n",
    "        NoiseEst[i, j] = x\n",
    "NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "for i in range(62):\n",
    "    for j in range(68):    \n",
    "        NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "MK_SBIFull  = np.zeros([62, 68])\n",
    "AK_SBIFull  = np.zeros([62, 68])\n",
    "RK_SBIFull  = np.zeros([62, 68])\n",
    "MKT_SBIFull = np.zeros([62, 68])\n",
    "KFA_SBIFull = np.zeros([62, 68])\n",
    "for i in tqdm(range(62),position=0,leave=True):\n",
    "    for j in range(68):\n",
    "        Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "        MK_SBIFull[i,j] = Metrics[0]\n",
    "        AK_SBIFull[i,j] = Metrics[1]\n",
    "        RK_SBIFull[i,j] = Metrics[2]\n",
    "        MKT_SBIFull[i,j] = Metrics[3]\n",
    "        KFA_SBIFull[i,j] = Metrics[4]\n",
    "KFA_SBIFull[np.isnan(KFA_SBIFull)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85a601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:20:09.183089Z",
     "start_time": "2025-12-24T15:20:08.955936Z"
    }
   },
   "outputs": [],
   "source": [
    "tnorm = TwoSlopeNorm(vmin=-0,vcenter = 0.6,vmax=1.4)\n",
    "temp = np.copy(MK_SBIFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(AK_SBIFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(RK_SBIFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(fraction=0.032, pad=0.04)\n",
    "cbar.ax.set_ylim(0,1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e746ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T21:58:15.885124Z",
     "start_time": "2025-12-28T21:57:28.361657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(TestData4D_2[:,:,axial_middle,:69], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "def optimize_chunk(pixels):\n",
    "    results = []\n",
    "    for i, j in pixels:\n",
    "        samples = Network.sample((500,), x=DKIFeatures(gtabHCP7.bvecs,gtabHCP7.bvals,TestData4D_2[i,j,axial_middle, true_indx]),show_progress_bars=False)\n",
    "        results.append((i, j, samples.mean(axis=0)))\n",
    "    return results\n",
    "\n",
    "chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize NoiseEst with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "\n",
    "NoiseEst = np.zeros([62, 68 ,22])\n",
    "for chunk in tqdm(results,position=0,leave=True):\n",
    "    for i, j, x in chunk:\n",
    "        NoiseEst[i, j] = x\n",
    "NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "for i in range(62):\n",
    "    for j in range(68):    \n",
    "        NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "MK_SBI7  = np.zeros([62, 68])\n",
    "AK_SBI7  = np.zeros([62, 68])\n",
    "RK_SBI7  = np.zeros([62, 68])\n",
    "MKT_SBI7 = np.zeros([62, 68])\n",
    "KFA_SBI7 = np.zeros([62, 68])\n",
    "for i in tqdm(range(62),position=0,leave=True):\n",
    "    for j in range(68):\n",
    "        Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "        MK_SBI7[i,j] = Metrics[0]\n",
    "        AK_SBI7[i,j] = Metrics[1]\n",
    "        RK_SBI7[i,j] = Metrics[2]\n",
    "        MKT_SBI7[i,j] = Metrics[3]\n",
    "        KFA_SBI7[i,j] = Metrics[4]\n",
    "KFA_SBI7[np.isnan(KFA_SBI7)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636eee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:21:44.156087Z",
     "start_time": "2025-12-24T15:21:43.921385Z"
    }
   },
   "outputs": [],
   "source": [
    "tnorm = TwoSlopeNorm(vmin=-0,vcenter = 0.6,vmax=1.4)\n",
    "temp = np.copy(MK_SBI7)\n",
    "temp = gaussian_filter(temp, sigma=0.5)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(AK_SBI7)\n",
    "temp = gaussian_filter(temp, sigma=0.5)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(RK_SBI7)\n",
    "temp = gaussian_filter(temp, sigma=0.5)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(fraction=0.032, pad=0.04)\n",
    "cbar.ax.set_ylim(0,1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cefec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:21:49.757859Z",
     "start_time": "2025-12-24T15:21:49.424015Z"
    }
   },
   "outputs": [],
   "source": [
    "ticks = [0,1,2]\n",
    "data = np.abs((MK_SBIFull-MK_SBI7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=1, vmax=2)\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data = np.abs((AK_SBIFull-AK_SBI7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=np.nanmax(data)/2, vmax=np.nanmax(data))\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()\n",
    "\n",
    "data = np.abs((RK_SBIFull-RK_SBI7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=1,vmax=2)\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a1419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0db051b",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75382a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:21:58.034493Z",
     "start_time": "2025-12-24T15:21:53.175751Z"
    }
   },
   "outputs": [],
   "source": [
    "dkimodelNL = dki.DiffusionKurtosisModel(gtabExt,fit_method='NLLS')\n",
    "dkifitNL = dkimodelNL.fit(TestData[:,:,:])\n",
    "\n",
    "MK_NLFull  = dkifitNL.mk() #np.zeros([62, 68])\n",
    "AK_NLFull  = dkifitNL.ak()# np.zeros([62, 68])\n",
    "RK_NLFull  = dkifitNL.rk()# np.zeros([62, 68])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125ede0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:21:59.115986Z",
     "start_time": "2025-12-24T15:21:58.878207Z"
    }
   },
   "outputs": [],
   "source": [
    "tnorm = TwoSlopeNorm(vmin=-0,vcenter = 0.6,vmax=1.4)\n",
    "temp = np.copy(MK_NLFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(AK_NLFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(RK_NLFull)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(fraction=0.032, pad=0.04)\n",
    "cbar.ax.set_ylim(0,1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07781526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:22:02.970297Z",
     "start_time": "2025-12-24T15:22:02.404691Z"
    }
   },
   "outputs": [],
   "source": [
    "dkimodelNL = dki.DiffusionKurtosisModel(gtabHCP7,fit_method='NLLS')\n",
    "dkifitNL = dkimodelNL.fit(TestData[:,:,true_indx])\n",
    "MK_NL7  = dkifitNL.mk() #np.zeros([62, 68])\n",
    "AK_NL7  = dkifitNL.ak()# np.zeros([62, 68])\n",
    "RK_NL7  = dkifitNL.rk()# np.zeros([62, 68])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f34ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:22:10.379652Z",
     "start_time": "2025-12-24T15:22:10.150747Z"
    }
   },
   "outputs": [],
   "source": [
    "tnorm = TwoSlopeNorm(vmin=-0,vcenter = 0.6,vmax=1.4)\n",
    "temp = np.copy(MK_NL7)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(AK_NL7)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "temp = np.copy(RK_NL7)\n",
    "temp[~cutout] = math.nan\n",
    "plt.imshow(temp.T,norm=tnorm,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(fraction=0.032, pad=0.04)\n",
    "cbar.ax.set_ylim(0,1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69332f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:03:16.177783Z",
     "start_time": "2025-12-17T13:03:16.177779Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.abs((MK_NLFull-MK_NL7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',vmin=0,vmax=2)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=[0,1,2])\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()\n",
    "\n",
    "dat = np.abs((AK_SBIFull-AK_SBI7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=np.nanmax(dat)/2, vmax=np.nanmax(dat))\n",
    "data = np.abs((AK_NLFull-AK_NL7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=1,vmax=2)\n",
    "data = np.abs((RK_NLFull-RK_NL7)*cutout).T\n",
    "data[~cutout.T] = np.nan\n",
    "#ticks = [0, np.round(np.max(data),10)]  #Adjust the number of ticks as needed\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfbb99",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce074091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:22:19.053557Z",
     "start_time": "2025-12-24T12:22:18.976967Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "bvalloc = HCP_dir + 'Pat'+str(i)+'/bvals_1k.txt'\n",
    "bvecloc = HCP_dir + 'Pat'+str(i)+'/bvecs_1k.txt'\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvalsHCP, bvecsHCP)\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(5):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "selected_indices7 = [0]+selected_indices\n",
    "\n",
    "bvalsHCP7_1 = bvalsHCP[selected_indices7]\n",
    "bvecsHCP7_1 = bvecsHCP[selected_indices7]\n",
    "\n",
    "bvalloc = HCP_dir + 'Pat'+str(i)+'/bvals_3k.txt'\n",
    "bvecloc = HCP_dir + 'Pat'+str(i)+'/bvecs_3k.txt'\n",
    "\n",
    "bvalsHCP3 = np.loadtxt(bvalloc)\n",
    "bvecsHCP3 = np.loadtxt(bvecloc)\n",
    "gtabHCP3 = gradient_table(bvalsHCP, bvecsHCP)\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [0]\n",
    "\n",
    "temp_bvecs = bvecsHCP3[bvalsHCP3>0]\n",
    "temp_bvals = bvalsHCP3[bvalsHCP3>0]\n",
    "distance_matrix = squareform(pdist(temp_bvecs))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(14):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(temp_bvecs))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "bvalsHCP7_3 = temp_bvals[selected_indices]\n",
    "bvecsHCP7_3 = temp_bvecs[selected_indices]\n",
    "\n",
    "gtabHCP7 = gradient_table(np.hstack((bvalsHCP7_1,bvalsHCP7_3)), np.vstack((bvecsHCP7_1,bvecsHCP7_3)))\n",
    "\n",
    "true_indx = []\n",
    "for b in bvecsHCP7_3:\n",
    "    true_indx.append(np.linalg.norm(b-bvecsHCP3,axis=1).argmin())\n",
    "selected_indices7 = selected_indices7+[t+69 for t in true_indx]\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "\n",
    "temp_bvecs = bvecsHCP[bvalsHCP>0]\n",
    "temp_bvals = bvalsHCP[bvalsHCP>0]\n",
    "distance_matrix = squareform(pdist(temp_bvecs))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(18):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(temp_bvecs))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "temp = selected_indices\n",
    "\n",
    "bvalsHCP7_1 = np.insert(temp_bvals[temp],0,0)\n",
    "bvecsHCP7_1 = np.insert(temp_bvecs[temp],0,[0,0,0],axis=0)\n",
    "\n",
    "bvalloc = HCP_dir + 'Pat'+str(i)+'/bvals_3k.txt'\n",
    "bvecloc = HCP_dir + 'Pat'+str(i)+'/bvecs_3k.txt'\n",
    "\n",
    "bvalsHCP3 = np.loadtxt(bvalloc)\n",
    "bvecsHCP3 = np.loadtxt(bvecloc)\n",
    "gtabHCP3 = gradient_table(bvalsHCP, bvecsHCP)\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [0]\n",
    "\n",
    "temp_bvecs = bvecsHCP3[bvalsHCP3>0]\n",
    "temp_bvals = bvalsHCP3[bvalsHCP3>0]\n",
    "distance_matrix = squareform(pdist(temp_bvecs))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(27):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(temp_bvecs))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "bvalsHCP7_3 = temp_bvals[selected_indices]\n",
    "bvecsHCP7_3 = temp_bvecs[selected_indices]\n",
    "\n",
    "gtabHCP20 = gradient_table(np.hstack((bvalsHCP7_1,bvalsHCP7_3)), np.vstack((bvecsHCP7_1,bvecsHCP7_3)))\n",
    "\n",
    "true_indx_one = []\n",
    "for b in bvecsHCP7_1:\n",
    "    true_indx_one.append(np.linalg.norm(b-bvecsHCP,axis=1).argmin())\n",
    "true_indx = []        \n",
    "for b in bvecsHCP7_3:\n",
    "    true_indx.append(np.linalg.norm(b-bvecsHCP3,axis=1).argmin())\n",
    "selected_indices20 = true_indx_one+[t+69 for t in true_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1458e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:22:19.936846Z",
     "start_time": "2025-12-24T12:22:19.780169Z"
    }
   },
   "outputs": [],
   "source": [
    "gTabsF = []\n",
    "gTabs7 = []\n",
    "gTabs20 = []\n",
    "\n",
    "FullDat   = []\n",
    "\n",
    "for i in tqdm(range(1,33)):\n",
    "    fdwi = HCP_dir + 'Pat'+str(i)+'/diff_1k.nii.gz'\n",
    "    bvalloc = HCP_dir + 'Pat'+str(i)+'/bvals_1k.txt'\n",
    "    bvecloc = HCP_dir + 'Pat'+str(i)+'/bvecs_1k.txt'\n",
    "    \n",
    "    fdwi3 = HCP_dir + 'Pat'+str(i)+'/diff_3k.nii.gz'\n",
    "    bvalloc3 = HCP_dir + 'Pat'+str(i)+'/bvals_3k.txt'\n",
    "    bvecloc3 = HCP_dir + 'Pat'+str(i)+'/bvecs_3k.txt'\n",
    "    \n",
    "    bvalsHCP = np.loadtxt(bvalloc)\n",
    "    bvecsHCP = np.loadtxt(bvecloc)\n",
    "    gtabHCP = gradient_table(bvalsHCP, bvecsHCP)\n",
    "    \n",
    "    bvalsHCP3 = np.loadtxt(bvalloc3)\n",
    "    bvecsHCP3 = np.loadtxt(bvecloc3)\n",
    "    gtabHCP3 = gradient_table(bvalsHCP3, bvecsHCP3)\n",
    "    \n",
    "    gtabExt  = gradient_table(np.hstack((bvalsHCP,bvalsHCP3)), np.vstack((bvecsHCP,bvecsHCP3)))\n",
    "    gTabsF.append(gtabExt)\n",
    "    \n",
    "    bvalsHCP7 = gtabExt.bvals[selected_indices7]\n",
    "    bvecsHCP7 = gtabExt.bvecs[selected_indices7]\n",
    "    gtabHCP7 = gradient_table(bvalsHCP7, bvecsHCP7)\n",
    "    gTabs7.append(gtabHCP7)\n",
    "\n",
    "    bvalsHCP20 = gtabExt.bvals[selected_indices20]\n",
    "    bvecsHCP20 = gtabExt.bvecs[selected_indices20]\n",
    "    gtabHCP20 = gradient_table(bvalsHCP20, bvecsHCP20)\n",
    "    gTabs20.append(gtabHCP20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c4948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:27:22.004856Z",
     "start_time": "2025-12-24T12:22:23.638768Z"
    }
   },
   "outputs": [],
   "source": [
    "TD = []\n",
    "axial_middles = []\n",
    "masks = []\n",
    "WMs = []\n",
    "for kk in tqdm(range(32)):\n",
    "    fdwi = HCP_dir + 'Pat'+str(kk+1)+'/diff_1k.nii.gz'\n",
    "    bvalloc = HCP_dir + 'Pat'+str(kk+1)+'/bvals_1k.txt'\n",
    "    bvecloc = HCP_dir + 'Pat'+str(kk+1)+'/bvecs_1k.txt'\n",
    "    \n",
    "    fdwi3 = HCP_dir + 'Pat'+str(kk+1)+'/diff_3k.nii.gz'\n",
    "    bvalloc3 = HCP_dir + 'Pat'+str(kk+1)+'/bvals_3k.txt'\n",
    "    bvecloc3 = HCP_dir + 'Pat'+str(kk+1)+'/bvecs_3k.txt'\n",
    "    \n",
    "    bvalsHCP = np.loadtxt(bvalloc)\n",
    "    bvecsHCP = np.loadtxt(bvecloc)\n",
    "    gtabHCP = gradient_table(bvalsHCP, bvecsHCP)\n",
    "    \n",
    "    bvalsHCP3 = np.loadtxt(bvalloc3)\n",
    "    bvecsHCP3 = np.loadtxt(bvecloc3)\n",
    "    gtabHCP3 = gradient_table(bvalsHCP3, bvecsHCP3)\n",
    "    \n",
    "    gtabExt  = gradient_table(bvals = np.hstack((bvalsHCP,bvalsHCP3)),bvecs =  np.vstack((bvecsHCP,bvecsHCP3)))\n",
    "    \n",
    "    data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "    data, affine = reslice(data, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "    maskdata, mask = median_otsu(data, vol_idx=range(10, 50), median_radius=3,\n",
    "                                 numpass=1, autocrop=False, dilate=2)\n",
    "    _, mask2 = median_otsu(data, vol_idx=range(10, 50), median_radius=3,\n",
    "                                 numpass=1, autocrop=True, dilate=2)\n",
    "    \n",
    "    \n",
    "    data3, affine, img = load_nifti(fdwi3, return_img=True)\n",
    "    data3, affine = reslice(data3, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "    # Get the indices of True values\n",
    "    true_indices = np.argwhere(mask)\n",
    "    \n",
    "    # Determine the minimum and maximum indices along each dimension\n",
    "    min_coords = true_indices.min(axis=0)\n",
    "    max_coords = true_indices.max(axis=0)\n",
    "    \n",
    "    maskdata  = maskdata[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "    axial_middle = maskdata.shape[2] // 2\n",
    "    maskdata3 = data3[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "    axial_middles.append(axial_middle)\n",
    "    TestData = np.concatenate([maskdata[:, :, axial_middle, :],maskdata3[:, :, axial_middle, :]],axis=-1)\n",
    "    TestData4D = np.concatenate([maskdata,maskdata3],axis=-1)\n",
    "    floor = np.clip(TestData4D.min(axis=-1),-np.inf,0)\n",
    "    TestData4D_2 = np.copy(TestData4D)\n",
    "    TestData4D_2[floor <0 ] = TestData4D[floor < 0] + abs(floor)[floor <0 ,None] + 1e-5\n",
    "    TD.append(TestData4D_2)\n",
    "    masks.append(mask[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,axial_middle])\n",
    "    WM, affine, img = load_nifti(HCP_dir + 'WM_Masks/c2Pat'+str(kk+1)+'_FP.nii', return_img=True)\n",
    "    WMs.append(np.fliplr(WM[:,:,axial_middle]>0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420524f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:53:11.287451Z",
     "start_time": "2025-12-24T12:27:22.005733Z"
    }
   },
   "outputs": [],
   "source": [
    "MKFullArr = []\n",
    "RKFullArr = []\n",
    "AKFullArr = []\n",
    "for kk in tqdm(range(32),position = 0,leave = True):\n",
    "\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(TD[kk][:, :, axial_middles[kk], :69], axis=-1) != 0\n",
    "\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    dat = TD[kk]\n",
    "    Ax = axial_middles[kk]\n",
    "    gt = gTabsF[kk]\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs,gt.bvals,dat[i,j,Ax, :]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "\n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    MK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    AK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    RK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(NoiseEst.shape[0]):\n",
    "        for j in range(NoiseEst.shape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK_SBIFull[i,j] = Metrics[0]\n",
    "            AK_SBIFull[i,j] = Metrics[1]\n",
    "            RK_SBIFull[i,j] = Metrics[2]\n",
    "\n",
    "\n",
    "    MKFullArr.append(MK_SBIFull)\n",
    "    RKFullArr.append(RK_SBIFull)\n",
    "    AKFullArr.append(AK_SBIFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56288cd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:29:53.476854Z",
     "start_time": "2025-12-24T12:53:11.288221Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMinArr = []\n",
    "RKMinArr = []\n",
    "AKMinArr = []\n",
    "for kk in tqdm(range(32)):\n",
    "\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(TD[kk][:, :, axial_middles[kk], :69], axis=-1) != 0\n",
    "\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    dat = TD[kk]\n",
    "    Ax = axial_middles[kk]\n",
    "    gt = gTabs7[kk]\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs,gt.bvals,dat[i,j,Ax, selected_indices7]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "\n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(NoiseEst.shape[0]):\n",
    "        for j in range(NoiseEst.shape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "    MK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    AK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    RK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "\n",
    "    for i in range(NoiseEst.shape[0]):\n",
    "        for j in range(NoiseEst.shape[1]): \n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK_SBIFull[i,j] = Metrics[0]\n",
    "            AK_SBIFull[i,j] = Metrics[1]\n",
    "            RK_SBIFull[i,j] = Metrics[2]\n",
    "\n",
    "\n",
    "    MKMinArr.append(MK_SBIFull)\n",
    "    RKMinArr.append(RK_SBIFull)\n",
    "    AKMinArr.append(AK_SBIFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f56d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:55:22.585559Z",
     "start_time": "2025-12-24T13:29:53.478127Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMidArr = []\n",
    "RKMidArr = []\n",
    "AKMidArr = []\n",
    "for kk in tqdm(range(32)):\n",
    "\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(TD[kk][:, :, axial_middles[kk], :69], axis=-1) != 0\n",
    "\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    dat = TD[kk]\n",
    "    Ax = axial_middles[kk]\n",
    "    gt = gTabs20[kk]\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs,gt.bvals,dat[i,j,Ax, selected_indices20]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    print('start')\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "    print('end')\n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(NoiseEst.shape[0]):\n",
    "        for j in range(NoiseEst.shape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "    MK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    AK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "    RK_SBIFull  = np.zeros([NoiseEst.shape[0], NoiseEst.shape[1]])\n",
    "\n",
    "    for i in range(NoiseEst.shape[0]):\n",
    "        for j in range(NoiseEst.shape[1]): \n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK_SBIFull[i,j] = Metrics[0]\n",
    "            AK_SBIFull[i,j] = Metrics[1]\n",
    "            RK_SBIFull[i,j] = Metrics[2]\n",
    "\n",
    "\n",
    "    MKMidArr.append(MK_SBIFull)\n",
    "    RKMidArr.append(RK_SBIFull)\n",
    "    AKMidArr.append(AK_SBIFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a52af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:57:53.717093Z",
     "start_time": "2025-12-24T13:55:22.586267Z"
    }
   },
   "outputs": [],
   "source": [
    "MKFullNLArr = []\n",
    "RKFullNLArr = []\n",
    "AKFullNLArr = []\n",
    "MKTFullNLArr = []\n",
    "KFAFullNLArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabsF[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(TD[kk][:,:,axial_middles[kk]])\n",
    "    MK_NL7_t  = dkifitNL.mk()\n",
    "    AK_NL7_t  = dkifitNL.ak()\n",
    "    RK_NL7_t = dkifitNL.rk()\n",
    "    MKFullNLArr.append(MK_NL7_t)\n",
    "    RKFullNLArr.append(RK_NL7_t)\n",
    "    AKFullNLArr.append(AK_NL7_t)\n",
    "\n",
    "MKMidNLArr = []\n",
    "RKMidNLArr = []\n",
    "AKMidNLArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabs20[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(TD[kk][:,:,axial_middles[kk],selected_indices20])\n",
    "    MK_NL7_t  = dkifitNL.mk()\n",
    "    AK_NL7_t  = dkifitNL.ak()\n",
    "    RK_NL7_t = dkifitNL.rk()\n",
    "    MKMidNLArr.append(MK_NL7_t)\n",
    "    RKMidNLArr.append(RK_NL7_t)\n",
    "    AKMidNLArr.append(AK_NL7_t)\n",
    "\n",
    "MKMinNLArr = []\n",
    "RKMinNLArr = []\n",
    "AKMinNLArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabs7[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(TD[kk][:,:,axial_middles[kk],selected_indices7])\n",
    "    MK_NL7_t  = dkifitNL.mk()\n",
    "    AK_NL7_t  = dkifitNL.ak()\n",
    "    RK_NL7_t = dkifitNL.rk()\n",
    "    MKMinNLArr.append(MK_NL7_t)\n",
    "    RKMinNLArr.append(RK_NL7_t)\n",
    "    AKMinNLArr.append(AK_NL7_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc21b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:58:34.996513Z",
     "start_time": "2025-12-24T13:57:53.717744Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_MK = []\n",
    "AccM20_MK = []\n",
    "AccMFulls_MK = []\n",
    "\n",
    "AccM7NL_MK = []\n",
    "AccM20NL_MK = []\n",
    "\n",
    "SSIM7_MK = []\n",
    "SSIM20_MK = []\n",
    "SSIMFulls_MK = []\n",
    "\n",
    "SSIM7NL_MK = []\n",
    "SSIM20NL_MK = []\n",
    "for i in range(32):\n",
    "    M7 =MKMinArr[i]\n",
    "    MF =MKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    AccM7_MK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =MKMidArr[i]\n",
    "    MF =MKFullArr[i]\n",
    "    AccM20_MK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =MKFullArr[i]\n",
    "    MF =MKFullNLArr[i]\n",
    "    AccMFulls_MK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 =MKMinNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =MKFullNLArr[i]\n",
    "    AccM7NL_MK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =MKMidNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =MKFullNLArr[i]\n",
    "    AccM20NL_MK.append(np.nanmean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    NS1 =MKMinArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =MKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7_MK.append(result)\n",
    "\n",
    "    NS1 =MKMidArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =MKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20_MK.append(result)\n",
    "    \n",
    "    NS1 =MKFullArr[i]\n",
    "    NS2 =MKFullNLArr[i]\n",
    "    Ma = masks[i] * NS2 == 0\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIMFulls_MK.append(result)\n",
    "\n",
    "    NS1 =MKMinNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =MKFullNLArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7NL_MK.append(result)\n",
    "\n",
    "    NS1 =MKMidNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =MKFullNLArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20NL_MK.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_MK = []\n",
    "Prec20_SBI_MK = []\n",
    "PrecFull_SBI_MK = []\n",
    "\n",
    "Prec7_NLLS_MK = []\n",
    "Prec20_NLLS_MK = []\n",
    "PrecFull_NLLS_MK = []\n",
    "for i in range(32):\n",
    "    Prec7_SBI_MK.append(np.std(MKMinArr[i][WMs[i]]))\n",
    "    Prec20_SBI_MK.append(np.std(MKMidArr[i][WMs[i]]))\n",
    "    PrecFull_SBI_MK.append(np.std(MKFullArr[i][WMs[i]]))\n",
    "\n",
    "    Prec7_NLLS_MK.append(np.std(MKMinNLArr[i][WMs[i]]))\n",
    "    Prec20_NLLS_MK.append(np.std(MKMidNLArr[i][WMs[i]]))\n",
    "    PrecFull_NLLS_MK.append(np.std(MKFullNLArr[i][WMs[i]]))\n",
    "\n",
    "AccM7_AK = []\n",
    "AccM20_AK = []\n",
    "AccMFulls_AK = []\n",
    "\n",
    "AccM7NL_AK = []\n",
    "AccM20NL_AK = []\n",
    "\n",
    "SSIM7_AK = []\n",
    "SSIM20_AK = []\n",
    "SSIMFulls_AK = []\n",
    "\n",
    "SSIM7NL_AK = []\n",
    "SSIM20NL_AK = []\n",
    "for i in range(32):\n",
    "    M7 =AKMinArr[i]\n",
    "    MF =AKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    AccM7_AK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =AKMidArr[i]\n",
    "    MF =AKFullArr[i]\n",
    "    AccM20_AK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =AKFullArr[i]\n",
    "    MF =AKFullNLArr[i]\n",
    "    AccMFulls_AK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 =AKMinNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =AKFullNLArr[i]\n",
    "    AccM7NL_AK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =AKMidNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =AKFullNLArr[i]\n",
    "    AccM20NL_AK.append(np.nanmean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    \n",
    "    NS1 =AKMinArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =AKFullArr[i]\n",
    "    NS2 = gaussian_filter(NS2, sigma=0.5)\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7_AK.append(result)\n",
    "\n",
    "    NS1 =AKMidArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =AKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20_AK.append(result)\n",
    "    \n",
    "    NS1 =AKFullArr[i]\n",
    "    NS2 =AKFullNLArr[i]\n",
    "    Ma = masks[i] * NS2 == 0\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIMFulls_AK.append(result)\n",
    "\n",
    "    NS1 =AKMinNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =AKFullNLArr[i]\n",
    "    NS2 = gaussian_filter(NS2, sigma=0.5)\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7NL_AK.append(result)\n",
    "\n",
    "    NS1 =AKMidNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =AKFullNLArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20NL_AK.append(result)\n",
    "\n",
    "Prec7_SBI_AK = []\n",
    "Prec20_SBI_AK = []\n",
    "PrecFull_SBI_AK = []\n",
    "\n",
    "Prec7_NLLS_AK = []\n",
    "Prec20_NLLS_AK = []\n",
    "PrecFull_NLLS_AK = []\n",
    "for i in range(32):\n",
    "    Prec7_SBI_AK.append(np.std(AKMinArr[i][WMs[i]]))\n",
    "    Prec20_SBI_AK.append(np.std(AKMidArr[i][WMs[i]]))\n",
    "    PrecFull_SBI_AK.append(np.std(AKFullArr[i][WMs[i]]))\n",
    "\n",
    "    Prec7_NLLS_AK.append(np.std(AKMinNLArr[i][WMs[i]]))\n",
    "    Prec20_NLLS_AK.append(np.std(AKMidNLArr[i][WMs[i]]))\n",
    "    PrecFull_NLLS_AK.append(np.std(AKFullNLArr[i][WMs[i]]))\n",
    "\n",
    "\n",
    "AccM7_RK = []\n",
    "AccM20_RK = []\n",
    "AccMFulls_RK = []\n",
    "\n",
    "AccM7NL_RK = []\n",
    "AccM20NL_RK = []\n",
    "\n",
    "SSIM7_RK = []\n",
    "SSIM20_RK = []\n",
    "SSIMFulls_RK = []\n",
    "\n",
    "SSIM7NL_RK = []\n",
    "SSIM20NL_RK = []\n",
    "for i in range(32):\n",
    "    M7 =RKMinArr[i]\n",
    "    MF =RKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    AccM7_RK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =RKMidArr[i]\n",
    "    MF =RKFullArr[i]\n",
    "    AccM20_RK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =RKFullArr[i]\n",
    "    MF =RKFullNLArr[i]\n",
    "    AccMFulls_RK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 =RKMinNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =RKFullNLArr[i]\n",
    "    AccM7NL_RK.append(np.median(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    M7 =RKMidNLArr[i]\n",
    "    M7[np.isnan(M7)] = 0\n",
    "    MF =RKFullNLArr[i]\n",
    "    AccM20NL_RK.append(np.nanmean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    \n",
    "    NS1 =RKMinArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =RKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7_RK.append(result)\n",
    "\n",
    "    NS1 =RKMidArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =RKFullArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20_RK.append(result)\n",
    "    \n",
    "    NS1 =RKFullArr[i]\n",
    "    NS2 =RKFullNLArr[i]\n",
    "    Ma = masks[i] * NS2 == 0\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIMFulls_RK.append(result)\n",
    "\n",
    "    NS1 =RKMinNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =RKFullNLArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM7NL_RK.append(result)\n",
    "\n",
    "    NS1 =RKMidNLArr[i]\n",
    "    NS1 = gaussian_filter(NS1, sigma=0.5)\n",
    "    NS2 =RKFullNLArr[i]\n",
    "    Ma = masks[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7,dat_range=10)\n",
    "    SSIM20NL_RK.append(result)\n",
    "\n",
    "Prec7_SBI_RK = []\n",
    "Prec20_SBI_RK = []\n",
    "PrecFull_SBI_RK = []\n",
    "\n",
    "Prec7_NLLS_RK = []\n",
    "Prec20_NLLS_RK = []\n",
    "PrecFull_NLLS_RK = []\n",
    "for i in range(32):\n",
    "    Prec7_SBI_RK.append(np.std(RKMinArr[i][WMs[i]]))\n",
    "    Prec20_SBI_RK.append(np.std(RKMidArr[i][WMs[i]]))\n",
    "    PrecFull_SBI_RK.append(np.std(RKFullArr[i][WMs[i]]))\n",
    "\n",
    "    Prec7_NLLS_RK.append(np.std(RKMinNLArr[i][WMs[i]]))\n",
    "    Prec20_NLLS_RK.append(np.std(RKMidNLArr[i][WMs[i]]))\n",
    "    PrecFull_NLLS_RK.append(np.std(RKFullNLArr[i][WMs[i]]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e528a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:58:35.262144Z",
     "start_time": "2025-12-24T13:58:35.238909Z"
    }
   },
   "outputs": [],
   "source": [
    "MSDir = '../../MS_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3c6fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T11:36:57.873112Z",
     "start_time": "2025-12-28T11:35:43.690045Z"
    }
   },
   "outputs": [],
   "source": [
    "gTabsF = []\n",
    "Dats   = []\n",
    "\n",
    "gTabs7 = []\n",
    "gTabs20 = []\n",
    "Masks = []\n",
    "WMDir = MSDir+'WM_masks/'\n",
    "WMs = []\n",
    "for i,Name in tqdm(enumerate(['NMSS_11_1year','NMSS_15','NMSS_16','NMSS_18','NMSS_19','Ctrl055_R01_28','Ctrl056_R01_29','Ctrl057_R01_30'])):\n",
    "    MatDir = MSDir+Name\n",
    "\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    affine = np.ones((4,4))\n",
    "    \n",
    "    data, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "    _, maskCut = median_otsu(data, vol_idx=range(10, 50),autocrop=False)\n",
    "\n",
    "    true_indices = np.argwhere(maskCut)\n",
    "    \n",
    "    # Determine the minimum and maximum indices along each dimension\n",
    "    min_coords = true_indices.min(axis=0)\n",
    "    max_coords = true_indices.max(axis=0)\n",
    "    \n",
    "    for k,x in enumerate(os.listdir(WMDir)):\n",
    "        if Name in x:\n",
    "            print(Name)\n",
    "            WM, affine, img = load_nifti(WMDir+x, return_img=True)\n",
    "            WM, affine = reslice(WM, affine, (2,2,2), (2.5,2.5,2.5))\n",
    "            if(i<5):\n",
    "                WM_t = np.fliplr(np.swapaxes(WM,0,1))\n",
    "            else:\n",
    "                WM_t = np.fliplr(np.flipud(np.swapaxes(WM,0,1)))\n",
    "            WM_t  = WM_t[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "            WMs.append(WM_t)\n",
    "            \n",
    "    maskdata, mask = median_otsu(data, vol_idx=range(10, 50),autocrop=True)\n",
    "    axial_middle = maskdata.shape[2] // 2\n",
    "    Masks.append(mask)\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    bvecs2000 = bvecs[bvals==2000]\n",
    "    bvecs4000 = bvecs[bvals==4000]\n",
    "\n",
    "    bvals2000 = np.array([0] + list(bvals[bvals==2000]))\n",
    "    bvecs2000 = np.vstack([[0,0,0],bvecs[bvals==2000]])\n",
    "\n",
    "    Dats.append(maskdata[:,:,:,:])\n",
    "    \n",
    "    gTabsF.append(gradient_table(bvals,bvecs))\n",
    "    if i == 0:\n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs2000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(6):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "        \n",
    "        selected_indices7 = selected_indices\n",
    "        \n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs4000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(14):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs4000))) - set(selected_indices))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "        selected_indices7_2 = selected_indices\n",
    "        \n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs2000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(19):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "        selected_indices20 = selected_indices\n",
    "        \n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs4000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(27):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs4000))) - set(selected_indices))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "        selected_indices20_2 = selected_indices\n",
    "    \n",
    "        Indxs7 = np.hstack([0,np.where(bvals==2000)[0][np.array(selected_indices7)[1:]-1],np.where(bvals==4000)[0][selected_indices7_2]])\n",
    "        Indxs20 = np.hstack([0,np.where(bvals==2000)[0][np.array(selected_indices20)[1:]-1],np.where(bvals==4000)[0][selected_indices20_2]])\n",
    "    gTabs7.append(gradient_table([0]+[2000]*6 + [4000]*15,np.vstack([bvecs2000[selected_indices7],bvecs4000[selected_indices7_2]])))\n",
    "    gTabs20.append(gradient_table([0]+[2000]*19 + [4000]*28,np.vstack([bvecs2000[selected_indices20],bvecs4000[selected_indices20_2]])))\n",
    "axial_middles = [32]*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245e881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:08:40.207243Z",
     "start_time": "2025-12-24T14:03:01.380442Z"
    }
   },
   "outputs": [],
   "source": [
    "MKFullArr = []\n",
    "RKFullArr = []\n",
    "AKFullArr = []\n",
    "MKTFullArr = []\n",
    "KFAFullArr = []\n",
    "for kk in range(8):\n",
    "    Dat = Dats[kk]\n",
    "    gt = gTabsF[kk]\n",
    "    ArrShape = Dat.shape[:2]\n",
    "    AM = axial_middles[kk]\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dat[:, :, AM, :], axis=-1) != 0\n",
    "    \n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs,gt.bvals,Dat[i,j,AM, :]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "    \n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "    \n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "        \n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):  \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "    \n",
    "    MK7  = np.zeros(ArrShape)\n",
    "    RK7  = np.zeros(ArrShape)\n",
    "    AK7  = np.zeros(ArrShape)\n",
    "    MKT7 = np.zeros(ArrShape)\n",
    "    KFA7 = np.zeros(ArrShape)\n",
    "    for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "        for j in range(ArrShape[1]):\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK7[i,j] = Metrics[0]\n",
    "            AK7[i,j] = Metrics[1]\n",
    "            RK7[i,j] = Metrics[2]\n",
    "            MKT7[i,j] = Metrics[3]\n",
    "            KFA7[i,j] = Metrics[4]\n",
    "    MKFullArr.append(MK7)\n",
    "    RKFullArr.append(RK7)\n",
    "    AKFullArr.append(AK7)\n",
    "    MKTFullArr.append(MKT7)\n",
    "    KFAFullArr.append(KFA7)\n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    plt.imshow(MKT7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    plt.imshow(KFA7.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b85fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:14:20.134523Z",
     "start_time": "2025-12-24T14:08:40.207971Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMidArr = []\n",
    "RKMidArr = []\n",
    "AKMidArr = []\n",
    "MKTMidArr = []\n",
    "KFAMidArr = []\n",
    "for kk in range(8):\n",
    "    Dat = Dats[kk]\n",
    "    ArrShape = Dat.shape[:2]\n",
    "    \n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dats[kk][:, :, axial_middles[kk], :], axis=-1) != 0\n",
    "    \n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    Arr = Dats[kk][:,:,axial_middles[kk], Indxs20]\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs[Indxs20],gt.bvals[Indxs20],Arr[i,j]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "    \n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):  \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "    \n",
    "    MK7  = np.zeros(ArrShape)\n",
    "    RK7  = np.zeros(ArrShape)\n",
    "    AK7  = np.zeros(ArrShape)\n",
    "    MKT7 = np.zeros(ArrShape)\n",
    "    KFA7 = np.zeros(ArrShape)\n",
    "    for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "        for j in range(ArrShape[1]):\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK7[i,j] = Metrics[0]\n",
    "            AK7[i,j] = Metrics[1]\n",
    "            RK7[i,j] = Metrics[2]\n",
    "            MKT7[i,j] = Metrics[3]\n",
    "            KFA7[i,j] = Metrics[4]\n",
    "    MKMidArr.append(MK7)\n",
    "    RKMidArr.append(RK7)\n",
    "    AKMidArr.append(AK7)\n",
    "    MKTMidArr.append(MKT7)\n",
    "    KFAMidArr.append(KFA7)\n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    plt.imshow(MKT7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    plt.imshow(KFA7.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284a6ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:02.057078Z",
     "start_time": "2025-12-24T14:14:20.135253Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMinArr = []\n",
    "RKMinArr = []\n",
    "AKMinArr = []\n",
    "MKTMinArr = []\n",
    "KFAMinArr = []\n",
    "for kk in range(8):\n",
    "    Dat = Dats[kk]\n",
    "    ArrShape = Dat.shape[:2]\n",
    "    \n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dats[kk][:, :, axial_middles[kk], :], axis=-1) != 0\n",
    "    \n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    Arr = Dats[kk][:,:,axial_middles[kk], Indxs7]\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((500,), x=DKIFeatures(gt.bvecs[Indxs7],gt.bvals[Indxs7],Arr[i,j]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "    \n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices)\n",
    "    )\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):  \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "    \n",
    "    MK7  = np.zeros(ArrShape)\n",
    "    RK7  = np.zeros(ArrShape)\n",
    "    AK7  = np.zeros(ArrShape)\n",
    "    MKT7 = np.zeros(ArrShape)\n",
    "    KFA7 = np.zeros(ArrShape)\n",
    "    for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "        for j in range(ArrShape[1]):\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            MK7[i,j] = Metrics[0]\n",
    "            AK7[i,j] = Metrics[1]\n",
    "            RK7[i,j] = Metrics[2]\n",
    "            MKT7[i,j] = Metrics[3]\n",
    "            KFA7[i,j] = Metrics[4]\n",
    "    MKMinArr.append(MK7)\n",
    "    RKMinArr.append(RK7)\n",
    "    AKMinArr.append(AK7)\n",
    "    MKTMinArr.append(MKT7)\n",
    "    KFAMinArr.append(KFA7)\n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    plt.imshow(MKT7.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    plt.imshow(KFA7.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720d9ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:11.929582Z",
     "start_time": "2025-12-24T14:20:02.057720Z"
    }
   },
   "outputs": [],
   "source": [
    "MKFullNLArr = []\n",
    "RKFullNLArr = []\n",
    "AKFullNLArr = []\n",
    "MKTFullNLArr = []\n",
    "KFAFullNLArr = []\n",
    "for kk in range(8):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabsF[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(Dats[kk][:,:,axial_middles[kk],:])\n",
    "    MK_NLFull  = dkifitNL.mk()\n",
    "    AK_NLFull  = dkifitNL.ak()\n",
    "    RK_NLFull = dkifitNL.rk()\n",
    "    \n",
    "    MKFullNLArr.append(MK_NLFull)\n",
    "    RKFullNLArr.append(RK_NLFull)\n",
    "    AKFullNLArr.append(AK_NLFull)\n",
    "    #MKTFullNLArr.append(MKT_NLFull)\n",
    "    #KFAFullNLArr.append(KFA_NLFull)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    #plt.imshow(MKT_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    #plt.imshow(KFA_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10536297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:16.421220Z",
     "start_time": "2025-12-24T14:20:11.930274Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMidNLArr = []\n",
    "RKMidNLArr = []\n",
    "AKMidNLArr = []\n",
    "MKTFullNLArr = []\n",
    "KFAFullNLArr = []\n",
    "for kk in range(8):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabs20[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(Dats[kk][:,:,axial_middles[kk],Indxs20])\n",
    "    MK_NLFull  = dkifitNL.mk()\n",
    "    AK_NLFull  = dkifitNL.ak()\n",
    "    RK_NLFull = dkifitNL.rk()\n",
    "    \n",
    "    MKMidNLArr.append(MK_NLFull)\n",
    "    RKMidNLArr.append(RK_NLFull)\n",
    "    AKMidNLArr.append(AK_NLFull)\n",
    "    #MKTFullNLArr.append(MKT_NLFull)\n",
    "    #KFAFullNLArr.append(KFA_NLFull)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    #plt.imshow(MKT_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    #plt.imshow(KFA_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79a0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:19.448945Z",
     "start_time": "2025-12-24T14:20:16.421846Z"
    }
   },
   "outputs": [],
   "source": [
    "MKMinNLArr = []\n",
    "RKMinNLArr = []\n",
    "AKMinNLArr = []\n",
    "MKTFullNLArr = []\n",
    "KFAFullNLArr = []\n",
    "for kk in range(8):\n",
    "    dkimodelNL = dki.DiffusionKurtosisModel(gTabs7[kk],fit_method='NLLS')\n",
    "    dkifitNL = dkimodelNL.fit(Dats[kk][:,:,axial_middles[kk],Indxs7])\n",
    "    MK_NLFull  = dkifitNL.mk()\n",
    "    AK_NLFull  = dkifitNL.ak()\n",
    "    RK_NLFull = dkifitNL.rk()\n",
    "    \n",
    "    MKMinNLArr.append(MK_NLFull)\n",
    "    RKMinNLArr.append(RK_NLFull)\n",
    "    AKMinNLArr.append(AK_NLFull)\n",
    "    #MKTFullNLArr.append(MKT_NLFull)\n",
    "    #KFAFullNLArr.append(KFA_NLFull)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,5,figsize=(24,6.4))\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(MK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(RK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(AK_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[3])\n",
    "    #plt.imshow(MKT_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.sca(ax[4])\n",
    "    #plt.imshow(KFA_NLFull.T,vmin=0,vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0d619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:23.350776Z",
     "start_time": "2025-12-24T14:20:19.449631Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_MK_MS= []\n",
    "AccM20_MK_MS= []\n",
    "AccMFulls_MK_MS= []\n",
    "\n",
    "AccM7NL_MK_MS= []\n",
    "AccM20NL_MK_MS= []\n",
    "\n",
    "SSIM7_MK_MS= []\n",
    "SSIM20_MK_MS= []\n",
    "SSIMFulls_MK_MS= []\n",
    "\n",
    "SSIM7NL_MK_MS= []\n",
    "SSIM20NL_MK_MS= []\n",
    "for i in range(8):\n",
    "    M7 = MKMinArr[i]\n",
    "    MF = MKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM7_MK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MKMidArr[i]\n",
    "    MF = MKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM20_MK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MKFullArr[i]\n",
    "    MF = MKFullNLArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccMFulls_MK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MKMinNLArr[i]\n",
    "    MF = MKFullNLArr[i]\n",
    "\n",
    "    AccM7NL_MK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MKMidNLArr[i]\n",
    "    MF = MKFullNLArr[i]\n",
    "\n",
    "    AccM20NL_MK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    NS1 = MKMinArr[i]\n",
    "    NS2 = MKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_MK_MS.append(result)\n",
    "\n",
    "    NS1 = MKMidArr[i]\n",
    "    NS2 = MKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_MK_MS.append(result)\n",
    "    \n",
    "    NS1 = MKFullArr[i]\n",
    "    NS2 = MKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma * (abs(NS2) > 0), win_size=7)\n",
    "    SSIMFulls_MK_MS.append(result)\n",
    "\n",
    "    NS1 = MKMinNLArr[i]\n",
    "    NS2 = MKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_MK_MS.append(result)\n",
    "\n",
    "    NS1 = MKMidNLArr[i]\n",
    "    NS2 = MKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_MK_MS.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_MK_MS= []\n",
    "Prec20_SBI_MK_MS= []\n",
    "PrecFull_SBI_MK_MS= []\n",
    "\n",
    "Prec7_NLLS_MK_MS= []\n",
    "Prec20_NLLS_MK_MS= []\n",
    "PrecFull_NLLS_MK_MS= []\n",
    "for i in range(8):\n",
    "    Prec7_SBI_MK_MS.append(np.std(MKMinArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_SBI_MK_MS.append(np.std(MKMidArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_SBI_MK_MS.append(np.std(MKFullArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "\n",
    "    Prec7_NLLS_MK_MS.append(np.std(MKMinNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_NLLS_MK_MS.append(np.std(MKMidNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_NLLS_MK_MS.append(np.std(MKFullNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e6657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:27.291324Z",
     "start_time": "2025-12-24T14:20:23.351518Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_AK_MS = []\n",
    "AccM20_AK_MS = []\n",
    "AccMFulls_AK_MS = []\n",
    "\n",
    "AccM7NL_AK_MS = []\n",
    "AccM20NL_AK_MS = []\n",
    "\n",
    "SSIM7_AK_MS = []\n",
    "SSIM20_AK_MS = []\n",
    "SSIMFulls_AK_MS = []\n",
    "\n",
    "SSIM7NL_AK_MS = []\n",
    "SSIM20NL_AK_MS = []\n",
    "for i in range(8):\n",
    "    M7 = AKMinArr[i]\n",
    "    MF = AKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM7_AK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AKMidArr[i]\n",
    "    MF = AKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM20_AK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AKFullArr[i]\n",
    "    MF = AKFullNLArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccMFulls_AK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AKMinNLArr[i]\n",
    "    MF = AKFullNLArr[i]\n",
    "\n",
    "    AccM7NL_AK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AKMidNLArr[i]\n",
    "    MF = AKFullNLArr[i]\n",
    "\n",
    "    AccM20NL_AK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    NS1 = AKMinArr[i]\n",
    "    NS2 = AKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_AK_MS.append(result)\n",
    "\n",
    "    NS1 = AKMidArr[i]\n",
    "    NS2 = AKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_AK_MS.append(result)\n",
    "    \n",
    "    NS1 = AKFullArr[i]\n",
    "    NS2 = AKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma * (abs(NS2) > 0), win_size=7)\n",
    "    SSIMFulls_AK_MS.append(result)\n",
    "\n",
    "    NS1 = AKMinNLArr[i]\n",
    "    NS2 = AKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_AK_MS.append(result)\n",
    "\n",
    "    NS1 = AKMidNLArr[i]\n",
    "    NS2 = AKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_AK_MS.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_AK_MS = []\n",
    "Prec20_SBI_AK_MS = []\n",
    "PrecFull_SBI_AK_MS = []\n",
    "\n",
    "Prec7_NLLS_AK_MS = []\n",
    "Prec20_NLLS_AK_MS = []\n",
    "PrecFull_NLLS_AK_MS = []\n",
    "for i in range(8):\n",
    "    Prec7_SBI_AK_MS.append(np.std(AKMinArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_SBI_AK_MS.append(np.std(AKMidArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_SBI_AK_MS.append(np.std(AKFullArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "\n",
    "    Prec7_NLLS_AK_MS.append(np.std(AKMinNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_NLLS_AK_MS.append(np.std(AKMidNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_NLLS_AK_MS.append(np.std(AKFullNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579cb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:20:31.207399Z",
     "start_time": "2025-12-24T14:20:27.292149Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_RK_MS = []\n",
    "AccM20_RK_MS = []\n",
    "AccMFulls_RK_MS = []\n",
    "\n",
    "AccM7NL_RK_MS = []\n",
    "AccM20NL_RK_MS = []\n",
    "\n",
    "SSIM7_RK_MS = []\n",
    "SSIM20_RK_MS = []\n",
    "SSIMFulls_RK_MS = []\n",
    "\n",
    "SSIM7NL_RK_MS = []\n",
    "SSIM20NL_RK_MS = []\n",
    "for i in range(8):\n",
    "    M7 = RKMinArr[i]\n",
    "    MF = RKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM7_RK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RKMidArr[i]\n",
    "    MF = RKFullArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccM20_RK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RKFullArr[i]\n",
    "    MF = RKFullNLArr[i]\n",
    "    Ma = Masks[i][:,:,axial_middles[i]]\n",
    "    AccMFulls_RK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RKMinNLArr[i]\n",
    "    MF = RKFullNLArr[i]\n",
    "\n",
    "    AccM7NL_RK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RKMidNLArr[i]\n",
    "    MF = RKFullNLArr[i]\n",
    "\n",
    "    AccM20NL_RK_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    NS1 = RKMinArr[i]\n",
    "    NS2 = RKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_RK_MS.append(result)\n",
    "\n",
    "    NS1 = RKMidArr[i]\n",
    "    NS2 = RKFullArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_RK_MS.append(result)\n",
    "    \n",
    "    NS1 = RKFullArr[i]\n",
    "    NS2 = RKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma * (abs(NS2) > 0), win_size=7)\n",
    "    SSIMFulls_RK_MS.append(result)\n",
    "\n",
    "    NS1 = RKMinNLArr[i]\n",
    "    NS2 = RKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_RK_MS.append(result)\n",
    "\n",
    "    NS1 = RKMidNLArr[i]\n",
    "    NS2 = RKFullNLArr[i]\n",
    "\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_RK_MS.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_RK_MS = []\n",
    "Prec20_SBI_RK_MS = []\n",
    "PrecFull_SBI_RK_MS = []\n",
    "\n",
    "Prec7_NLLS_RK_MS = []\n",
    "Prec20_NLLS_RK_MS = []\n",
    "PrecFull_NLLS_RK_MS = []\n",
    "for i in range(8):\n",
    "    Prec7_SBI_RK_MS.append(np.std(RKMinArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_SBI_RK_MS.append(np.std(RKMidArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_SBI_RK_MS.append(np.std(RKFullArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "\n",
    "    Prec7_NLLS_RK_MS.append(np.std(RKMinNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    Prec20_NLLS_RK_MS.append(np.std(RKMidNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n",
    "    PrecFull_NLLS_RK_MS.append(np.std(RKFullNLArr[i][WMs[i][:,:,axial_middles[i]]>0.8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8793c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "MK_RT_SBI= []\n",
    "AK_RT_SBI = []\n",
    "RK_RT_SBI = []\n",
    "\n",
    "MK_RT_SBI_Min = []\n",
    "AK_RT_SBI_Min = []\n",
    "RK_RT_SBI_Min = []\n",
    "\n",
    "MK_RT_NLLS_Min = []\n",
    "AK_RT_NLLS_Min = []\n",
    "RK_RT_NLLS_Min = []\n",
    "\n",
    "MK_RT_NLLS_Full = []\n",
    "AK_RT_NLLS_Full = []\n",
    "RK_RT_NLLS_Full = []\n",
    "for jj,N in enumerate(Names):\n",
    "    Subfiles = []\n",
    "    for k,x in enumerate(os.listdir(RetestDir)):\n",
    "        if N in x:\n",
    "            print(x)\n",
    "            Subfiles.append(x)\n",
    "    Subfiles = sorted(Subfiles)\n",
    "\n",
    "    S = Subfiles[0]\n",
    "    MatDir = RetestDir+S\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    affine1 = np.eye(4)\n",
    "\n",
    "    data, affine1 = reslice(F['data'], affine1, (2,2,2), (2.5,2.5,2.5))\n",
    "    _, maskCut = median_otsu(data, vol_idx=range(10, 80), autocrop=False)\n",
    "    true_indices = np.argwhere(maskCut)\n",
    "\n",
    "    # Determine the minimum and maximum indices along each dimension\n",
    "    min_coords = true_indices.min(axis=0)\n",
    "    max_coords = true_indices.max(axis=0)\n",
    "    AM = (max_coords[-1]+min_coords[-1])//2\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    \n",
    "    bvecs2000 = bvecs[bvals==2000]\n",
    "    bvecs4000 = bvecs[bvals==4000]\n",
    "    bvals2000 = np.array([0] + list(bvals[bvals==2000]))\n",
    "    bvecs2000 = np.vstack([[0,0,0],bvecs[bvals==2000]])\n",
    "    # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "    selected_indices = [0]\n",
    "    distance_matrix = squareform(pdist(bvecs2000))\n",
    "    # Iteratively select the point furthest from the current selection\n",
    "    for _ in range(6):  # We need 7 points in total, and one is already selected\n",
    "        remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices))\n",
    "\n",
    "        # Calculate the minimum distance to the selected points for each remaining point\n",
    "        min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "\n",
    "        # Select the point with the maximum minimum distance\n",
    "        next_index = remaining_indices[np.argmax(min_distances)]\n",
    "        selected_indices.append(next_index)\n",
    "\n",
    "    selected_indices7 = selected_indices\n",
    "\n",
    "    # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "    selected_indices = [0]\n",
    "    distance_matrix = squareform(pdist(bvecs4000))\n",
    "    # Iteratively select the point furthest from the current selection\n",
    "    for _ in range(14):  # We need 7 points in total, and one is already selected\n",
    "        remaining_indices = list(set(range(len(bvecs4000))) - set(selected_indices))\n",
    "\n",
    "        # Calculate the minimum distance to the selected points for each remaining point\n",
    "        min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "\n",
    "        # Select the point with the maximum minimum distance\n",
    "        next_index = remaining_indices[np.argmax(min_distances)]\n",
    "        selected_indices.append(next_index)\n",
    "    selected_indices7_2 = selected_indices\n",
    "    Indxs7 = [np.hstack([0,np.where(bvals==2000)[0][np.array(selected_indices7)[1:]-1],np.where(bvals==4000)[0][selected_indices7_2]])]\n",
    "    gTabs7 = [gradient_table([0]+[2000]*6 + [4000]*15,np.vstack([bvecs2000[selected_indices7],bvecs4000[selected_indices7_2]]))]\n",
    "    \n",
    "\n",
    "    gtabs = [gradient_table(bvals = bvals,bvecs = bvecs)]\n",
    "    Dats = []\n",
    "    for i,S in enumerate(Subfiles[1:]):\n",
    "        MatDir = RetestDir+S\n",
    "        F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "        affine = np.eye(4)\n",
    "\n",
    "        data1, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "\n",
    "        bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "        bvecs[np.isnan(bvecs)] = 0\n",
    "        bvals = F['bval']\n",
    "        if(jj == 0):\n",
    "            if(i < 2):\n",
    "                data1 = data1[:,::-1]\n",
    "        elif(jj == 1 or jj == 2 or jj == 3 or jj == 4):\n",
    "            if(i<3):\n",
    "                data1 = data1[:,::-1]\n",
    "        elif(jj==5):\n",
    "            if(i>0 and i < 3):\n",
    "                data1 = data1[:,::-1]\n",
    "        Dats.append(data1)\n",
    "        gtabs.append(gradient_table(bvals = bvals,bvecs = bvecs))\n",
    "        \n",
    "        bvecs2000 = bvecs[bvals==2000]\n",
    "        bvecs4000 = bvecs[bvals==4000]\n",
    "        bvals2000 = np.array([0] + list(bvals[bvals==2000]))\n",
    "        bvecs2000 = np.vstack([[0,0,0],bvecs[bvals==2000]])\n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs2000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(6):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices))\n",
    "\n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "\n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "\n",
    "        selected_indices7 = selected_indices\n",
    "\n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs4000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(14):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs4000))) - set(selected_indices))\n",
    "\n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "\n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices.append(next_index)\n",
    "        selected_indices7_2 = selected_indices\n",
    "        Indxs7.append(np.hstack([0,np.where(bvals==2000)[0][np.array(selected_indices7)[1:]-1],np.where(bvals==4000)[0][selected_indices7_2]]))\n",
    "        gTabs7.append(gradient_table([0]+[2000]*6 + [4000]*15,np.vstack([bvecs2000[selected_indices7],bvecs4000[selected_indices7_2]])))\n",
    "\n",
    "    NewDats = [data]\n",
    "    for d,gt in zip(Dats,gtabs[1:]):\n",
    "        affine_map = rigid_register(data[...,gtabs[0].bvals==0].mean(axis=-1),d[...,gt.bvals==0].mean(axis=-1),affine1,affine1)\n",
    "        data2_warp = np.array([affine_map.transform(d[:,:,:,i], interpolation=\"linear\") for i in range(len(gt.bvals))])\n",
    "        data2_warp = np.rollaxis(data2_warp, 0, data2_warp.ndim)\n",
    "        NewDats.append(data2_warp)\n",
    "    \n",
    "    NewDats_masked = [ND*maskCut[...,None] for ND in NewDats]\n",
    "    \n",
    "    MK_Arr = []\n",
    "    AK_Arr = []\n",
    "    RK_Arr = []\n",
    "    for ND,gt in tqdm(zip(NewDats_masked,gtabs),position=0,leave=True):\n",
    "        mask = np.sum(ND[:, :, AM, :], axis=-1) != 0\n",
    "        # Get the indices where mask is True\n",
    "        indices = np.argwhere(mask)\n",
    "        floor = np.clip(ND.min(axis=-1),-np.inf,0)\n",
    "        dat = ND + abs(floor)[:,:,:,None] + 1e-5\n",
    "        # Define the function for optimization\n",
    "        def optimize_chunk(pixels):\n",
    "            results = []\n",
    "            for i, j in pixels:\n",
    "                samples = Network.sample((1000,), x=DKIFeatures(gt.bvecs,gt.bvals,dat[i,j,AM]),show_progress_bars=False)\n",
    "                results.append((i, j, samples.mean(axis=0)))\n",
    "            return results\n",
    "\n",
    "        chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "        results = Parallel(n_jobs=8)(\n",
    "            delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    "        )\n",
    "        ArrShape = mask.shape\n",
    "        NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "\n",
    "        # Assign the optimization results to NoiseEst\n",
    "        for chunk in results:\n",
    "            for i, j, x in chunk:\n",
    "                NoiseEst[i, j] = x\n",
    "\n",
    "        NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]):  \n",
    "                NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "        MK7  = np.zeros(ArrShape)\n",
    "        RK7  = np.zeros(ArrShape)\n",
    "        AK7  = np.zeros(ArrShape)\n",
    "        for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "            for j in range(ArrShape[1]):\n",
    "                Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "                MK7[i,j] = Metrics[0]\n",
    "                AK7[i,j] = Metrics[1]\n",
    "                RK7[i,j] = Metrics[2]\n",
    "        MK_Arr.append(MK7)\n",
    "        AK_Arr.append(AK7)\n",
    "        RK_Arr.append(RK7)\n",
    "    MK_RT_SBI.append(MK_Arr)\n",
    "    AK_RT_SBI.append(AK_Arr)\n",
    "    RK_RT_SBI.append(RK_Arr)\n",
    "\n",
    "    MK_Arr = []\n",
    "    AK_Arr = []\n",
    "    RK_Arr = []\n",
    "    for ND,gt,idx in tqdm(zip(NewDats_masked,gTabs7,Indxs7),position=0,leave=True):\n",
    "        mask = np.sum(ND[:, :, AM, :], axis=-1) != 0\n",
    "        # Get the indices where mask is True\n",
    "        indices = np.argwhere(mask)\n",
    "        floor = np.clip(ND.min(axis=-1),-np.inf,0)\n",
    "        dat = ND + abs(floor)[:,:,:,None] + 1e-5\n",
    "        dat = dat[...,idx]\n",
    "        def optimize_chunk(pixels):\n",
    "            results = []\n",
    "            for i, j in pixels:\n",
    "                samples = Network.sample((1000,), x=DKIFeatures(gt.bvecs,gt.bvals,dat[i,j,AM]),show_progress_bars=False)\n",
    "                results.append((i, j, samples.mean(axis=0)))\n",
    "            return results\n",
    "\n",
    "        chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "        results = Parallel(n_jobs=8)(\n",
    "            delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    "        )\n",
    "        \n",
    "        NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "\n",
    "        # Assign the optimization results to NoiseEst\n",
    "        for chunk in results:\n",
    "            for i, j, x in chunk:\n",
    "                NoiseEst[i, j] = x\n",
    "\n",
    "        NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]):  \n",
    "                NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "        MK7  = np.zeros(ArrShape)\n",
    "        RK7  = np.zeros(ArrShape)\n",
    "        AK7  = np.zeros(ArrShape)\n",
    "        for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "            for j in range(ArrShape[1]):\n",
    "                Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "                MK7[i,j] = Metrics[0]\n",
    "                AK7[i,j] = Metrics[1]\n",
    "                RK7[i,j] = Metrics[2]\n",
    "        MK_Arr.append(MK7)\n",
    "        AK_Arr.append(AK7)\n",
    "        RK_Arr.append(RK7)\n",
    "    MK_RT_SBI_Min.append(MK_Arr)\n",
    "    AK_RT_SBI_Min_list.append(AK_Arr)\n",
    "    RK_RT_SBI_Min_list.append(RK_Arr)    \n",
    "    \n",
    "    \n",
    "    MK_NLS_arr = []\n",
    "    AK_NLS_arr = []\n",
    "    RK_NLS_arr = []\n",
    "    for d,gt,idx in zip(NewDats_masked,gTabs7,Indxs7):\n",
    "        tenmodel = dki.DiffusionKurtosisModel(gt,return_S0_hat = True)\n",
    "        tenfit = tenmodel.fit(d[:,:,AM,idx])\n",
    "\n",
    "        MK_NLS_arr.append(tenfit.mk())\n",
    "        AK_NLS_arr.append(tenfit.ak())\n",
    "        RK_NLS_arr.append(tenfit.rk())\n",
    "    \n",
    "    MK_RT_NLLS_Min.append(MK_NLS_arr)\n",
    "    AK_RT_NLLS_Min.append(AK_NLS_arr)\n",
    "    RK_RT_NLLS_Min.append(RK_NLS_arr)\n",
    "    \n",
    "    MK_NLS_arr = []\n",
    "    AK_NLS_arr = []\n",
    "    RK_NLS_arr = []\n",
    "    for d,gt in zip(NewDats_masked,gtabs):\n",
    "        tenmodel = dki.DiffusionKurtosisModel(gt,return_S0_hat = True)\n",
    "        tenfit = tenmodel.fit(d[:,:,AM])\n",
    "\n",
    "        MK_NLS_arr.append(tenfit.mk())\n",
    "        AK_NLS_arr.append(tenfit.ak())\n",
    "        RK_NLS_arr.append(tenfit.rk())\n",
    "    \n",
    "    MK_RT_NLLS_Full.append(MK_NLS_arr)\n",
    "    AK_RT_NLLS_Full.append(AK_NLS_arr)\n",
    "    RK_RT_NLLS_Full.append(RK_NLS_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589515ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MK_RT_SBI_Min_list = []\n",
    "RK_RT_SBI_Min_list = []\n",
    "AK_RT_SBI_Min_list = []\n",
    "MK_RT_SBI_Full_list = []\n",
    "RK_RT_SBI_Full_list = []\n",
    "AK_RT_SBI_Full_list = []\n",
    "\n",
    "MK_RT_NLLS_Min_list = []\n",
    "RK_RT_NLLS_Min_list = []\n",
    "AK_RT_NLLS_Min_list = []\n",
    "MK_RT_NLLS_Full_list = []\n",
    "RK_RT_NLLS_Full_list = []\n",
    "AK_RT_NLLS_Full_list = []\n",
    "\n",
    "\n",
    "for kk in range(len(MK_RT_SBI_Min)):\n",
    "    for i in range(len(MK_RT_SBI_Min[kk])):\n",
    "        MK_RT_SBI_Min_list.append(MK_RT_SBI_Min[kk][i])\n",
    "        AK_RT_SBI_Min_list.append(AK_RT_SBI_Min[kk][i])\n",
    "        RK_RT_SBI_Min_list.append(RK_RT_SBI_Min[kk][i])\n",
    "\n",
    "        MK_RT_SBI_Full_list.append(MK_RT_SBI_Full[kk][i])\n",
    "        AK_RT_SBI_Full_list.append(AK_RT_SBI_Full[kk][i])\n",
    "        RK_RT_SBI_Full_list.append(RK_RT_SBI_Full[kk][i])\n",
    "        \n",
    "        MK_RT_NLLS_Min_list.append(MK_RT_NLLS_Min[kk][i])\n",
    "        AK_RT_NLLS_Min_list.append(AK_RT_NLLS_Min[kk][i])\n",
    "        RK_RT_NLLS_Min_list.append(RK_RT_NLLS_Min[kk][i])\n",
    "\n",
    "        MK_RT_NLLS_Full_list.append(MK_RT_NLLS_Full[kk][i])\n",
    "        AK_RT_NLLS_Full_list.append(AK_RT_NLLS_Full[kk][i])\n",
    "        RK_RT_NLLS_Full_list.append(RK_RT_NLLS_Full[kk][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccM7_MK_RT = []\n",
    "AccMFulls_MK_RT = []\n",
    "\n",
    "AccM7NL_MK_RT = []\n",
    "\n",
    "SSIM7_MK_RT = []\n",
    "SSIMFulls_MK_RT = []\n",
    "\n",
    "SSIM7NL_MK_RT = []\n",
    "for i in tqdm(range(29),position=0,leave=True):\n",
    "    M7 = MK_RT_SBI_Min_list[i]\n",
    "    MF = MK_RT_SBI_Full_list[i]\n",
    "    Ma = np.logical_not(MK_RT_SBI_Min_list[i]==0)\n",
    "    AccM7_MK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MK_RT_SBI_Full_list[i]\n",
    "    MF = MK_RT_NLLS_Full_list[i]\n",
    "    AccMFulls_MK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MK_RT_NLLS_Min_list[i]\n",
    "    MF = MK_RT_NLLS_Full_list[i]\n",
    "    AccM7NL_MK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = MK_RT_SBI_Min_list[i]\n",
    "    NS2 = MK_RT_SBI_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_MK_RT.append(result)\n",
    "\n",
    "    NS1 = MK_RT_SBI_Full_list[i]\n",
    "    NS2 = MK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_MK_RT.append(result)\n",
    "\n",
    "    NS1 = MK_RT_NLLS_Min_list[i]\n",
    "    NS2 = MK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_MK_RT.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccM7_AK_RT = []\n",
    "AccMFulls_AK_RT = []\n",
    "\n",
    "AccM7NL_AK_RT = []\n",
    "\n",
    "SSIM7_AK_RT = []\n",
    "SSIMFulls_AK_RT = []\n",
    "\n",
    "SSIM7NL_AK_RT = []\n",
    "for i in tqdm(range(29),position=0,leave=True):\n",
    "    M7 = AK_RT_SBI_Min_list[i]\n",
    "    MF = AK_RT_SBI_Full_list[i]\n",
    "    Ma = np.logical_not(MK_RT_SBI_Min_list[i]==0)\n",
    "    AccM7_AK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AK_RT_SBI_Full_list[i]\n",
    "    MF = AK_RT_NLLS_Full_list[i]\n",
    "    AccMFulls_AK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = AK_RT_NLLS_Min_list[i]\n",
    "    MF = AK_RT_NLLS_Full_list[i]\n",
    "    AccM7NL_AK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = AK_RT_SBI_Min_list[i]\n",
    "    NS2 = AK_RT_SBI_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_AK_RT.append(result)\n",
    "\n",
    "    NS1 = AK_RT_SBI_Full_list[i]\n",
    "    NS2 = AK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_AK_RT.append(result)\n",
    "\n",
    "    NS1 = AK_RT_NLLS_Min_list[i]\n",
    "    NS2 = AK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_AK_RT.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccM7_RK_RT = []\n",
    "AccMFulls_RK_RT = []\n",
    "\n",
    "AccM7NL_RK_RT = []\n",
    "\n",
    "SSIM7_RK_RT = []\n",
    "SSIMFulls_RK_RT = []\n",
    "\n",
    "SSIM7NL_RK_RT = []\n",
    "for i in tqdm(range(29),position=0,leave=True):\n",
    "    M7 = RK_RT_SBI_Min_list[i]\n",
    "    MF = RK_RT_SBI_Full_list[i]\n",
    "    Ma = np.logical_not(MK_RT_SBI_Min_list[i]==0)\n",
    "    AccM7_RK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RK_RT_SBI_Full_list[i]\n",
    "    MF = RK_RT_NLLS_Full_list[i]\n",
    "    AccMFulls_RK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = RK_RT_NLLS_Min_list[i]\n",
    "    MF = RK_RT_NLLS_Full_list[i]\n",
    "    AccM7NL_RK_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = RK_RT_SBI_Min_list[i]\n",
    "    NS2 = RK_RT_SBI_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_RK_RT.append(result)\n",
    "\n",
    "    NS1 = RK_RT_SBI_Full_list[i]\n",
    "    NS2 = RK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_RK_RT.append(result)\n",
    "\n",
    "    NS1 = RK_RT_NLLS_Min_list[i]\n",
    "    NS2 = RK_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_RK_RT.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a725016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "fig, ax2 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "y_data = np.array(AccM7NL_MK + AccM7NL_MK_MS+AccM7NL_MK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "#plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "y_data = np.array(AccM7NL_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.8)\n",
    "\n",
    "y_data = np.array(AccM7NL_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "ax2.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7NL_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.sca(ax2)\n",
    "\n",
    "y_data = np.array(AccMFulls_MK + AccMFulls_MK_MS+AccMFulls_MK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccMFulls_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_MK + AccM20_MK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5,label='HPC')\n",
    "\n",
    "y_data = np.array(AccM20_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_MK + AccM7_MK_MS+AccM7_MK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM7_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(AccM7_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5,label='GH\\ndata')\n",
    "\n",
    "y_data = np.array(AccM7_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "y_data = np.array(AccM20NL_MK + AccM20NL_MK_MS)\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20NL_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_MK + AccM20NL_MK_MS)\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "#ax2.set_ylim(0, 0.00016)\n",
    "\n",
    "# Common x-ticks\n",
    "\n",
    "# Adding broken axis effect\n",
    "d = .5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12, linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "\n",
    "leg = plt.legend(\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor= (-0.05,1.0),markerscale=1.5)\n",
    "\n",
    "for h in leg.legend_handles:\n",
    "    try:\n",
    "        h.set_alpha(1)\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between Axes\n",
    "\n",
    "y_data = np.array(SSIMFulls_MK + SSIMFulls_MK_MS+SSIMFulls_MK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.7)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.7)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_MK+SSIM20_MK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False,scatter_alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5,label='MS-\\nlesions')\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5,label='MS-\\nctrl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7_MK+SSIM7_MK_MS+SSIM7_MK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MK +SSIM20NL_MK_MS)\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MK+SSIM7NL_MK_MS+SSIM7NL_MK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7NL_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "leg = plt.legend(\n",
    "    loc='lower left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,markerscale=1.5,bbox_to_anchor=(-0.1,0))\n",
    "\n",
    "for h in leg.legend_handles:\n",
    "    try:\n",
    "        h.set_alpha(1)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "y_data = np.array(PrecFull_SBI_MK+PrecFull_SBI_MK_MS)\n",
    "g_pos = np.array([0.65])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(0.55,1.5,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 77)\n",
    "plt.fill_between(x,y1,y2,color=SBIFit,zorder=10,alpha=0.2,hatch='//')\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MK+Prec20_SBI_MK_MS)\n",
    "g_pos = np.array([1])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MK+Prec7_SBI_MK_MS)\n",
    "g_pos = np.array([1.35])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "y_data = np.array(PrecFull_NLLS_MK+PrecFull_NLLS_MK_MS)\n",
    "g_pos = np.array([1.8])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(1.7,2.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_MK)[~np.isnan(PrecFull_NLLS_MK)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_MK)[~np.isnan(PrecFull_NLLS_MK)], 77)\n",
    "plt.fill_between(x,y1,y2,color=WLSFit,zorder=10,alpha=0.2,hatch='//')#\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MK)\n",
    "g_pos = np.array([2.15])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MK+Prec7_NLLS_MK_MS)\n",
    "g_pos = np.array([2.5])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "plt.xticks([0.65,1,1.35,1.8,2.15,2.5],['Full','Mid','Min','Full','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xlim([0.3,2.7])\n",
    "ax.set_yticks([0.2,0.4,0.6,0.8,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33adb710",
   "metadata": {},
   "source": [
    "## d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "fig, ax2 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "y_data = np.array(AccM7NL_AK + AccM7NL_AK_MS+AccM7NL_AK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "#plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "y_data = np.array(AccM7NL_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.8)\n",
    "\n",
    "y_data = np.array(AccM7NL_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "ax2.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7NL_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.sca(ax2)\n",
    "\n",
    "y_data = np.array(AccMFulls_AK + AccMFulls_AK_MS+AccMFulls_AK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccMFulls_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_AK + AccM20_AK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5,label='HPC')\n",
    "\n",
    "y_data = np.array(AccM20_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_AK + AccM7_AK_MS+AccM7_AK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM7_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(AccM7_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5,label='GH\\ndata')\n",
    "\n",
    "y_data = np.array(AccM7_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "y_data = np.array(AccM20NL_AK + AccM20NL_AK_MS)\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20NL_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_AK + AccM20NL_AK_MS)\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "#ax2.set_ylim(0, 0.00016)\n",
    "\n",
    "# Common x-ticks\n",
    "\n",
    "# Adding broken axis effect\n",
    "d = .5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12, linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "\n",
    "if Save: plt.savefig(FigLoc+'DKI_AK_Acc.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between Axes\n",
    "\n",
    "y_data = np.array(SSIMFulls_AK + SSIMFulls_AK_MS+SSIMFulls_AK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(SSIMFulls_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIMFulls_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.7)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.7)\n",
    "\n",
    "y_data = np.array(SSIMFulls_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_AK+SSIM20_AK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False,scatter_alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5,label='MS-\\nlesions')\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5,label='MS-\\nctrl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7_AK+SSIM7_AK_MS+SSIM7_AK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_AK +SSIM20NL_AK_MS)\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM20NL_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_AK+SSIM7NL_AK_MS+SSIM7NL_AK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7NL_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_AK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7NL_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "if Save: plt.savefig(FigLoc+'DKI_AK_SSIM.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a370a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "y_data = np.array(PrecFull_SBI_AK+PrecFull_SBI_AK_MS)\n",
    "g_pos = np.array([0.65])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(0.55,1.5,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 77)\n",
    "plt.fill_between(x,y1,y2,color=SBIFit,zorder=10,alpha=0.2,hatch='//')\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_AK+Prec20_SBI_AK_MS)\n",
    "g_pos = np.array([1])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_AK+Prec7_SBI_AK_MS)\n",
    "g_pos = np.array([1.35])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "y_data = np.array(PrecFull_NLLS_AK+PrecFull_NLLS_AK_MS)\n",
    "g_pos = np.array([1.8])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(1.7,2.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_AK)[~np.isnan(PrecFull_NLLS_AK)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_AK)[~np.isnan(PrecFull_NLLS_AK)], 77)\n",
    "plt.fill_between(x,y1,y2,color=WLSFit,zorder=10,alpha=0.2,hatch='//')#\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_AK)\n",
    "g_pos = np.array([2.15])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_AK+Prec7_NLLS_AK_MS)\n",
    "g_pos = np.array([2.5])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_AK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_AK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "plt.xticks([0.65,1,1.35,1.8,2.15,2.5],['Full','Mid','Min','Full','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xlim([0.3,2.7])\n",
    "if Save: plt.savefig(FigLoc+'DKI_AK_Prec.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1f04a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:39:10.058471Z",
     "start_time": "2025-12-28T23:39:10.015085Z"
    }
   },
   "source": [
    "## e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "fig, ax2 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "y_data = np.array(AccM7NL_RK + AccM7NL_RK_MS+AccM7NL_RK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "#plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "y_data = np.array(AccM7NL_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.8)\n",
    "\n",
    "y_data = np.array(AccM7NL_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "ax2.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7NL_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.sca(ax2)\n",
    "\n",
    "y_data = np.array(AccMFulls_RK + AccMFulls_RK_MS+AccMFulls_RK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccMFulls_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_RK + AccM20_RK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5,label='HPC')\n",
    "\n",
    "y_data = np.array(AccM20_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_RK + AccM7_RK_MS+AccM7_RK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM7_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(AccM7_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5,label='GH\\ndata')\n",
    "\n",
    "y_data = np.array(AccM7_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "y_data = np.array(AccM20NL_RK + AccM20NL_RK_MS)\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20NL_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_RK + AccM20NL_RK_MS)\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "#ax2.set_ylim(0, 0.00016)\n",
    "\n",
    "# Common x-ticks\n",
    "\n",
    "# Adding broken axis effect\n",
    "d = .5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12, linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "\n",
    "if Save: plt.savefig(FigLoc+'DKI_RK_Acc.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between Axes\n",
    "\n",
    "y_data = np.array(SSIMFulls_RK + SSIMFulls_RK_MS+SSIMFulls_RK_RT)\n",
    "g_pos = np.array([0.8])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(SSIMFulls_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIMFulls_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.7)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.7)\n",
    "\n",
    "y_data = np.array(SSIMFulls_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_RK+SSIM20_RK_MS)\n",
    "g_pos = np.array([1.55])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False,scatter_alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5,label='MS-\\nlesions')\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5,label='MS-\\nctrl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7_RK+SSIM7_RK_MS+SSIM7_RK_RT)\n",
    "g_pos = np.array([1.95])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_RK +SSIM20NL_RK_MS)\n",
    "g_pos = np.array([2.65])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM20NL_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_RK+SSIM7NL_RK_MS+SSIM7NL_RK_RT)\n",
    "g_pos = np.array([3.05])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7NL_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_RK_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7NL_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "plt.xticks([0.8,1.55,1.95,2.65,3.05],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "    \n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "if Save: plt.savefig(FigLoc+'DKI_RK_SSIM.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.2,4.8))#, sharex=True)\n",
    "y_data = np.array(PrecFull_SBI_RK+PrecFull_SBI_RK_MS)\n",
    "g_pos = np.array([0.65])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(0.55,1.5,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 77)\n",
    "plt.fill_between(x,y1,y2,color=SBIFit,zorder=10,alpha=0.2,hatch='//')\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_RK+Prec20_SBI_RK_MS)\n",
    "g_pos = np.array([1])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_RK+Prec7_SBI_RK_MS)\n",
    "g_pos = np.array([1.35])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "y_data = np.array(PrecFull_NLLS_RK+PrecFull_NLLS_RK_MS)\n",
    "g_pos = np.array([1.8])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(1.7,2.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_RK)[~np.isnan(PrecFull_NLLS_RK)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_RK)[~np.isnan(PrecFull_NLLS_RK)], 77)\n",
    "plt.fill_between(x,y1,y2,color=WLSFit,zorder=10,alpha=0.2,hatch='//')#\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_RK)\n",
    "g_pos = np.array([2.15])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_RK+Prec7_NLLS_RK_MS)\n",
    "g_pos = np.array([2.5])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_RK)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_RK_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "plt.xticks([0.65,1,1.35,1.8,2.15,2.5],['Full','Mid','Min','Full','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xlim([0.3,2.7])\n",
    "ax.set_ylim([-0.01,1.5])\n",
    "if Save: plt.savefig(FigLoc+'DKI_RK_Prec.pdf',format='pdf',bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7de04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T15:33:55.749522Z",
     "start_time": "2025-12-16T15:33:55.701187Z"
    }
   },
   "source": [
    "## f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c1213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:31:38.281576Z",
     "start_time": "2025-12-28T13:31:38.144800Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Name = 'NMSS_11_1year'\n",
    "with open(MSDir+Name+'/Les_dict.pkl', 'rb') as f:\n",
    "    LesDict = pickle.load(f)\n",
    "_, maskCut = median_otsu(LesDict['data'][...,0], vol_idx=range(10, 50),autocrop=False)\n",
    "\n",
    "temp = np.copy(LesDict['data'][...,0])\n",
    "temp[~maskCut] = math.nan\n",
    "plt.imshow(temp,cmap='gray')\n",
    "lesion_cmap = ListedColormap(['red'])\n",
    "contra_cmap = ListedColormap(['lightsalmon'])\n",
    "plt.imshow(LesDict['lesion'],cmap=lesion_cmap,alpha=0.7)\n",
    "plt.imshow(LesDict['contra'],cmap=contra_cmap,alpha=0.7)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59855d54",
   "metadata": {},
   "source": [
    "## g-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5996943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T12:00:24.397696Z",
     "start_time": "2025-12-28T11:55:56.004404Z"
    }
   },
   "outputs": [],
   "source": [
    "MK_arr = []\n",
    "AK_arr = []\n",
    "RK_arr = []\n",
    "FA_arr = []\n",
    "MD_arr = []\n",
    "for i,Name in tqdm(enumerate(['NMSS_11_1year','NMSS_15','NMSS_16','NMSS_18','NMSS_19'])):\n",
    "    with open(MSDir+Name+'/Les_dict.pkl', 'rb') as f:\n",
    "        LesDict = pickle.load(f)\n",
    "    plt.imshow(LesDict['data'][...,0],cmap='gray')\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn',alpha=0.5)\n",
    "    plt.imshow(LesDict['contra'],cmap='winter',alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.imshow(LesDict['data'][...,0],cmap='gray')\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn',alpha=0.5)\n",
    "    plt.imshow(np.fliplr(LesDict['contra']),cmap='winter',alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn')\n",
    "    plt.imshow(LesDict['contra'],cmap='winter')\n",
    "    plt.imshow(LesDict['contra']*LesDict['lesion'],cmap='gray')\n",
    "    plt.show()\n",
    "    bin_les = LesDict['lesion'] == LesDict['lesion']\n",
    "    bin_con = LesDict['contra'] == LesDict['contra']\n",
    "    overlap = bin_les*bin_con\n",
    "    bin_les[overlap] = 0\n",
    "    bin_con[overlap] = 0\n",
    "\n",
    "    MatDir = MSDir+Name\n",
    "\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    gtabExt = gradient_table(bvals = bvals,bvecs = bvecs)\n",
    "\n",
    "    # Compute the mask where the sum is not zero\n",
    "    dat = LesDict['data']\n",
    "    mask = np.sum(dat[...,:69], axis=-1) != 0\n",
    "\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            samples = Network.sample((500,), x=DKIFeatures(gtabExt.bvecs[:],gtabExt.bvals[:],dat[i,j,:]),show_progress_bars=False)\n",
    "            results.append((i, j, samples.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "    for chunk in tqdm(results,position=0,leave=True):\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "    FA_SBIFull  = np.zeros(ArrShape)\n",
    "    MD_SBIFull  = np.zeros(ArrShape)        \n",
    "    MK_SBIFull  = np.zeros(ArrShape)\n",
    "    AK_SBIFull  = np.zeros(ArrShape)\n",
    "    RK_SBIFull  = np.zeros(ArrShape)\n",
    "    MKT_SBIFull = np.zeros(ArrShape)\n",
    "    KFA_SBIFull = np.zeros(ArrShape)\n",
    "    for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "        for j in range(ArrShape[1]):\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j][:6]))[0]\n",
    "            MD_SBIFull[i,j] = np.mean(Eigs)\n",
    "            FA_SBIFull[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "            MK_SBIFull[i,j] = Metrics[0]\n",
    "            AK_SBIFull[i,j] = Metrics[1]\n",
    "            RK_SBIFull[i,j] = Metrics[2]\n",
    "            MKT_SBIFull[i,j] = Metrics[3]\n",
    "            KFA_SBIFull[i,j] = Metrics[4]\n",
    "    KFA_SBIFull[np.isnan(KFA_SBIFull)] = 1\n",
    "\n",
    "    RK_arr.append([RK_SBIFull[bin_les],RK_SBIFull[bin_con]])\n",
    "    MK_arr.append([MK_SBIFull[bin_les],MK_SBIFull[bin_con]])\n",
    "    AK_arr.append([AK_SBIFull[bin_les],AK_SBIFull[bin_con]])\n",
    "    \n",
    "    MD_arr.append([MD_SBIFull[bin_les],MD_SBIFull[bin_con]])\n",
    "    FA_arr.append([FA_SBIFull[bin_les],FA_SBIFull[bin_con]])\n",
    "    plt.boxplot(RK_SBIFull[bin_les],positions=[0],showfliers=False)\n",
    "    plt.boxplot(RK_SBIFull[bin_con],positions=[1],showfliers=False)\n",
    "    print(stats.ttest_ind(RK_SBIFull[bin_les],RK_SBIFull[bin_con]))\n",
    "    plt.show()\n",
    "    plt.boxplot(MK_SBIFull[bin_les],positions=[0],showfliers=False)\n",
    "    plt.boxplot(MK_SBIFull[bin_con],positions=[1],showfliers=False)\n",
    "    print(stats.ttest_ind(MK_SBIFull[bin_les],MK_SBIFull[bin_con]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6849edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T11:25:04.209219Z",
     "start_time": "2025-12-28T11:25:04.163923Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_sig_bar(ax, x1, x2, y, h, text):\n",
    "    ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y],\n",
    "            lw=1, c='k')\n",
    "    ax.text((x1+x2)/2, y, text,\n",
    "            ha='center', va='center',fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd3d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:33:55.721962Z",
     "start_time": "2025-12-28T13:33:55.558083Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in MK_arr]\n",
    "con_RK = [R[1] for R in MK_arr]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,1.8,0.0,'*')\n",
    "add_sig_bar(ax,1.8,2,1.1,0.0,'*')\n",
    "add_sig_bar(ax,3.8,4,1,0.0,'*')\n",
    "ax.set_xticks([])\n",
    "\n",
    "leg_patch2 = mpatches.Patch(color='red', label='Lesion')\n",
    "leg_patch3 = mpatches.Patch(color='lightsalmon', label='Contralateral')\n",
    "\n",
    "ax.legend(\n",
    "    handles=[leg_patch2,leg_patch3],\n",
    "    loc='upper right',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=24,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(1.2,1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f7399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:34:22.186126Z",
     "start_time": "2025-12-28T13:34:22.022952Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in AK_arr]\n",
    "con_RK = [R[1] for R in AK_arr]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,1,0.0,'*')\n",
    "add_sig_bar(ax,1.8,2,0.95,0.0,'*')\n",
    "add_sig_bar(ax,3.8,4,0.87,0.0,'*')\n",
    "ax.set_xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a830a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:34:25.450162Z",
     "start_time": "2025-12-28T13:34:25.294280Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in RK_arr]\n",
    "con_RK = [R[1] for R in RK_arr]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,3.1,0.0,'*')\n",
    "add_sig_bar(ax,1.8,2,1.3,0.0,'*')\n",
    "add_sig_bar(ax,3.8,4,1.2,0.0,'*')\n",
    "ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc532a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T11:55:56.003203Z",
     "start_time": "2025-12-28T11:51:10.959445Z"
    }
   },
   "outputs": [],
   "source": [
    "MK_arr_Min = []\n",
    "AK_arr_Min = []\n",
    "RK_arr_Min = []\n",
    "FA_arr = []\n",
    "MD_arr = []\n",
    "for i,Name in tqdm(enumerate(['NMSS_11_1year','NMSS_15','NMSS_16','NMSS_18','NMSS_19'])):\n",
    "    with open(MSDir+Name+'/Les_dict.pkl', 'rb') as f:\n",
    "        LesDict = pickle.load(f)\n",
    "    plt.imshow(LesDict['data'][...,0],cmap='gray')\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn',alpha=0.5)\n",
    "    plt.imshow(LesDict['contra'],cmap='winter',alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.imshow(LesDict['data'][...,0],cmap='gray')\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn',alpha=0.5)\n",
    "    plt.imshow(np.fliplr(LesDict['contra']),cmap='winter',alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.imshow(LesDict['lesion'],cmap='autumn')\n",
    "    plt.imshow(LesDict['contra'],cmap='winter')\n",
    "    plt.imshow(LesDict['contra']*LesDict['lesion'],cmap='gray')\n",
    "    plt.show()\n",
    "    bin_les = LesDict['lesion'] == LesDict['lesion']\n",
    "    bin_con = LesDict['contra'] == LesDict['contra']\n",
    "    overlap = bin_les*bin_con\n",
    "    bin_les[overlap] = 0\n",
    "    bin_con[overlap] = 0\n",
    "\n",
    "    MatDir = MSDir+Name\n",
    "\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    gtabExt = gradient_table(bvals = bvals,bvecs = bvecs)\n",
    "\n",
    "    # Compute the mask where the sum is not zero\n",
    "    dat = LesDict['data']\n",
    "    mask = np.sum(dat[...,:69], axis=-1) != 0\n",
    "\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            samples = Network.sample((500,), x=DKIFeatures(gtabExt.bvecs[Indxs7],gtabExt.bvals[Indxs7],dat[i,j,Indxs7]),show_progress_bars=False)\n",
    "            results.append((i, j, samples.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in tqdm(chunked_indices,position=0,leave=True)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [22])\n",
    "    for chunk in tqdm(results,position=0,leave=True):\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,6:]])\n",
    "\n",
    "    ArrShape = mask.shape\n",
    "\n",
    "    FA_SBIMin  = np.zeros(ArrShape)\n",
    "    MD_SBIMin  = np.zeros(ArrShape)        \n",
    "    MK_SBIMin  = np.zeros(ArrShape)\n",
    "    AK_SBIMin  = np.zeros(ArrShape)\n",
    "    RK_SBIMin  = np.zeros(ArrShape)\n",
    "    MKT_SBIMin = np.zeros(ArrShape)\n",
    "    KFA_SBIMin = np.zeros(ArrShape)\n",
    "    for i in tqdm(range(ArrShape[0]),position=0,leave=True):\n",
    "        for j in range(ArrShape[1]):\n",
    "            Metrics = DKIMetrics(NoiseEst2[i,j][:6],NoiseEst2[i,j][6:21])\n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j][:6]))[0]\n",
    "            MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "            FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "            MK_SBIMin[i,j] = Metrics[0]\n",
    "            AK_SBIMin[i,j] = Metrics[1]\n",
    "            RK_SBIMin[i,j] = Metrics[2]\n",
    "            MKT_SBIMin[i,j] = Metrics[3]\n",
    "            KFA_SBIMin[i,j] = Metrics[4]\n",
    "    KFA_SBIMin[np.isnan(KFA_SBIMin)] = 1\n",
    "\n",
    "    RK_arr_Min.append([RK_SBIMin[bin_les],RK_SBIMin[bin_con]])\n",
    "    MK_arr_Min.append([MK_SBIMin[bin_les],MK_SBIMin[bin_con]])\n",
    "    AK_arr_Min.append([AK_SBIMin[bin_les],AK_SBIMin[bin_con]])\n",
    "    \n",
    "    MD_arr.append([MD_SBIMin[bin_les],MD_SBIMin[bin_con]])\n",
    "    FA_arr.append([FA_SBIMin[bin_les],FA_SBIMin[bin_con]])\n",
    "    plt.boxplot(RK_SBIMin[bin_les],positions=[0],showfliers=False)\n",
    "    plt.boxplot(RK_SBIMin[bin_con],positions=[1],showfliers=False)\n",
    "    print(stats.ttest_ind(RK_SBIMin[bin_les],RK_SBIMin[bin_con]))\n",
    "    plt.show()\n",
    "    plt.boxplot(MK_SBIMin[bin_les],positions=[0],showfliers=False)\n",
    "    plt.boxplot(MK_SBIMin[bin_con],positions=[1],showfliers=False)\n",
    "    print(stats.ttest_ind(MK_SBIMin[bin_les],MK_SBIMin[bin_con]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4360c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T13:33:33.510320Z",
     "start_time": "2025-12-17T13:33:33.461301Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_sig_bar(ax, x1, x2, y, h1,h2, text):\n",
    "    ax.plot([x1, x1, x2, x2], [y-h1, y, y, y-h2],\n",
    "            lw=1, c='k')\n",
    "    ax.text((x1+x2)/2, y, text,\n",
    "            ha='center', va='center',fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f4b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:34:30.798722Z",
     "start_time": "2025-12-28T13:34:30.642360Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in MK_arr_Min]\n",
    "con_RK = [R[1] for R in MK_arr_Min]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,1.3,0.,'*')\n",
    "add_sig_bar(ax,1.8,2,1.05,0.,'*')\n",
    "add_sig_bar(ax,3.8,4.,1.07,0.,'*')\n",
    "ax.set_xticks([])\n",
    "\n",
    "leg_patch2 = mpatches.Patch(color='mediumturquoise', label='Lesion')\n",
    "leg_patch3 = mpatches.Patch(color='sandybrown', label='Contralateral')\n",
    "\n",
    "ax.set_yticks([0.3,0.6,0.9,1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e18ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:34:33.539369Z",
     "start_time": "2025-12-28T13:34:33.372045Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in AK_arr_Min]\n",
    "con_RK = [R[1] for R in AK_arr_Min]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,0.9,0.0,'*')\n",
    "add_sig_bar(ax,1.8,2,0.95,0.0,'*')\n",
    "add_sig_bar(ax,3.8,4,0.9,0.0,'*')\n",
    "ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafc10f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:34:36.478469Z",
     "start_time": "2025-12-28T13:34:36.300186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in RK_arr_Min]\n",
    "con_RK = [R[1] for R in RK_arr_Min]\n",
    "# Plotting on ax1\n",
    "ps = []\n",
    "for i,(l1,l2) in enumerate(zip(les_RK,con_RK)):\n",
    "    plt.sca(ax)\n",
    "    y_data = l1\n",
    "    g_pos = np.array([0.8+1*i])\n",
    "    colors = ['red']\n",
    "    colors2 = ['tomato']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    \n",
    "    y_data = l2\n",
    "    g_pos = np.array([1 +1*i])\n",
    "    colors = ['lightsalmon']\n",
    "    colors2 = ['mistyrose']\n",
    "\n",
    "    BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "    ps.append(stats.mannwhitneyu(l1,l2).pvalue)\n",
    "add_sig_bar(ax,0.8,1,1.9,0.0,'*')\n",
    "add_sig_bar(ax,1.8,2,1.3,0.0,'*')\n",
    "add_sig_bar(ax,3.8,4,1.3,0.0,'*')\n",
    "ax.set_xticks([])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4fd9f",
   "metadata": {},
   "source": [
    "## j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14313fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T17:04:25.375258Z",
     "start_time": "2025-12-28T17:04:25.250827Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2.8,4.8))#, sharex=True)\n",
    "les_RK = [R[0] for R in MK_arr]\n",
    "con_RK = [R[1] for R in MK_arr]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([0.])\n",
    "colors = ['black']\n",
    "colors2 = ['dimgrey']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "les_RK = [R[0] for R in MK_arr_Min]\n",
    "con_RK = [R[1] for R in MK_arr_Min]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([0.2])\n",
    "colors = ['gray']\n",
    "colors2 = ['silver']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "les_RK = [R[0] for R in AK_arr]\n",
    "con_RK = [R[1] for R in AK_arr]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([1.])\n",
    "colors = ['black']\n",
    "colors2 = ['dimgrey']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "les_RK = [R[0] for R in AK_arr_Min]\n",
    "con_RK = [R[1] for R in AK_arr_Min]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([1.2])\n",
    "colors = ['gray']\n",
    "colors2 = ['silver']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "les_RK = [R[0] for R in RK_arr]\n",
    "con_RK = [R[1] for R in RK_arr]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([2.])\n",
    "colors = ['black']\n",
    "colors2 = ['dimgrey']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "les_RK = [R[0] for R in RK_arr_Min]\n",
    "con_RK = [R[1] for R in RK_arr_Min]\n",
    "y_data = np.array([(np.mean(lK)-np.mean(cK))/(np.mean(lK)+np.mean(cK)) for lK,cK in zip(les_RK,con_RK)])\n",
    "g_pos = np.array([2.2])\n",
    "colors = ['gray']\n",
    "colors2 = ['silver']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "plt.xticks([0.1,1.1,2.1],['MK','RK','AK'])\n",
    "plt.yticks([-0.1,0])\n",
    "\n",
    "leg_patch2 = mpatches.Patch(color='black', label='Full')\n",
    "leg_patch3 = mpatches.Patch(color='gray', label='Min')\n",
    "\n",
    "ax.legend(\n",
    "    handles=[leg_patch3,leg_patch2],\n",
    "    loc='lower left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=24,columnspacing=0.3,labelspacing=0.1,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(0.15,-0.08))\n",
    "plt.axhline(0,ls='--',c='k',lw='2')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "965px",
    "left": "22px",
    "top": "185px",
    "width": "495.948px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
