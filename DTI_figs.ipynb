{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdca995",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51837c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:20:40.272968Z",
     "start_time": "2025-12-28T23:20:37.449108Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DTI_funcs import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ffbdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:20:41.107053Z",
     "start_time": "2025-12-28T23:20:41.056911Z"
    }
   },
   "outputs": [],
   "source": [
    "Save = False\n",
    "\n",
    "InferSamples = 1000\n",
    "TestSamples = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2793fa",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624b875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:20:43.351823Z",
     "start_time": "2025-12-28T23:20:43.304218Z"
    }
   },
   "outputs": [],
   "source": [
    "fdwi = HCPDir + '/Pat'+str(1)+'/diff_1k.nii.gz'\n",
    "bvalloc = HCPDir + '/Pat'+str(1)+'/bvals_1k.txt'\n",
    "bvecloc = HCPDir + '/Pat'+str(1)+'/bvecs_1k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvals = bvalsHCP, bvecs = bvecsHCP)\n",
    "\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(5):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "selected_indices = [0]+selected_indices\n",
    "\n",
    "bvalsHCP7 = bvalsHCP[selected_indices]\n",
    "bvecsHCP7 = bvecsHCP[selected_indices]\n",
    "gtabHCP7 = gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0ab37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:20:46.224643Z",
     "start_time": "2025-12-28T23:20:46.170034Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(NetworkDir+\"DTI_Network.pickle\"):\n",
    "    with open(NetworkDir+\"DTI_Network.pickle\", \"rb\") as handle:\n",
    "        Network = pickle.load(handle)\n",
    "        print('loaded')\n",
    "else:\n",
    "    TrainingSamples = 1_000_000\n",
    "    Obs = []\n",
    "    Par = []\n",
    "    D_prior = []\n",
    "    MD_prior = np.random.rand(int(TrainingSamples))*0.005\n",
    "    FA_prior = np.random.rand(TrainingSamples)*0.999\n",
    "    S0_prior = np.random.uniform(20,2500,TrainingSamples)\n",
    "    \n",
    "    R1 = (np.ones(int(TrainingSamples*0.8))*6).astype(int)\n",
    "    R2 = np.random.choice(np.arange(6,68),int(TrainingSamples*0.2))\n",
    "    \n",
    "    R = [np.insert(np.random.choice(np.arange(1,69),r,replace=False),0,0) for r in np.hstack([R1,R2])]\n",
    "    bval_choice = np.random.choice([1,2],TrainingSamples,replace=True)\n",
    "    \n",
    "    for m,f,r,S,bv in tqdm(zip(MD_prior,FA_prior,R,S0_prior,bval_choice),position=0,leave=True):\n",
    "        dt = random_diffusion_tensor(m, f)\n",
    "        D_prior.append(mat_to_vals(dt))\n",
    "        gtab = gradient_table(bvals = gtabHCP.bvals[r]*bv,bvecs = gtabHCP.bvecs[r])\n",
    "        a = 50#N\n",
    "        Obs.append(DTIFeatures(gtab.bvecs,gtab.bvals,CustomSimulator(dt,gtab,S,a)))\n",
    "        Par.append(np.hstack([mat_to_vals(dt),S]))\n",
    "\n",
    "    Obs = np.array(Obs)\n",
    "    Par = np.array(Par)\n",
    "    Obs= torch.tensor(Obs).float()\n",
    "    Par= torch.tensor(Par).float()\n",
    "\n",
    "    # Create inference object. Here, NPE is used.\n",
    "    inference = SNPE(device='mps')\n",
    "\n",
    "    # generate simulations and pass to the inference object\n",
    "    inference = inference.append_simulations(Par, Obs,data_device='cpu')\n",
    "\n",
    "    # train the density estim ator and build the posterior\n",
    "    density_estimator = inference.train(training_batch_size = 512)\n",
    "    low = torch.tensor([\n",
    "        *[-1e-2,-5e-3,-1e-2,-5e-3,-5e-3,-1e-2,0],    # dhind (6)\n",
    "    ])\n",
    "    high = torch.tensor([\n",
    "        *[1e-2,5e-3,1e-2,5e-3,5e-3,1e-2,3000],    # dhind (6)\n",
    "    ])\n",
    "\n",
    "    prior_bounds = BoxUniform(low=low, high=high)\n",
    "    Network = DirectPosterior(density_estimator.cpu(), prior=prior_bounds)\n",
    "    if not os.path.exists(NetworkDir+\"DTI_Network.pickle\"):\n",
    "        with open(NetworkDir+\"DTI_Network.pickle\", \"wb\") as handle:\n",
    "            pickle.dump(Network, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a97966",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c332b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T17:40:24.527467Z",
     "start_time": "2025-12-23T17:40:24.498245Z"
    }
   },
   "outputs": [],
   "source": [
    "fdwi = HCPDir + '/Pat'+str(1)+'/diff_1k.nii.gz'\n",
    "bvalloc = HCPDir + '/Pat'+str(1)+'/bvals_1k.txt'\n",
    "bvecloc = HCPDir + '/Pat'+str(1)+'/bvecs_1k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvals = bvalsHCP, bvecs = bvecsHCP)\n",
    "\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(5):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "selected_indices = [0]+selected_indices\n",
    "\n",
    "bvalsHCP7 = bvalsHCP[selected_indices]\n",
    "bvecsHCP7 = bvecsHCP[selected_indices]\n",
    "gtabHCP7 = gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33be2b",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8254491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T17:40:29.560759Z",
     "start_time": "2025-12-23T17:40:29.533606Z"
    }
   },
   "outputs": [],
   "source": [
    "MD_truth = 0.001\n",
    "FA_truth = 0.5\n",
    "dtTruth = random_diffusion_tensor(MD_truth, FA_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216510d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T17:40:33.115224Z",
     "start_time": "2025-12-23T17:40:33.081561Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "Truth = CustomSimulator(dtTruth,gtabHCP, S0=200,snr=None)\n",
    "SNR = [CustomSimulator(dtTruth,gtabHCP, S0=200,snr=scale) for scale in [20,10,5,2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64df177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T17:40:43.376636Z",
     "start_time": "2025-12-23T17:40:43.289659Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(Truth,'k',lw=2,label='True signal')\n",
    "plt.plot(SNR[0],'gray',lw=2,ls='--',label='Noisy signal')\n",
    "plt.axis('off')\n",
    "legend= plt.legend(ncols=2,loc=1,bbox_to_anchor =  (1.03,1.7),fontsize=26,columnspacing=0.3,handlelength=0.4,handletextpad=0.1)\n",
    "for handle in legend.get_lines():\n",
    "    handle.set_linewidth(6)  # Set desired linewidth\n",
    "plt.show()\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(Truth,'k',lw=2)\n",
    "plt.plot(SNR[1],'gray',lw=2,ls='--')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(Truth,'k',lw=2)\n",
    "plt.plot(SNR[2],'gray',lw=2,ls='--')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.subplots(figsize=(6,1))\n",
    "plt.plot(Truth,'k',lw=2)\n",
    "plt.plot(SNR[3],'gray',lw=2,ls='--')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c22085",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae2f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T17:40:45.805830Z",
     "start_time": "2025-12-23T17:40:45.559607Z"
    }
   },
   "outputs": [],
   "source": [
    "SNR20 = np.vstack([CustomSimulator(dtTruth,gtabHCP, S0=200,snr=20) for k in range(200)])\n",
    "SNR10 = np.vstack([CustomSimulator(dtTruth,gtabHCP, S0=200,snr=10) for k in range(200)])\n",
    "SNR5 = np.vstack([CustomSimulator(dtTruth,gtabHCP, S0=200,snr=5) for k in range(200)])\n",
    "SNR2 = np.vstack([CustomSimulator(dtTruth,gtabHCP, S0=200,snr=2) for k in range(200)])\n",
    "\n",
    "tenmodel = dti.TensorModel(gtabHCP,return_S0_hat = True,fit_method='NLLS')\n",
    "tenfit = tenmodel.fit(SNR20)\n",
    "FA20 = dti.fractional_anisotropy(tenfit.evals)\n",
    "MD20 = dti.mean_diffusivity(tenfit.evals)\n",
    "tenfit = tenmodel.fit(SNR10)\n",
    "FA10 = dti.fractional_anisotropy(tenfit.evals)\n",
    "MD10 = dti.mean_diffusivity(tenfit.evals)\n",
    "tenfit = tenmodel.fit(SNR5)\n",
    "FA5 = dti.fractional_anisotropy(tenfit.evals)\n",
    "MD5 = dti.mean_diffusivity(tenfit.evals)\n",
    "tenfit = tenmodel.fit(SNR2)\n",
    "FA2 = dti.fractional_anisotropy(tenfit.evals)\n",
    "MD2 = dti.mean_diffusivity(tenfit.evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bb723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:34:53.497918Z",
     "start_time": "2025-12-22T09:34:12.821834Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "gtab = gtabHCP\n",
    "MD20_SBI = []\n",
    "FA20_SBI = []\n",
    "for S in tqdm(SNR20,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,S),show_progress_bars=False)\n",
    "    X = np.array([MD_FA(vals_to_mat(p)) for p in posterior_samples_1])\n",
    "    MD,FA = np.mean(X,axis=0)\n",
    "    MD20_SBI.append(MD)\n",
    "    FA20_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD10_SBI = []\n",
    "FA10_SBI = []\n",
    "for S in tqdm(SNR10,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,S),show_progress_bars=False)\n",
    "    X = np.array([MD_FA(vals_to_mat(p)) for p in posterior_samples_1])\n",
    "    MD,FA = np.mean(X,axis=0)\n",
    "    MD10_SBI.append(MD)\n",
    "    FA10_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD5_SBI = []\n",
    "\n",
    "\n",
    "FA5_SBI = []\n",
    "for S in tqdm(SNR5,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,S),show_progress_bars=False)\n",
    "    X = np.array([MD_FA(vals_to_mat(p)) for p in posterior_samples_1])\n",
    "    MD,FA = np.mean(X,axis=0)\n",
    "    MD5_SBI.append(MD)\n",
    "    FA5_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD2_SBI = []\n",
    "FA2_SBI = []\n",
    "for S in tqdm(SNR2,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,S),show_progress_bars=False)\n",
    "    X = np.array([MD_FA(vals_to_mat(p)) for p in posterior_samples_1])\n",
    "    MD,FA = np.mean(X,axis=0)\n",
    "    MD2_SBI.append(MD)\n",
    "    FA2_SBI.append(FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68585efb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:35:14.079764Z",
     "start_time": "2025-12-22T09:34:53.499410Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "gtab = gtabHCP\n",
    "MD20_SBI = []\n",
    "FA20_SBI = []\n",
    "for S in tqdm(SNR20,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,S),show_progress_bars=False)\n",
    "    mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "    mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "    MD,FA = MD_FA(mat_guess)\n",
    "    MD20_SBI.append(MD)\n",
    "    FA20_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD10_SBI = []\n",
    "FA10_SBI = []\n",
    "for S in tqdm(SNR10,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,S),show_progress_bars=False)\n",
    "    mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "    mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "    MD,FA = MD_FA(mat_guess)\n",
    "    MD10_SBI.append(MD)\n",
    "    FA10_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD5_SBI = []\n",
    "\n",
    "\n",
    "FA5_SBI = []\n",
    "for S in tqdm(SNR5,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,S),show_progress_bars=False)\n",
    "    mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "    mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "    MD,FA = MD_FA(mat_guess)\n",
    "    MD5_SBI.append(MD)\n",
    "    FA5_SBI.append(FA)\n",
    "\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "MD2_SBI = []\n",
    "FA2_SBI = []\n",
    "for S in tqdm(SNR2,position=0,leave=True):\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,S),show_progress_bars=False)\n",
    "    mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "    mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "    MD,FA = MD_FA(mat_guess)\n",
    "    MD2_SBI.append(MD)\n",
    "    FA2_SBI.append(FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512fe8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:35:17.803716Z",
     "start_time": "2025-12-22T09:35:17.667489Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6.4,2.4))\n",
    "y_data = np.array([MD20_SBI,MD10_SBI,MD5_SBI,MD2_SBI])\n",
    "g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "\n",
    "colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "g_pos = np.array([1,2,3,4])\n",
    "colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "y_data = np.array([MD20,MD10,MD5,MD2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "l = plt.axhline(MD_truth,c='k',lw=3,ls='--',label='True MD')\n",
    "plt.xticks([])\n",
    "\n",
    "leg_patch2 = mpatches.Patch(color='sandybrown', label='NLLS Fit')\n",
    "ax.legend(\n",
    "    handles=[leg_patch2],\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(0,0.5))\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks([0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547f488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:39:37.722750Z",
     "start_time": "2025-12-11T13:39:37.617790Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6.4,2.4))\n",
    "y_data = np.array([MD20_SBI,MD10_SBI,MD5_SBI,MD2_SBI])\n",
    "g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "\n",
    "colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "g_pos = np.array([1,2,3,4])\n",
    "colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "y_data = np.array([MD20,MD10,MD5,MD2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "l = plt.axhline(MD_truth,c='k',lw=3,ls='--',label='True MD')\n",
    "plt.xticks([])\n",
    "\n",
    "leg_patch2 = mpatches.Patch(color='sandybrown', label='NLLS Fit')\n",
    "ax.legend(\n",
    "    handles=[leg_patch2],\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(0,0.5))\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks([0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323f0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:39:44.938595Z",
     "start_time": "2025-12-11T13:39:44.831222Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6.4,2.4))\n",
    "y_data = np.array([FA20_SBI,FA10_SBI,FA5_SBI,FA2_SBI])\n",
    "g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "\n",
    "colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "g_pos = np.array([1,2,3,4])\n",
    "colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "y_data = np.array([FA20,FA10,FA5,FA2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "l = plt.axhline(FA_truth,c='k',lw=3,ls='--',label='True FA')\n",
    "plt.xticks([1,2,3,4],[20,10,5,2],fontsize=28)\n",
    "plt.xticks(fontsize=28)\n",
    "#plt.xlabel('SNR',fontsize=32)\n",
    "#plt.ylabel('FA',fontsize=32)\n",
    "leg_patch1 = mpatches.Patch(color='lightseagreen', label='SBI Fit')\n",
    "leg_patch2 = mpatches.Patch(color='sandybrown', label='NLLS Fit')\n",
    "ax.legend(\n",
    "    handles=[leg_patch1],\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(0,0.5))\n",
    "plt.yticks([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1efa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:39:09.072227Z",
     "start_time": "2025-12-11T13:39:08.963150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6.4,2.4))\n",
    "y_data = np.array([FA20_SBI,FA10_SBI,FA5_SBI,FA2_SBI])\n",
    "g_pos = np.array([1.3,2.3,3.3,4.3])\n",
    "\n",
    "colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "g_pos = np.array([1,2,3,4])\n",
    "colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "y_data = np.array([FA20,FA10,FA5,FA2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.3,scatter=True)\n",
    "\n",
    "l = plt.axhline(FA_truth,c='k',lw=3,ls='--',label='True FA')\n",
    "plt.xticks([1,2,3,4],[20,10,5,2],fontsize=28)\n",
    "plt.xticks(fontsize=28)\n",
    "#plt.xlabel('SNR',fontsize=32)\n",
    "#plt.ylabel('FA',fontsize=32)\n",
    "leg_patch1 = mpatches.Patch(color='lightseagreen', label='SBI Fit')\n",
    "leg_patch2 = mpatches.Patch(color='sandybrown', label='NLLS Fit')\n",
    "ax.legend(\n",
    "    handles=[leg_patch1],\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor=(0,0.5))\n",
    "plt.yticks([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7a9bb",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d852f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:49:18.658225Z",
     "start_time": "2025-12-22T09:48:33.733350Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(9,3))\n",
    "r = np.insert(np.random.choice(np.arange(1,69),68,replace=False),0,0)\n",
    "gtab = gtabHCP\n",
    "torch.manual_seed(10)\n",
    "for i,kk in enumerate([20,10,5,2]):\n",
    "    np.random.seed(10)\n",
    "    print('---Starting process---')\n",
    "    D_prior = []\n",
    "    MD_prior = np.random.uniform(0.0005,0.003,TestSamples)\n",
    "    FA_prior = np.random.rand(TestSamples)*0.999\n",
    "    S0_prior = np.ones(TestSamples)*200\n",
    "    Noise_prior = np.ones(TestSamples)*kk\n",
    "\n",
    "    print('---Generating observations and parameters---')\n",
    "    D_prior  = [random_diffusion_tensor(m, f) for m,f in zip(MD_prior,FA_prior)]\n",
    "    \n",
    "    Obs_test  = np.array([CustomSimulator(dt,gtab,S,n) for dt,S,n in zip(D_prior,S0_prior,Noise_prior)])\n",
    "    Pars_test = np.column_stack([mat_to_vals(dt) for dt in D_prior]).T\n",
    "    True_MD_FA = np.array([MD_FA(vals_to_mat(P)) for P in Pars_test]).T\n",
    "\n",
    "    #NLLSFIt\n",
    "    tenmodel = dti.TensorModel(gtab,fit_method='NLLS')\n",
    "    NLLSFit = tenmodel.fit(Obs_test)\n",
    "    MD_FA_NLLS = np.array([NLLSFit.md,NLLSFit.fa])\n",
    "\n",
    "    MD_FA_SBI= []\n",
    "    for O in tqdm(Obs_test,position=0,leave=True):\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,O),show_progress_bars=False)\n",
    "        MD,FA = np.array([MD_FA(vals_to_mat(p)) for p in posterior_samples_1]).mean(axis=0)\n",
    "        MD_FA_SBI.append([MD,FA])\n",
    "    MD_FA_SBI = np.array(MD_FA_SBI).T\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    #x[0].set_ylim([0,0.004])\n",
    "    ax[1].set_ylim([0,1])\n",
    "    ax[0].yaxis.grid(True)\n",
    "    ax[1].yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "for ll,a in enumerate(ax):\n",
    "    plt.sca(a)\n",
    "    plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "    plt.yticks(fontsize=32)\n",
    "    plt.xticks([1.15, 2.15, 3.15, 4.15,], [20,10,5,2],fontsize=32)\n",
    "    if(ll==0):\n",
    "        handles = [\n",
    "            Line2D([0], [0], color=SBIFit, lw=4, label='SBI'),  # Adjust color as per the actual plot color\n",
    "        ]\n",
    "        # Add the legenda\n",
    "        plt.legend(handles=handles,loc=2, bbox_to_anchor=(0,1.15),\n",
    "                   fontsize=36,columnspacing=0.3,handlelength=0.6,handletextpad=0.3)\n",
    "        plt.ylim([np.float64(-0.00025242580421944123), np.float64(0.005317867177548843)])\n",
    "    if(ll==1):\n",
    "        handles = [\n",
    "            Line2D([0], [0], color=WLSFit, lw=4, label='NLLS'),  # Adjust color as per the actual plot color\n",
    "        ]\n",
    "        # Add the legenda\n",
    "        plt.legend(handles=handles,loc=2, bbox_to_anchor=(0,1.15),\n",
    "                   fontsize=36,columnspacing=0.3,handlelength=0.6,handletextpad=0.3)\n",
    "        plt.ylim([-0.05,1])\n",
    "        plt.yticks([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed2cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:44:56.619190Z",
     "start_time": "2025-12-22T09:44:34.380948Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(9,3))\n",
    "r = np.insert(np.random.choice(np.arange(1,69),68,replace=False),0,0)\n",
    "gtab = gtabHCP\n",
    "torch.manual_seed(10)\n",
    "for i,kk in enumerate([20,10,5,2]):\n",
    "    np.random.seed(10)\n",
    "    print('---Starting process---')\n",
    "    D_prior = []\n",
    "    MD_prior = np.random.uniform(0.0005,0.003,TestSamples)\n",
    "    FA_prior = np.random.rand(TestSamples)*0.999\n",
    "    S0_prior = np.ones(TestSamples)*200\n",
    "    Noise_prior = np.ones(TestSamples)*kk\n",
    "\n",
    "    print('---Generating observations and parameters---')\n",
    "    D_prior  = [random_diffusion_tensor(m, f) for m,f in zip(MD_prior,FA_prior)]\n",
    "    \n",
    "    Obs_test  = np.array([CustomSimulator(dt,gtab,S,n) for dt,S,n in zip(D_prior,S0_prior,Noise_prior)])\n",
    "    Pars_test = np.column_stack([mat_to_vals(dt) for dt in D_prior]).T\n",
    "    True_MD_FA = np.array([MD_FA(vals_to_mat(P)) for P in Pars_test]).T\n",
    "\n",
    "    #NLLSFIt\n",
    "    tenmodel = dti.TensorModel(gtab,fit_method='NLLS')\n",
    "    NLLSFit = tenmodel.fit(Obs_test)\n",
    "    MD_FA_NLLS = np.array([NLLSFit.md,NLLSFit.fa])\n",
    "\n",
    "    MD_FA_SBI= []\n",
    "    for O in tqdm(Obs_test,position=0,leave=True):\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,O),show_progress_bars=False)\n",
    "        mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "        mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "        MD,FA = MD_FA(mat_guess)\n",
    "        MD_FA_SBI.append([MD,FA])\n",
    "    MD_FA_SBI = np.array(MD_FA_SBI).T\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    #x[0].set_ylim([0,0.004])\n",
    "    ax[1].set_ylim([0,1])\n",
    "    ax[0].yaxis.grid(True)\n",
    "    ax[1].yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "for ll,a in enumerate(ax):\n",
    "    plt.sca(a)\n",
    "    plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "    plt.yticks(fontsize=32)\n",
    "    plt.xticks([1.15, 2.15, 3.15, 4.15,], [20,10,5,2],fontsize=32)\n",
    "    if(ll==0):\n",
    "        handles = [\n",
    "            Line2D([0], [0], color=SBIFit, lw=4, label='SBI'),  # Adjust color as per the actual plot color\n",
    "        ]\n",
    "        # Add the legenda\n",
    "        plt.legend(handles=handles,loc=2, bbox_to_anchor=(0,1.15),\n",
    "                   fontsize=36,columnspacing=0.3,handlelength=0.6,handletextpad=0.3)\n",
    "        plt.ylim([np.float64(-0.00025242580421944123), np.float64(0.005317867177548843)])\n",
    "    if(ll==1):\n",
    "        handles = [\n",
    "            Line2D([0], [0], color=WLSFit, lw=4, label='NLLS'),  # Adjust color as per the actual plot color\n",
    "        ]\n",
    "        # Add the legenda\n",
    "        plt.legend(handles=handles,loc=2, bbox_to_anchor=(0,1.15),\n",
    "                   fontsize=36,columnspacing=0.3,handlelength=0.6,handletextpad=0.3)\n",
    "        plt.ylim([-0.05,1])\n",
    "        plt.yticks([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d21ffe",
   "metadata": {},
   "source": [
    "## d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f8629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T12:35:01.394145Z",
     "start_time": "2025-12-10T12:34:19.545917Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(9,3))\n",
    "r = np.insert(np.random.choice(np.arange(1,69),68,replace=False),0,0)\n",
    "gtab = gtabHCP7\n",
    "torch.manual_seed(10)\n",
    "for i,kk in enumerate([20,10,5,2]):\n",
    "    np.random.seed(10)\n",
    "    print('---Starting process---')\n",
    "    D_prior = []\n",
    "    MD_prior = np.random.uniform(0.0005,0.003,TestSamples)\n",
    "    FA_prior = np.random.rand(TestSamples)*0.999\n",
    "    S0_prior = np.ones(TestSamples)*200\n",
    "    Noise_prior = np.ones(TestSamples)*kk\n",
    "\n",
    "    print('---Generating observations and parameters---')\n",
    "    D_prior  = [random_diffusion_tensor(m, f) for m,f in zip(MD_prior,FA_prior)]\n",
    "    \n",
    "    Obs_test  = np.array([CustomSimulator(dt,gtab,S,n) for dt,S,n in zip(D_prior,S0_prior,Noise_prior)])\n",
    "    Pars_test = np.column_stack([mat_to_vals(dt) for dt in D_prior]).T\n",
    "    True_MD_FA = np.array([MD_FA(vals_to_mat(P)) for P in Pars_test]).T\n",
    "\n",
    "    #NLLSFIt\n",
    "    tenmodel = dti.TensorModel(gtab,fit_method='NLLS')\n",
    "    NLLSFit = tenmodel.fit(Obs_test)\n",
    "    MD_FA_NLLS = np.array([NLLSFit.md,NLLSFit.fa])\n",
    "\n",
    "    MD_FA_SBI= []\n",
    "    for O in tqdm(Obs_test,position=0,leave=True):\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,O),show_progress_bars=False)\n",
    "        mat_guess = vals_to_mat(posterior_samples_1.mean(axis=0))\n",
    "        mat_guess = clip_negative_eigenvalues(mat_guess)\n",
    "        MD,FA = MD_FA(mat_guess)\n",
    "        MD_FA_SBI.append([MD,FA])\n",
    "    MD_FA_SBI = np.array(MD_FA_SBI).T\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[0,:]-True_MD_FA[0,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[0],widths=0.3,scatter=False)\n",
    "\n",
    "    y_data = abs(MD_FA_SBI[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1.3 + i])\n",
    "    colors = ['lightseagreen','lightseagreen','lightseagreen','lightseagreen']\n",
    "    colors2 = ['paleturquoise','paleturquoise','paleturquoise','paleturquoise']\n",
    "\n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    y_data = abs(MD_FA_NLLS[1,:]-True_MD_FA[1,:])\n",
    "    g_pos = np.array([1+i])\n",
    "    colors = ['sandybrown','sandybrown','sandybrown','sandybrown']\n",
    "    colors2 = ['peachpuff','peachpuff','peachpuff','peachpuff']\n",
    "    \n",
    "    BoxPlots(y_data.T,g_pos,colors,colors2,ax[1],widths=0.3,scatter=False)\n",
    "    \n",
    "    #x[0].set_ylim([0,0.004])\n",
    "    ax[1].set_ylim([0,1])\n",
    "    ax[0].yaxis.grid(True)\n",
    "    ax[1].yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "for ll,a in enumerate(ax):\n",
    "    plt.sca(a)\n",
    "    plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "    plt.yticks(fontsize=32)\n",
    "    plt.xticks([1.15, 2.15, 3.15, 4.15,], [20,10,5,2],fontsize=32)\n",
    "    if(ll==0):\n",
    "        plt.ylim([np.float64(-0.00025242580421944123), np.float64(0.005317867177548843)])\n",
    "    if(ll==1):\n",
    "        plt.ylim([-0.05,1])\n",
    "        plt.yticks([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0727cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T11:54:37.374437Z",
     "start_time": "2025-11-05T11:54:37.325114Z"
    }
   },
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b7fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T13:54:20.274304Z",
     "start_time": "2025-12-22T13:54:14.142632Z"
    }
   },
   "outputs": [],
   "source": [
    "fdwi = '../../HCP_data/Pat'+str(1)+'/diff_1k.nii.gz'\n",
    "\n",
    "data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "data, affine = reslice(data, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "floor = np.clip(data.min(axis=-1),-np.inf,0)\n",
    "data2 = data + abs(floor)[:,:,:,None] + 1e-5\n",
    "axial_middle = data2.shape[2] // 2\n",
    "maskdata, mask = median_otsu(data2, vol_idx=range(10, 50), median_radius=3,\n",
    "                             numpass=1, autocrop=True, dilate=2)\n",
    "mask_cutout = np.copy(mask[:,:,axial_middle])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59e67d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:10:51.473095Z",
     "start_time": "2025-12-10T14:10:37.722437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(maskdata[:, :, axial_middle, :], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "# Define the function for optimization\n",
    "def optimize_pixel(i, j):\n",
    "    torch.manual_seed(10)  # If required\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,maskdata[i, j,axial_middle, :]),show_progress_bars=False)\n",
    "    return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "# Initialize array with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "print('start')\n",
    "# Use joblib to parallelize the optimization tasks\n",
    "results = Parallel(n_jobs=24)(\n",
    "    delayed(optimize_pixel)(i, j) for i, j in tqdm(indices,position=0,leave=True)\n",
    ")\n",
    "print('end')\n",
    "\n",
    "InferredParams = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "# Assign the optimization results to InferredParams\n",
    "for i, j, x in results:\n",
    "    InferredParams[i, j] = x\n",
    "    \n",
    "MD_SBIFull = np.zeros([55,64])\n",
    "FA_SBIFull = np.zeros([55,64])\n",
    "for i in range(55):\n",
    "    for j in range(64):\n",
    "        Eigs = np.linalg.eigh(vals_to_mat(InferredParams[i,j,:6]))[0]\n",
    "        MD_SBIFull[i,j] = np.mean(Eigs)\n",
    "        FA_SBIFull[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "FA_SBIFull[np.isnan(FA_SBIFull )] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca1913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:10:53.472506Z",
     "start_time": "2025-12-10T14:10:53.210160Z"
    }
   },
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtabHCP,return_S0_hat = True,fit_method='NLLS')\n",
    "tenfit = tenmodel.fit(maskdata[:,:,axial_middle,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed22ab1",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86cb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:11:08.698993Z",
     "start_time": "2025-12-10T14:11:08.614411Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MD_SBIFull)\n",
    "\n",
    "temp[~mask_cutout] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf8de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:11:17.803804Z",
     "start_time": "2025-12-10T14:11:17.690316Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(tenfit.md)\n",
    "\n",
    "temp[~mask_cutout] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "vmin, vmax = img.get_clim()\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce069d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:11:19.206932Z",
     "start_time": "2025-12-10T14:11:19.096435Z"
    }
   },
   "outputs": [],
   "source": [
    "data = MD_SBIFull.T-tenfit.md.T\n",
    "data[~mask_cutout.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=np.nanmin(data), vcenter=0, vmax=np.nanmax(data))\n",
    "plt.imshow(data,cmap='seismic',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "ticks = [np.nanmin(data), 0, np.nanmax(data)]  # Adjust the number of ticks as needed\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb5394",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da2efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:11:35.372101Z",
     "start_time": "2025-12-10T14:11:35.285927Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(FA_SBIFull)\n",
    "\n",
    "temp[~mask_cutout] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "vmin, vmax = img.get_clim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2d1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:13:43.228897Z",
     "start_time": "2025-12-10T14:13:43.118001Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(tenfit.fa)\n",
    "\n",
    "temp[~mask_cutout] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "vmin, vmax = img.get_clim()\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.set_ticks([0,0.2,0.4,0.6,0.8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b7e4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:11:38.388820Z",
     "start_time": "2025-12-10T14:11:38.285908Z"
    }
   },
   "outputs": [],
   "source": [
    "data = FA_SBIFull.T-tenfit.fa.T\n",
    "data[~mask_cutout.T] = np.nan\n",
    "plt.imshow(data,cmap='seismic',vmin=-1, vmax=1)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "ticks = [-1, 0, 1]  # Adjust the number of ticks as needed\n",
    "cbar.set_ticks(ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095feec",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2bb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:05.899272Z",
     "start_time": "2025-12-10T14:11:43.571498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(maskdata[:, :, axial_middle, :], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "# Define the function for optimization\n",
    "def optimize_pixel(i, j):\n",
    "    torch.manual_seed(10)  # If required\n",
    "    posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtabHCP7.bvecs,gtabHCP7.bvals,maskdata[i, j,axial_middle, selected_indices]),show_progress_bars=False)\n",
    "    return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "# Initialize array with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "print('start')\n",
    "# Use joblib to parallelize the optimization tasks\n",
    "results = Parallel(n_jobs=24)(\n",
    "    delayed(optimize_pixel)(i, j) for i, j in tqdm(indices,position=0,leave=True)\n",
    ")\n",
    "print('end')\n",
    "\n",
    "InferredParams = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "# Assign the optimization results to InferredParams\n",
    "for i, j, x in results:\n",
    "    InferredParams[i, j] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cc73a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:05.978843Z",
     "start_time": "2025-12-10T14:12:05.900380Z"
    }
   },
   "outputs": [],
   "source": [
    "MD_SBIMin = np.zeros([55,64])\n",
    "FA_SBIMin = np.zeros([55,64])\n",
    "for i in range(55):\n",
    "    for j in range(64):\n",
    "        Eigs = np.linalg.eigh(vals_to_mat(InferredParams[i,j,:6]))[0]\n",
    "        MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "        FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "FA_SBIMin[np.isnan(FA_SBIMin )] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cfa1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:06.029441Z",
     "start_time": "2025-12-10T14:12:05.979544Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MD_SBIMin)\n",
    "\n",
    "temp[~mask_cutout] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=4e-3)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786568a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:09.788014Z",
     "start_time": "2025-12-10T14:12:09.558471Z"
    }
   },
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtabHCP7,return_S0_hat = True,fit_method='NLLS')\n",
    "tenfit_min = tenmodel.fit(maskdata[:,:,axial_middle,selected_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0f98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:09.909067Z",
     "start_time": "2025-12-10T14:12:09.826325Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(tenfit_min.md)\n",
    "\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=3.5e-3)\n",
    "plt.axis('off')\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d1156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:12:11.077787Z",
     "start_time": "2025-12-10T14:12:10.937849Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.abs(MD_SBIFull.T-MD_SBIMin.T)\n",
    "data[~mask.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=np.nanmax(data)/2, vmax=np.nanmax(data))\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=np.nanmax(data)/2, vmax=np.nanmax(data))\n",
    "ticks = [0, np.round(np.nanmax(data),3)]  # Adjust the number of ticks as needed\n",
    "data = np.abs(tenfit.md.T-tenfit_min.md.T)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f13ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:53:19.258327Z",
     "start_time": "2025-11-10T15:53:19.208110Z"
    }
   },
   "source": [
    "## d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ceb14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T14:14:35.182004Z",
     "start_time": "2025-12-10T14:14:35.099082Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = gaussian_filter(FA_SBIMin, sigma=0.51).T\n",
    "temp[~mask_cutout.T] = math.nan\n",
    "plt.imshow(temp,cmap='hot',vmin=0,vmax=1)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469280d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:55:45.594996Z",
     "start_time": "2025-12-10T10:55:45.479666Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(tenfit_min.fa)\n",
    "\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=1)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2942c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T10:55:47.339669Z",
     "start_time": "2025-12-10T10:55:47.206061Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.abs(FA_SBIFull.T-FA_SBIMin.T)\n",
    "data[~mask.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=0.5, vmax=1)\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=0.5, vmax=1)\n",
    "ticks = [0, 1]  # Adjust the number of ticks as needed\n",
    "data = np.abs(tenfit.fa.T-tenfit_min.fa.T)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "cbar.set_ticks(ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81349f0a",
   "metadata": {},
   "source": [
    "## e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce711ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T13:54:28.110634Z",
     "start_time": "2025-12-22T13:54:28.068161Z"
    }
   },
   "outputs": [],
   "source": [
    "fdwi = '../../HCP_data/Pat'+str(1)+'/diff_1k.nii.gz'\n",
    "bvalloc = '../../HCP_data/Pat'+str(1)+'/bvals_1k.txt'\n",
    "bvecloc = '../../HCP_data/Pat'+str(1)+'/bvecs_1k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices20 = [0]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(19):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices20))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices20], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices20.append(next_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa0be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T13:57:28.888584Z",
     "start_time": "2025-12-22T13:54:28.626829Z"
    }
   },
   "outputs": [],
   "source": [
    "Masks = []\n",
    "maskdatas = []\n",
    "axial_middles = []\n",
    "WMs = []\n",
    "\n",
    "gTabsF = []\n",
    "gTabs7 = []\n",
    "gTabs20 = []\n",
    "\n",
    "FullDat   = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    fdwi = '../../HCP_data/Pat'+str(kk+1)+'/diff_1k.nii.gz'\n",
    "    bvalloc = '../../HCP_data/Pat'+str(kk+1)+'/bvals_1k.txt'\n",
    "    bvecloc = '../../HCP_data/Pat'+str(kk+1)+'/bvecs_1k.txt'\n",
    "    \n",
    "    bvalsHCP = np.loadtxt(bvalloc)\n",
    "    bvecsHCP = np.loadtxt(bvecloc)\n",
    "    gtabHCP = gradient_table(bvals = bvalsHCP, bvecs = bvecsHCP)\n",
    "    gTabsF.append(gtabHCP)\n",
    "\n",
    "    data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "    data, affine = reslice(data, affine, (1.5,1.5,1.5), (2.5,2.5,2.5))\n",
    "    floor = np.clip(data.min(axis=-1),-np.inf,0)\n",
    "    data2 = data + abs(floor)[:,:,:,None] + 1e-5\n",
    "    maskdata, _ = median_otsu(data2, vol_idx=range(10, 50), median_radius=3,\n",
    "                                 numpass=1, autocrop=True, dilate=2)\n",
    "    axial_middle = maskdata.shape[2] // 2\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(maskdata[:, :, axial_middle, :], axis=-1) != 0\n",
    "    Masks.append(mask)\n",
    "    maskdatas.append(maskdata[:,:,axial_middle])\n",
    "    axial_middles.append(axial_middle)\n",
    "\n",
    "    WM, affine, img = load_nifti('../../HCP_data/WM_Masks/c2Pat'+str(kk+1)+'_FP.nii', return_img=True)\n",
    "    WMs.append(np.fliplr(WM[:,:,axial_middles[kk]]>0.8))\n",
    "    \n",
    "    bvalsHCP7 = bvalsHCP[selected_indices]\n",
    "    bvecsHCP7 = bvecsHCP[selected_indices]\n",
    "    gtabHCP7 = gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7)\n",
    "\n",
    "    gTabs7.append(gtabHCP7)\n",
    "\n",
    "    bvalsHCP20 = bvalsHCP[selected_indices20]\n",
    "    bvecsHCP20 = bvecsHCP[selected_indices20]\n",
    "    gtabHCP20 = gradient_table(bvals = bvalsHCP20, bvecs = bvecsHCP20)\n",
    "\n",
    "    gTabs20.append(gtabHCP20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa4396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:04:53.970386Z",
     "start_time": "2025-12-22T13:57:28.889971Z"
    }
   },
   "outputs": [],
   "source": [
    "MDFullArr = []\n",
    "FAFullArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dat = maskdatas[kk]\n",
    "    mask = np.sum(dat, axis=-1) != 0\n",
    "\n",
    "    gtab = gTabsF[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,dat[i,j]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in chunked_indices\n",
    "    )\n",
    "\n",
    "    # Initialize array with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIFull = np.zeros(ArrShape)\n",
    "    FA_SBIFull = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIFull[i,j] = np.mean(Eigs)\n",
    "            FA_SBIFull[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIFull[np.isnan(FA_SBIFull)] = 0\n",
    "    MDFullArr.append(MD_SBIFull)\n",
    "    FAFullArr.append(FA_SBIFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e43ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:13:06.075984Z",
     "start_time": "2025-12-22T14:04:53.971416Z"
    }
   },
   "outputs": [],
   "source": [
    "MDMidArr = []\n",
    "FAMidArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dat = maskdatas[kk]\n",
    "    mask = np.sum(dat, axis=-1) != 0\n",
    "\n",
    "    gtab = gTabs20[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,dat[i,j,selected_indices20]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in chunked_indices\n",
    "    )\n",
    "\n",
    "    # Initialize array with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIMid = np.zeros(ArrShape)\n",
    "    FA_SBIMid = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIMid[i,j] = np.mean(Eigs)\n",
    "            FA_SBIMid[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIMid[np.isnan(FA_SBIMid)] = 0\n",
    "    MDMidArr.append(MD_SBIMid)\n",
    "    FAMidArr.append(FA_SBIMid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ac153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:24:19.775055Z",
     "start_time": "2025-12-22T14:18:17.098556Z"
    }
   },
   "outputs": [],
   "source": [
    "MDMinArr = []\n",
    "FAMinArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dat = maskdatas[kk]\n",
    "    mask = np.sum(dat, axis=-1) != 0\n",
    "\n",
    "    gtab = gTabs7[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    def optimize_chunk(pixels):\n",
    "        results = []\n",
    "        for i, j in pixels:\n",
    "            posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,dat[i,j,selected_indices]),show_progress_bars=False)\n",
    "            results.append((i, j, posterior_samples_1.mean(axis=0)))\n",
    "        return results\n",
    "\n",
    "    chunked_indices = [indices[i:i+ChunkSize] for i in range(0, len(indices), ChunkSize)]\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_chunk)(chunk) for chunk in chunked_indices\n",
    "    )\n",
    "\n",
    "    # Initialize array with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for chunk in results:\n",
    "        for i, j, x in chunk:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIFull = np.zeros(ArrShape)\n",
    "    FA_SBIFull = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIFull[i,j] = np.mean(Eigs)\n",
    "            FA_SBIFull[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIFull[np.isnan(FA_SBIFull)] = 0\n",
    "    MDMinArr.append(MD_SBIFull)\n",
    "    FAMinArr.append(FA_SBIFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b49d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:27:00.384804Z",
     "start_time": "2025-12-22T14:26:28.534343Z"
    }
   },
   "outputs": [],
   "source": [
    "MDFullNLArr = []\n",
    "FAFullNLArr = []\n",
    "\n",
    "MDMidNLArr = []\n",
    "FAMidNLArr = []\n",
    "\n",
    "MDMinNLArr = []\n",
    "FAMinNLArr = []\n",
    "for kk in tqdm(range(32),position=0,leave=True):\n",
    "    dat = maskdatas[kk]\n",
    "    gtab = gTabsF[kk]\n",
    "    tenmodel = dti.TensorModel(gTabsF[kk],return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(dat)\n",
    "    FAFull_t = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull_t = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDFullNLArr.append(MDFull_t)\n",
    "    FAFullNLArr.append(FAFull_t)\n",
    "\n",
    "    gtab = gTabs20[kk]\n",
    "    tenmodel = dti.TensorModel(gtab,return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(dat[...,selected_indices20])\n",
    "    FAFull_t = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull_t = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDMidNLArr.append(MDFull_t)\n",
    "    FAMidNLArr.append(FAFull_t)\n",
    "    \n",
    "    gtab = gTabs7[kk]\n",
    "    tenmodel = dti.TensorModel(gtab,return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(dat[...,selected_indices])\n",
    "    FAFull_t = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull_t = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDMinNLArr.append(MDFull_t)\n",
    "    FAMinNLArr.append(FAFull_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba390f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:27:27.224347Z",
     "start_time": "2025-12-22T14:27:00.386011Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_MD = []\n",
    "AccM20_MD = []\n",
    "AccMFulls_MD = []\n",
    "\n",
    "AccM7NL_MD = []\n",
    "AccM20NL_MD = []\n",
    "\n",
    "SSIM7_MD = []\n",
    "SSIM20_MD = []\n",
    "SSIMFulls_MD = []\n",
    "\n",
    "SSIM7NL_MD = []\n",
    "SSIM20NL_MD = []\n",
    "\n",
    "Prec7_SBI_MD = []\n",
    "Prec20_SBI_MD = []\n",
    "PrecFull_SBI_MD = []\n",
    "\n",
    "Prec7_NLLS_MD = []\n",
    "Prec20_NLLS_MD = []\n",
    "PrecFull_NLLS_MD = []\n",
    "for i in tqdm(range(32),position=0,leave=True):\n",
    "    M7 = MDMinArr[i]\n",
    "    MF = MDFullArr[i]\n",
    "    Ma = Masks[i]\n",
    "    AccM7_MD.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMidArr[i]\n",
    "    MF = MDFullArr[i]\n",
    "    AccM20_MD.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDFullArr[i]\n",
    "    MF = MDFullNLArr[i]\n",
    "    AccMFulls_MD.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMinNLArr[i]\n",
    "    MF = MDFullNLArr[i]\n",
    "    AccM7NL_MD.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMidNLArr[i]\n",
    "    MF = MDFullNLArr[i]\n",
    "    AccM20NL_MD.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = MDMinArr[i]\n",
    "    NS2 = MDFullArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_MD.append(result)\n",
    "\n",
    "    NS1 = MDMidArr[i]\n",
    "    NS2 = MDFullArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_MD.append(result)\n",
    "    \n",
    "    NS1 = MDFullArr[i]\n",
    "    NS2 = MDFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_MD.append(result)\n",
    "\n",
    "    NS1 = MDMinNLArr[i]\n",
    "    NS2 = MDFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_MD.append(result)\n",
    "\n",
    "    NS1 = MDMidNLArr[i]\n",
    "    NS2 = MDFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_MD.append(result)\n",
    "\n",
    "    Prec7_SBI_MD.append(np.std(MDMinArr[i][WMs[i]]))\n",
    "    Prec20_SBI_MD.append(np.std(MDMidArr[i][WMs[i]]))\n",
    "    PrecFull_SBI_MD.append(np.std(MDFullArr[i][WMs[i]]))\n",
    "\n",
    "    Prec7_NLLS_MD.append(np.std(MDMinNLArr[i][WMs[i]]))\n",
    "    Prec20_NLLS_MD.append(np.std(MDMidNLArr[i][WMs[i]]))\n",
    "    PrecFull_NLLS_MD.append(np.std(MDFullNLArr[i][WMs[i]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd350c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:27:54.077424Z",
     "start_time": "2025-12-22T14:27:27.225210Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_FA = []\n",
    "AccM20_FA = []\n",
    "AccMFulls_FA = []\n",
    "\n",
    "AccM7NL_FA = []\n",
    "AccM20NL_FA = []\n",
    "\n",
    "SSIM7_FA = []\n",
    "SSIM20_FA = []\n",
    "SSIMFulls_FA = []\n",
    "\n",
    "SSIM7NL_FA = []\n",
    "SSIM20NL_FA = []\n",
    "\n",
    "Prec7_SBI_FA = []\n",
    "Prec20_SBI_FA = []\n",
    "PrecFull_SBI_FA = []\n",
    "\n",
    "Prec7_NLLS_FA = []\n",
    "Prec20_NLLS_FA = []\n",
    "PrecFull_NLLS_FA = []\n",
    "for i in range(32):\n",
    "    M7 = FAMinArr[i]\n",
    "    MF = FAFullArr[i]\n",
    "    Ma = Masks[i]\n",
    "    AccM7_FA.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMidArr[i]\n",
    "    MF = FAFullArr[i]\n",
    "    AccM20_FA.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAFullArr[i]\n",
    "    MF = FAFullNLArr[i]\n",
    "    AccMFulls_FA.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMinNLArr[i]\n",
    "    MF = FAFullNLArr[i]\n",
    "    AccM7NL_FA.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMidNLArr[i]\n",
    "    MF = FAFullNLArr[i]\n",
    "    AccM20NL_FA.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = FAMinArr[i]\n",
    "    NS2 = FAFullArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_FA.append(result)\n",
    "\n",
    "    NS1 = FAMidArr[i]\n",
    "    NS2 = FAFullArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_FA.append(result)\n",
    "    \n",
    "    NS1 = FAFullArr[i]\n",
    "    NS2 = FAFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_FA.append(result)\n",
    "\n",
    "    NS1 = FAMinNLArr[i]\n",
    "    NS2 = FAFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_FA.append(result)\n",
    "\n",
    "    NS1 = FAMidNLArr[i]\n",
    "    NS2 = FAFullNLArr[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_FA.append(result)\n",
    "\n",
    "    Prec7_SBI_FA.append(np.std(FAMinArr[i][WMs[i]]))\n",
    "    Prec20_SBI_FA.append(np.std(FAMidArr[i][WMs[i]]))\n",
    "    PrecFull_SBI_FA.append(np.std(FAFullArr[i][WMs[i]]))\n",
    "\n",
    "    Prec7_NLLS_FA.append(np.std(FAMinNLArr[i][WMs[i]]))\n",
    "    Prec20_NLLS_FA.append(np.std(FAMidNLArr[i][WMs[i]]))\n",
    "    PrecFull_NLLS_FA.append(np.std(FAFullNLArr[i][WMs[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff619591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:43:45.759240Z",
     "start_time": "2025-12-22T14:38:13.587287Z"
    }
   },
   "outputs": [],
   "source": [
    "Dats_MS   = []\n",
    "gTabs7_MS = []\n",
    "gTabs20_MS = []\n",
    "gTabsF_MS = []\n",
    "Masks_MS   = []\n",
    "TrueIndxs = []\n",
    "axial_middles_MS = []\n",
    "for i,Name in tqdm(enumerate(['NMSS_11_1year','NMSS_15','NMSS_16','NMSS_18','NMSS_19','Ctrl055_R01_28','Ctrl056_R01_29','Ctrl057_R01_30']),position = 0,leave = True):\n",
    "    MatDir = '../../MS_data/'+Name\n",
    "\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    affine = np.ones((4,4))\n",
    "    \n",
    "    data, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "    _, maskCut = median_otsu(data, vol_idx=range(10, 80), autocrop=False)\n",
    "    maskdata, mask = median_otsu(data, vol_idx=range(10, 80), autocrop=True)\n",
    "    Masks_MS.append(mask)\n",
    "    axial_middle = maskdata.shape[2] // 2\n",
    "    axial_middles_MS.append(axial_middle)\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    bvecs2000 = bvecs[bvals==2000]\n",
    "    bvecs4000 = bvecs[bvals==4000]\n",
    "\n",
    "    bvals2000 = np.array([0] + list(bvals[bvals==2000]))\n",
    "    bvecs2000 = np.vstack([[0,0,0],bvecs[bvals==2000]])\n",
    "\n",
    "    Dats_MS.append(maskdata[:,:,:,np.hstack([0,np.where(bvals==2000)[0]])])\n",
    "    \n",
    "    gTabsF_MS.append(gradient_table(bvals = bvals2000,bvecs = bvecs2000))\n",
    "\n",
    "    if(i == 0):\n",
    "        # Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "        selected_indices_MS = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs2000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(6):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices_MS))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices_MS], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices_MS.append(next_index)\n",
    "        \n",
    "        selected_indices_MS = selected_indices_MS\n",
    "\n",
    "        selected_indices20_MS = [0]\n",
    "        distance_matrix = squareform(pdist(bvecs2000))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(19):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs2000))) - set(selected_indices20_MS))\n",
    "            \n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices20_MS], axis=1)\n",
    "            \n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices20_MS.append(next_index)\n",
    "\n",
    "    bvalsHCP7 = bvals2000[selected_indices_MS]\n",
    "    bvecsHCP7 = bvecs2000[selected_indices_MS]\n",
    "    \n",
    "    gTabs7_MS.append(gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7))\n",
    "    bvalsHCP7 = bvals2000[selected_indices20_MS]\n",
    "    bvecsHCP7 = bvecs2000[selected_indices20_MS]\n",
    "    \n",
    "    gTabs20_MS.append(gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97b76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T23:23:16.299175Z",
     "start_time": "2025-12-28T23:23:16.251589Z"
    }
   },
   "outputs": [],
   "source": [
    "MSDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cde604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:37:22.686693Z",
     "start_time": "2025-12-22T14:33:29.855207Z"
    }
   },
   "outputs": [],
   "source": [
    "WMDir = MSDir+'WM_masks/'\n",
    "WMs_MS = []\n",
    "for i,Name in tqdm(enumerate(['NMSS_11_1year','NMSS_15','NMSS_16','NMSS_18','NMSS_19','Ctrl055_R01_28','Ctrl056_R01_29','Ctrl057_R01_30']),position = 0,leave = True):\n",
    "    MatDir = MSDir+Name\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    affine = np.ones((4,4))\n",
    "    \n",
    "    data, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "    _, maskCut = median_otsu(data, vol_idx=range(10, 80), autocrop=False)\n",
    "    \n",
    "    true_indices = np.argwhere(maskCut)\n",
    "    \n",
    "    # Determine the minimum and maximum indices along each dimension\n",
    "    min_coords = true_indices.min(axis=0)\n",
    "    max_coords = true_indices.max(axis=0)\n",
    "    \n",
    "    for k,x in enumerate(os.listdir(WMDir)):\n",
    "        if Name in x:\n",
    "            print(Name)\n",
    "            WM, affine, img = load_nifti(WMDir+x, return_img=True)\n",
    "            WM, affine = reslice(WM, affine, (2,2,2), (2.5,2.5,2.5))\n",
    "            if(i<5):\n",
    "                WM_t = np.fliplr(np.swapaxes(WM,0,1))\n",
    "            else:\n",
    "                WM_t = np.fliplr(np.flipud(np.swapaxes(WM,0,1)))\n",
    "            WM_t  = WM_t[min_coords[0]:max_coords[0]+1,min_coords[1]:max_coords[1]+1,min_coords[2]:max_coords[2]+1]\n",
    "            WMs_MS.append(WM_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0464b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:46:07.063520Z",
     "start_time": "2025-12-22T14:43:51.747727Z"
    }
   },
   "outputs": [],
   "source": [
    "MDFullArr_MS = []\n",
    "FAFullArr_MS = []\n",
    "for kk in tqdm(range(8),position=0,leave=True):\n",
    "    Dat = Dats_MS[kk]\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dat[:, :, axial_middles_MS[kk], :], axis=-1) != 0\n",
    "    gtab = gTabsF_MS[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    AM = axial_middles_MS[kk]\n",
    "    \n",
    "    # Define the function for optimization\n",
    "    def optimize_pixel(i, j):\n",
    "        torch.manual_seed(10)  # If required\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,Dat[i, j,AM, :]),show_progress_bars=False)\n",
    "        return i, j, posterior_samples_1.mean(axis=0)\n",
    "    \n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    \n",
    "    # Use joblib to parallelize the optimization tasks\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_pixel)(i, j) for i, j in indices\n",
    "    )\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for i, j, x in results:\n",
    "        NoiseEst[i, j] = x\n",
    "    \n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIMin = np.zeros(ArrShape)\n",
    "    FA_SBIMin = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "            FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIMin[np.isnan(FA_SBIMin)] = 0\n",
    "    MDFullArr_MS.append(MD_SBIMin)\n",
    "    FAFullArr_MS.append(FA_SBIMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0df6b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:48:20.958153Z",
     "start_time": "2025-12-22T14:47:04.761642Z"
    }
   },
   "outputs": [],
   "source": [
    "MDMinArr_MS = []\n",
    "FAMinArr_MS = []\n",
    "for kk in tqdm(range(8),position=0,leave=True):\n",
    "    Dat = Dats_MS[kk]\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dat[:, :, axial_middles_MS[kk], :], axis=-1) != 0\n",
    "    gtab = gTabs7_MS[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    AM = axial_middles_MS[kk]\n",
    "    \n",
    "    # Define the function for optimization\n",
    "    def optimize_pixel(i, j):\n",
    "        torch.manual_seed(10)  # If required\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,Dat[i, j,AM, selected_indices_MS]),show_progress_bars=False)\n",
    "        return i, j, posterior_samples_1.mean(axis=0)\n",
    "    \n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    \n",
    "    # Use joblib to parallelize the optimization tasks\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_pixel)(i, j) for i, j in indices\n",
    "    )\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for i, j, x in results:\n",
    "        NoiseEst[i, j] = x\n",
    "    \n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIMin = np.zeros(ArrShape)\n",
    "    FA_SBIMin = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "            FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIMin[np.isnan(FA_SBIMin)] = 0\n",
    "    MDMinArr_MS.append(MD_SBIMin)\n",
    "    FAMinArr_MS.append(FA_SBIMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094debe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:49:38.267640Z",
     "start_time": "2025-12-22T14:48:20.960507Z"
    }
   },
   "outputs": [],
   "source": [
    "MDMidArr_MS = []\n",
    "FAMidArr_MS = []\n",
    "for kk in tqdm(range(8),position=0,leave=True):\n",
    "    Dat = Dats_MS[kk]\n",
    "    # Compute the mask where the sum is not zero\n",
    "    mask = np.sum(Dat[:, :, axial_middles_MS[kk], :], axis=-1) != 0\n",
    "    gtab = gTabs20_MS[kk]\n",
    "    # Get the indices where mask is True\n",
    "    indices = np.argwhere(mask)\n",
    "    AM = axial_middles_MS[kk]\n",
    "    \n",
    "    # Define the function for optimization\n",
    "    def optimize_pixel(i, j):\n",
    "        torch.manual_seed(10)  # If required\n",
    "        posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,Dat[i, j,AM, selected_indices20_MS]),show_progress_bars=False)\n",
    "        return i, j, posterior_samples_1.mean(axis=0)\n",
    "    \n",
    "    # Initialize NoiseEst with the appropriate shape\n",
    "    ArrShape = mask.shape\n",
    "    \n",
    "    # Use joblib to parallelize the optimization tasks\n",
    "    results = Parallel(n_jobs=8)(\n",
    "        delayed(optimize_pixel)(i, j) for i, j in indices\n",
    "    )\n",
    "    \n",
    "    NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "    \n",
    "    # Assign the optimization results to NoiseEst\n",
    "    for i, j, x in results:\n",
    "        NoiseEst[i, j] = x\n",
    "    \n",
    "    NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]):    \n",
    "            NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "    MD_SBIMin = np.zeros(ArrShape)\n",
    "    FA_SBIMin = np.zeros(ArrShape)\n",
    "    for i in range(ArrShape[0]):\n",
    "        for j in range(ArrShape[1]): \n",
    "            Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "            MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "            FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "    FA_SBIMin[np.isnan(FA_SBIMin)] = 0\n",
    "    MDMidArr_MS.append(MD_SBIMin)\n",
    "    FAMidArr_MS.append(FA_SBIMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209469d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:49:44.945032Z",
     "start_time": "2025-12-22T14:49:38.268568Z"
    }
   },
   "outputs": [],
   "source": [
    "MDFullNLArr_MS = []\n",
    "FAFullNLArr_MS = []\n",
    "for kk in range(8):\n",
    "    \n",
    "    tenmodel = dti.TensorModel(gTabsF_MS[kk],return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(Dats_MS[kk][:,:,axial_middles_MS[kk],:])\n",
    "    FAFull = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDFullNLArr_MS.append(MDFull)\n",
    "    FAFullNLArr_MS.append(FAFull)\n",
    "MDMinNLArr_MS = []\n",
    "FAMinNLArr_MS = []\n",
    "for kk in range(8):\n",
    "    \n",
    "    tenmodel = dti.TensorModel(gTabs7_MS[kk],return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(Dats_MS[kk][:,:,axial_middles_MS[kk],selected_indices_MS])\n",
    "    FAFull = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDMinNLArr_MS.append(MDFull)\n",
    "    FAMinNLArr_MS.append(FAFull)\n",
    "MDMidNLArr_MS = []\n",
    "FAMidNLArr_MS = []\n",
    "for kk in range(8):\n",
    "    \n",
    "    tenmodel = dti.TensorModel(gTabs20_MS[kk],return_S0_hat = True,fit_method='NLLS')\n",
    "    tenfit = tenmodel.fit(Dats_MS[kk][:,:,axial_middles_MS[kk],selected_indices20_MS])\n",
    "    FAFull = dti.fractional_anisotropy(tenfit.evals)\n",
    "    MDFull = dti.mean_diffusivity(tenfit.evals)\n",
    "    MDMidNLArr_MS.append(MDFull)\n",
    "    FAMidNLArr_MS.append(FAFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ef225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:49:50.795754Z",
     "start_time": "2025-12-22T14:49:44.946640Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_MD_MS = []\n",
    "AccM20_MD_MS = []\n",
    "AccMFulls_MD_MS = []\n",
    "\n",
    "AccM7NL_MD_MS = []\n",
    "AccM20NL_MD_MS = []\n",
    "\n",
    "SSIM7_MD_MS = []\n",
    "SSIM20_MD_MS = []\n",
    "SSIMFulls_MD_MS = []\n",
    "\n",
    "SSIM7NL_MD_MS = []\n",
    "SSIM20NL_MD_MS = []\n",
    "for i in range(8):\n",
    "    M7 = MDMinArr_MS[i]\n",
    "    MF = MDFullArr_MS[i]\n",
    "    Ma = Masks_MS[i][:,:,axial_middles_MS[i]]\n",
    "    AccM7_MD_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMidArr_MS[i]\n",
    "    MF = MDFullArr_MS[i]\n",
    "    AccM20_MD_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDFullArr_MS[i]\n",
    "    MF = MDFullNLArr_MS[i]\n",
    "    AccMFulls_MD_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMinNLArr_MS[i]\n",
    "    MF = MDFullNLArr_MS[i]\n",
    "    AccM7NL_MD_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MDMidNLArr_MS[i]\n",
    "    MF = MDFullNLArr_MS[i]\n",
    "    AccM20NL_MD_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = MDMinArr_MS[i]\n",
    "    NS2 = MDFullArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_MD_MS.append(result)\n",
    "\n",
    "    NS1 = MDMidArr_MS[i]\n",
    "    NS2 = MDFullArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_MD_MS.append(result)\n",
    "    \n",
    "    NS1 = MDFullArr_MS[i]\n",
    "    NS2 = MDFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_MD_MS.append(result)\n",
    "\n",
    "    NS1 = MDMinNLArr_MS[i]\n",
    "    NS2 = MDFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_MD_MS.append(result)\n",
    "\n",
    "    NS1 = MDMidNLArr_MS[i]\n",
    "    NS2 = MDFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_MD_MS.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_MD_MS = []\n",
    "Prec20_SBI_MD_MS = []\n",
    "PrecFull_SBI_MD_MS = []\n",
    "\n",
    "Prec7_NLLS_MD_MS = []\n",
    "Prec20_NLLS_MD_MS = []\n",
    "PrecFull_NLLS_MD_MS = []\n",
    "for i in range(8):\n",
    "    Prec7_SBI_MD_MS.append(np.std(MDMinArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    Prec20_SBI_MD_MS.append(np.std(MDMidArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    PrecFull_SBI_MD_MS.append(np.std(MDFullArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "\n",
    "    Prec7_NLLS_MD_MS.append(np.std(MDMinNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    Prec20_NLLS_MD_MS.append(np.std(MDMidNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    PrecFull_NLLS_MD_MS.append(np.std(MDFullNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643eb00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T14:49:56.573641Z",
     "start_time": "2025-12-22T14:49:50.796658Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_FA_MS = []\n",
    "AccM20_FA_MS = []\n",
    "AccMFulls_FA_MS = []\n",
    "\n",
    "AccM7NL_FA_MS = []\n",
    "AccM20NL_FA_MS = []\n",
    "\n",
    "SSIM7_FA_MS = []\n",
    "SSIM20_FA_MS = []\n",
    "SSIMFulls_FA_MS = []\n",
    "\n",
    "SSIM7NL_FA_MS = []\n",
    "SSIM20NL_FA_MS = []\n",
    "for i in range(8):\n",
    "    M7 = FAMinArr_MS[i]\n",
    "    MF = FAFullArr_MS[i]\n",
    "    Ma = Masks_MS[i][:,:,axial_middles_MS[i]]\n",
    "    AccM7_FA_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMidArr_MS[i]\n",
    "    MF = FAFullArr_MS[i]\n",
    "    AccM20_FA_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAFullArr_MS[i]\n",
    "    MF = FAFullNLArr_MS[i]\n",
    "    AccMFulls_FA_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMinNLArr_MS[i]\n",
    "    MF = FAFullNLArr_MS[i]\n",
    "    AccM7NL_FA_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FAMidNLArr_MS[i]\n",
    "    MF = FAFullNLArr_MS[i]\n",
    "    AccM20NL_FA_MS.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = FAMinArr_MS[i]\n",
    "    NS2 = FAFullArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_FA_MS.append(result)\n",
    "\n",
    "    NS1 = FAMidArr_MS[i]\n",
    "    NS2 = FAFullArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20_FA_MS.append(result)\n",
    "    \n",
    "    NS1 = FAFullArr_MS[i]\n",
    "    NS2 = FAFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_FA_MS.append(result)\n",
    "\n",
    "    NS1 = FAMinNLArr_MS[i]\n",
    "    NS2 = FAFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_FA_MS.append(result)\n",
    "\n",
    "    NS1 = FAMidNLArr_MS[i]\n",
    "    NS2 = FAFullNLArr_MS[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM20NL_FA_MS.append(result)\n",
    "\n",
    "\n",
    "Prec7_SBI_FA_MS = []\n",
    "Prec20_SBI_FA_MS = []\n",
    "PrecFull_SBI_FA_MS = []\n",
    "\n",
    "Prec7_NLLS_FA_MS = []\n",
    "Prec20_NLLS_FA_MS = []\n",
    "PrecFull_NLLS_FA_MS = []\n",
    "for i in range(8):\n",
    "    Prec7_SBI_FA_MS.append(np.std(FAMinArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    Prec20_SBI_FA_MS.append(np.std(FAMidArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    PrecFull_SBI_FA_MS.append(np.std(FAFullArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "\n",
    "    Prec7_NLLS_FA_MS.append(np.std(FAMinNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    Prec20_NLLS_FA_MS.append(np.std(FAMidNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n",
    "    PrecFull_NLLS_FA_MS.append(np.std(FAFullNLArr_MS[i][WMs_MS[i][:,:,axial_middles_MS[i]]>0.8]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18288195",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_RT_SBI = []\n",
    "FA_RT_SBI = []\n",
    "MD_RT_NLLS  =[]\n",
    "FA_RT_NLLS  =[]\n",
    "\n",
    "MD_RT_SBI_Min = []\n",
    "FA_RT_SBI_Min = []\n",
    "MD_RT_NLLS_Min  =[]\n",
    "FA_RT_NLLS_Min  =[]\n",
    "\n",
    "for jj,N in enumerate(RTNames):\n",
    "    Subfiles = []\n",
    "    for k,x in enumerate(os.listdir(BaseDir)):\n",
    "        if N in x:\n",
    "            print(x)\n",
    "            Subfiles.append(x)\n",
    "    Subfiles = sorted(Subfiles)\n",
    "\n",
    "    S = Subfiles[0]\n",
    "    MatDir = BaseDir+S\n",
    "    F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "    affine = np.eye(4)\n",
    "\n",
    "    data, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "    _, maskCut = median_otsu(data, vol_idx=range(10, 80), autocrop=False)\n",
    "    true_indices = np.argwhere(maskCut)\n",
    "\n",
    "    # Determine the minimum and maximum indices along each dimension\n",
    "    min_coords = true_indices.min(axis=0)\n",
    "    max_coords = true_indices.max(axis=0)\n",
    "    AM = (max_coords[-1]+min_coords[-1])//2\n",
    "    bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "    bvecs[np.isnan(bvecs)] = 0\n",
    "    bvals = F['bval']\n",
    "    data = data[...,np.logical_or(bvals==2000,bvals == 0)]\n",
    "    bvecs2000 = bvecs[np.logical_or(bvals==2000,bvals == 0)]\n",
    "\n",
    "    bvals2000 = np.array(list(bvals[np.logical_or(bvals==2000,bvals == 0)]))\n",
    "\n",
    "    gtabs = [gradient_table(bvals = bvals2000,bvecs = bvecs2000)]\n",
    "    Dats = []\n",
    "    for i,S in enumerate(Subfiles[1:]):\n",
    "        MatDir = BaseDir+S\n",
    "        F = pmt.read_mat(MatDir+'/data_loaded.mat')\n",
    "        affine = np.eye(4)\n",
    "\n",
    "        data1, affine = reslice(F['data'], affine, (2,2,2), (2.5,2.5,2.5))\n",
    "\n",
    "        bvecs = (F['direction'].T/np.linalg.norm(F['direction'],axis=1)).T\n",
    "        bvecs[np.isnan(bvecs)] = 0\n",
    "        bvals = F['bval']\n",
    "        data1 = data1[...,np.logical_or(bvals==2000,bvals == 0)]\n",
    "        if(jj == 0):\n",
    "            if(i < 2):\n",
    "                data1 = data1[:,::-1]\n",
    "        elif(jj == 1 or jj == 2 or jj == 3 or jj == 4):\n",
    "            if(i<3):\n",
    "                data1 = data1[:,::-1]\n",
    "        elif(jj==5):\n",
    "            if(i>0 and i < 3):\n",
    "                data1 = data1[:,::-1]\n",
    "        Dats.append(data1)\n",
    "        bvecs2000 = bvecs[np.logical_or(bvals==2000,bvals == 0)]\n",
    "\n",
    "        bvals2000 = np.array(list(bvals[np.logical_or(bvals==2000,bvals == 0)]))\n",
    "\n",
    "        gtabs.append(gradient_table(bvals = bvals2000,bvecs = bvecs2000))\n",
    "        \n",
    "        selected_indices_MS = [0]\n",
    "        bvecs_temp = np.copy(gtab1.bvecs)\n",
    "        distance_matrix = squareform(pdist(bvecs_temp))\n",
    "        # Iteratively select the point furthest from the current selection\n",
    "        for _ in range(6):  # We need 7 points in total, and one is already selected\n",
    "            remaining_indices = list(set(range(len(bvecs_temp))) - set(selected_indices_MS))\n",
    "\n",
    "            # Calculate the minimum distance to the selected points for each remaining point\n",
    "            min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices_MS], axis=1)\n",
    "\n",
    "            # Select the point with the maximum minimum distance\n",
    "            next_index = remaining_indices[np.argmax(min_distances)]\n",
    "            selected_indices_MS.append(next_index)\n",
    "\n",
    "        bvalsHCP7 = gtab1.bvals[selected_indices1]\n",
    "        bvecsHCP7 = gtab1.bvecs[selected_indices1]\n",
    "\n",
    "\n",
    "        gtabs7.append(gradient_table(bvals = bvalsHCP7, bvecs = bvecsHCP7))\n",
    "        Indxs7.append(selected_indices_MS)\n",
    "        \n",
    "    NewDats = [data]\n",
    "    for d,gt in zip(Dats,gtabs[1:]):\n",
    "        affine_map = rigid_register(data[...,gtabs[0].bvals==0].mean(axis=-1),d[...,gt.bvals==0].mean(axis=-1),affine1,affine1)\n",
    "        data2_warp = np.array([affine_map.transform(d[:,:,:,i], interpolation=\"linear\") for i in range(len(gt.bvals))])\n",
    "        data2_warp = np.rollaxis(data2_warp, 0, data2_warp.ndim)\n",
    "        NewDats.append(data2_warp)\n",
    "\n",
    "    NewDats_masked = [ND*maskCut[...,None] for ND in NewDats]\n",
    "    MD_arr = []\n",
    "    FA_arr = []\n",
    "    for ND,gt in tqdm(zip(NewDats_masked,gtabs),position=0,leave=True):\n",
    "        mask = np.sum(ND[:, :, 42, :], axis=-1) != 0\n",
    "        gtab = gt\n",
    "        # Get the indices where mask is True\n",
    "        indices = np.argwhere(mask)\n",
    "        floor = np.clip(ND.min(axis=-1),-np.inf,0)\n",
    "        dat = ND + abs(floor)[:,:,:,None] + 1e-5\n",
    "        # Define the function for optimization\n",
    "        def optimize_pixel(i, j):\n",
    "            torch.manual_seed(10)  # If required\n",
    "            posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,dat[i, j,AM, :]),show_progress_bars=False)\n",
    "            return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "        # Initialize NoiseEst with the appropriate shape\n",
    "        ArrShape = mask.shape\n",
    "\n",
    "        # Use joblib to parallelize the optimization tasks\n",
    "        results = Parallel(n_jobs=8)(\n",
    "            delayed(optimize_pixel)(i, j) for i, j in tqdm(indices,position=0,leave=True)\n",
    "        )\n",
    "\n",
    "        NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "        # Assign the optimization results to NoiseEst\n",
    "        for i, j, x in results:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "        NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]):    \n",
    "                NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "        MD_SBIMin = np.zeros(ArrShape)\n",
    "        FA_SBIMin = np.zeros(ArrShape)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]): \n",
    "                Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "                MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "                FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "        FA_SBIMin[np.isnan(FA_SBIMin)] = 0\n",
    "\n",
    "        MD_arr.append(MD_SBIMin)\n",
    "        FA_arr.append(FA_SBIMin)\n",
    "\n",
    "    FA_NLS_arr = []\n",
    "    MD_NLS_arr = []\n",
    "    for d,gt in zip(NewDats_masked,gtabs):\n",
    "        tenmodel = dti.TensorModel(gt,return_S0_hat = True)\n",
    "        tenfit = tenmodel.fit(d[:,:,AM])\n",
    "\n",
    "        FA_NLS_arr.append(tenfit.fa)\n",
    "        MD_NLS_arr.append(tenfit.md)\n",
    "    \n",
    "    MD_RT_SBI_Full.append(MD_arr)\n",
    "    FA_RT_SBI_Full.append(FA_arr)\n",
    "\n",
    "    ND_RT_NLLS_Full.append(MD_NLS_arr)\n",
    "    FA_RT_NLLS_Full.append(FA_NLS_arr)\n",
    "    \n",
    "    MD_arr = []\n",
    "    FA_arr = []\n",
    "    for ND,gt,idx in tqdm(zip(NewDats_masked,gtabs7,Indxs7),position=0,leave=True):\n",
    "        mask = np.sum(ND[:, :, 42, :], axis=-1) != 0\n",
    "        gtab = gt\n",
    "        # Get the indices where mask is True\n",
    "        indices = np.argwhere(mask)\n",
    "        floor = np.clip(ND.min(axis=-1),-np.inf,0)\n",
    "        dat = ND + abs(floor)[:,:,:,None] + 1e-5\n",
    "        dat = dat[...,idx]\n",
    "        # Define the function for optimization\n",
    "        def optimize_pixel(i, j):\n",
    "            torch.manual_seed(10)  # If required\n",
    "            posterior_samples_1 = Network.sample((InferSamples,), x=DTIFeatures(gtab.bvecs,gtab.bvals,dat[i, j,AM, :]),show_progress_bars=False)\n",
    "            return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "        # Initialize NoiseEst with the appropriate shape\n",
    "        ArrShape = mask.shape\n",
    "\n",
    "        # Use joblib to parallelize the optimization tasks\n",
    "        results = Parallel(n_jobs=8)(\n",
    "            delayed(optimize_pixel)(i, j) for i, j in tqdm(indices,position=0,leave=True)\n",
    "        )\n",
    "\n",
    "        NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "        # Assign the optimization results to NoiseEst\n",
    "        for i, j, x in results:\n",
    "            NoiseEst[i, j] = x\n",
    "\n",
    "        NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]):    \n",
    "                NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1:]])\n",
    "        MD_SBIMin = np.zeros(ArrShape)\n",
    "        FA_SBIMin = np.zeros(ArrShape)\n",
    "        for i in range(ArrShape[0]):\n",
    "            for j in range(ArrShape[1]): \n",
    "                Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "                MD_SBIMin[i,j] = np.mean(Eigs)\n",
    "                FA_SBIMin[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "        FA_SBIMin[np.isnan(FA_SBIMin)] = 0\n",
    "\n",
    "        MD_arr.append(MD_SBIMin)\n",
    "        FA_arr.append(FA_SBIMin)\n",
    "\n",
    "    FA_NLS_arr = []\n",
    "    MD_NLS_arr = []\n",
    "    for d,gt,idx in zip(NewDats_masked,gtabs7,Indxs7):\n",
    "        tenmodel = dti.TensorModel(gt,return_S0_hat = True)\n",
    "        tenfit = tenmodel.fit(d[:,:,AM,idx])\n",
    "\n",
    "        FA_NLS_arr.append(tenfit.fa)\n",
    "        MD_NLS_arr.append(tenfit.md)\n",
    "    \n",
    "    MD_RT_SBI_Min.append(MD_arr)\n",
    "    FA_RT_SBI_Min.append(FA_arr)\n",
    "\n",
    "    MD_RT_NLLS_Min.append(MD_NLS_arr)\n",
    "    FA_RT_NLLS_Min.append(FA_NLS_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078de09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:39:47.837565Z",
     "start_time": "2025-12-23T08:39:47.788684Z"
    }
   },
   "outputs": [],
   "source": [
    "MD_RT_SBI_Min_list = []\n",
    "FA_RT_SBI_Min_list = []\n",
    "MD_RT_SBI_Full_list = []\n",
    "FA_RT_SBI_Full_list = []\n",
    "\n",
    "MD_RT_NLLS_Min_list = []\n",
    "FA_RT_NLLS_Min_list = []\n",
    "MD_RT_NLLS_Full_list = []\n",
    "FA_RT_NLLS_Full_list = []\n",
    "\n",
    "\n",
    "for kk in range(len(MD_RT_SBI_Min)):\n",
    "    for i in range(len(MD_RT_SBI_Min[kk])):\n",
    "        MD_RT_SBI_Min_list.append(MD_RT_SBI_Min[kk][i])\n",
    "        FA_RT_SBI_Min_list.append(FA_RT_SBI_Min[kk][i])\n",
    "        MD_RT_SBI_Full_list.append(MD_RT_SBI_Full[kk][i])\n",
    "        FA_RT_SBI_Full_list.append(FA_RT_SBI_Full[kk][i])\n",
    "        \n",
    "        MD_RT_NLLS_Min_list.append(MD_RT_NLLS_Min[kk][i])\n",
    "        FA_RT_NLLS_Min_list.append(FA_RT_NLLS_Min[kk][i])\n",
    "        MD_RT_NLLS_Full_list.append(MD_RT_NLLS_Full[kk][i])\n",
    "        FA_RT_NLLS_Full_list.append(FA_RT_NLLS_Full[kk][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111af70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:40:14.425969Z",
     "start_time": "2025-12-23T08:39:48.156020Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_MD_RT = []\n",
    "AccMFulls_MD_RT = []\n",
    "\n",
    "AccM7NL_MD_RT = []\n",
    "\n",
    "SSIM7_MD_RT = []\n",
    "SSIMFulls_MD_RT = []\n",
    "\n",
    "SSIM7NL_MD_RT = []\n",
    "for i in tqdm(range(29),position=0,leave=True):\n",
    "    M7 = MD_RT_SBI_Min_list[i]\n",
    "    MF = MD_RT_SBI_Full_list[i]\n",
    "    Ma = np.logical_not(MD_RT_SBI_Min_list[i]==1e-5)\n",
    "    AccM7_MD_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MD_RT_SBI_Full_list[i]\n",
    "    MF = MD_RT_NLLS_Full_list[i]\n",
    "    AccMFulls_MD_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = MD_RT_NLLS_Min_list[i]\n",
    "    MF = MD_RT_NLLS_Full_list[i]\n",
    "    AccM7NL_MD_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = MD_RT_SBI_Min_list[i]\n",
    "    NS2 = MD_RT_SBI_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_MD_RT.append(result)\n",
    "\n",
    "    NS1 = MD_RT_SBI_Full_list[i]\n",
    "    NS2 = MD_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_MD_RT.append(result)\n",
    "\n",
    "    NS1 = MD_RT_NLLS_Min_list[i]\n",
    "    NS2 = MD_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_MD_RT.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d0f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:40:40.959176Z",
     "start_time": "2025-12-23T08:40:14.427135Z"
    }
   },
   "outputs": [],
   "source": [
    "AccM7_FA_RT = []\n",
    "AccMFulls_FA_RT = []\n",
    "\n",
    "AccM7NL_FA_RT = []\n",
    "\n",
    "SSIM7_FA_RT = []\n",
    "SSIMFulls_FA_RT = []\n",
    "\n",
    "SSIM7NL_FA_RT = []\n",
    "for i in tqdm(range(29),position=0,leave=True):\n",
    "    M7 = FA_RT_SBI_Min_list[i]\n",
    "    MF = FA_RT_SBI_Full_list[i]\n",
    "    Ma = np.logical_not(MD_RT_SBI_Min_list[i]==1e-5)\n",
    "    AccM7_FA_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FA_RT_SBI_Full_list[i]\n",
    "    MF = FA_RT_NLLS_Full_list[i]\n",
    "    AccMFulls_FA_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "    M7 = FA_RT_NLLS_Min_list[i]\n",
    "    MF = FA_RT_NLLS_Full_list[i]\n",
    "    AccM7NL_FA_RT.append(np.mean(np.abs(M7-MF)[Ma]))\n",
    "\n",
    "\n",
    "    NS1 = FA_RT_SBI_Min_list[i]\n",
    "    NS2 = FA_RT_SBI_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7_FA_RT.append(result)\n",
    "\n",
    "    NS1 = FA_RT_SBI_Full_list[i]\n",
    "    NS2 = FA_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIMFulls_FA_RT.append(result)\n",
    "\n",
    "    NS1 = FA_RT_NLLS_Min_list[i]\n",
    "    NS2 = FA_RT_NLLS_Full_list[i]\n",
    "    result = masked_local_ssim(NS1, NS2, Ma, win_size=7)\n",
    "    SSIM7NL_FA_RT.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbbb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:59:47.193696Z",
     "start_time": "2025-12-23T09:59:46.958974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "fig, ax2 = plt.subplots(1, 1)\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "y_data = np.array(AccM7NL_MD + AccM7NL_MD_MS+AccM7NL_MD_RT)\n",
    "g_pos = np.array([3.1])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "#plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "y_data = np.array(AccM7NL_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.8)\n",
    "\n",
    "y_data = np.array(AccM7NL_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "ax2.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7NL_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "ax1.set_ylim(0, 8e-4)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(-3, -3))\n",
    "#ax1.yaxis.set_ticks(np.arange(0.0005, 0.006, 0.002))\n",
    "ax1.set_xticks([])\n",
    "\n",
    "plt.sca(ax2)\n",
    "\n",
    "y_data = np.array(AccMFulls_MD + AccMFulls_MD_MS+AccMFulls_MD_RT)\n",
    "g_pos = np.array([1])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccMFulls_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_MD + AccM20_MD_MS)\n",
    "g_pos = np.array([1.7])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_MD + AccM7_MD_MS+AccM7_MD_RT)\n",
    "g_pos = np.array([2])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM7_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(AccM7_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5,label='GH data')\n",
    "\n",
    "y_data = np.array(AccM7_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "g_pos = np.array([2.8])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "y_data = np.array(AccM20NL_MD + AccM20NL_MD_MS)\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20NL_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_MD + AccM20NL_MD_MS)\n",
    "\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "#ax2.set_ylim(0, 0.00016)\n",
    "ax2.ticklabel_format(axis='y', style='sci', scilimits=(-3, -3))\n",
    "ax2.yaxis.set_ticks(np.arange(0, 0.0005, 0.0001))\n",
    "\n",
    "# Common x-ticks\n",
    "ax2.set_xticks([1, 1.7, 2, 2.8, 3.1])\n",
    "ax2.set_xticklabels(['Full', 'Mid', 'Min', 'Mid', 'Min'], fontsize=32, rotation=90)\n",
    "\n",
    "# Adding broken axis effect\n",
    "d = .5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12, linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0], [0], transform=ax1.transAxes, **kwargs)\n",
    "\n",
    "leg = plt.legend(\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor= (-0.05,1.0),markerscale=1.5)\n",
    "\n",
    "for h in leg.legend_handles:\n",
    "    try:\n",
    "        h.set_alpha(1)\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8873958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T10:01:37.104216Z",
     "start_time": "2025-12-23T10:01:36.812013Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1)#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between Axes\n",
    "\n",
    "y_data = np.array(SSIMFulls_MD + SSIMFulls_MD_MS+SSIMFulls_MD_RT)\n",
    "g_pos = np.array([1])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.7)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.7)\n",
    "\n",
    "y_data = np.array(SSIMFulls_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_MD+SSIM20_MD_MS)\n",
    "g_pos = np.array([1.7])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False,scatter_alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5,label='HPC')\n",
    "\n",
    "y_data = np.array(SSIM20_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5,label='MS-lesions')\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5,label='MS-ctrl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7_MD+SSIM7_MD_MS+SSIM7_MD_RT)\n",
    "g_pos = np.array([2])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MD +SSIM20NL_MD_MS)\n",
    "g_pos = np.array([2.8])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MD+SSIM7NL_MD_MS+SSIM7NL_MD_RT)\n",
    "g_pos = np.array([3.1])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_MD_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7NL_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlim(ax1.get_xlim())\n",
    "#ax1.axhline(0.66, lw=3, ls='--', c='k')\n",
    "ax1.set_xticks([1, 1.7, 2, 2.8, 3.1])\n",
    "ax1.set_xticklabels(['Full', 'Mid', 'Min', 'Mid', 'Min'], fontsize=32, rotation=90)\n",
    "\n",
    "leg = ax1.legend(\n",
    "    loc='upper left',         # base location  # fine-tune the legend's position\n",
    "    frameon=False, ncols=1,\n",
    "fontsize=32,columnspacing=0.3,handlelength=0.6,handletextpad=0.3,bbox_to_anchor= (-0.0,0.6),markerscale=1.5)\n",
    "\n",
    "for h in leg.legend_handles:\n",
    "    try:\n",
    "        h.set_alpha(1)\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0a8f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:42:05.694863Z",
     "start_time": "2025-12-23T08:42:05.444890Z"
    }
   },
   "outputs": [],
   "source": [
    "y_data = np.array(PrecFull_SBI_MD+PrecFull_SBI_MD_MS)\n",
    "g_pos = np.array([1])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "fig,ax = plt.subplots()\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(0.85,1.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 77)\n",
    "plt.fill_between(x,y1,y2,color=SBIFit,zorder=10,alpha=0.2,hatch='//')\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MD+Prec20_SBI_MD_MS)\n",
    "g_pos = np.array([1.2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MD+Prec7_SBI_MD_MS)\n",
    "g_pos = np.array([1.4])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "y_data = np.array(PrecFull_NLLS_MD+PrecFull_NLLS_MD_MS)\n",
    "g_pos = np.array([2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(1.85,2.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_MD)[~np.isnan(PrecFull_NLLS_MD)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_MD)[~np.isnan(PrecFull_NLLS_MD)], 77)\n",
    "plt.fill_between(x,y1,y2,color=WLSFit,zorder=10,alpha=0.2,hatch='//')#\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MD)\n",
    "g_pos = np.array([2.2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MD+Prec7_NLLS_MD_MS)\n",
    "g_pos = np.array([2.4])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MD)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_MD_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "plt.xticks([1,1.2,1.4,2,2.2,2.4],['Full','Mid','Min','Full','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9cc3c",
   "metadata": {},
   "source": [
    "## f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb24f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:42:10.279653Z",
     "start_time": "2025-12-23T08:42:10.057315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "fig, ax2 = plt.subplots(1, 1)\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "y_data = np.array(AccM7NL_FA + AccM7NL_FA_MS+AccM7NL_FA_RT)\n",
    "g_pos = np.array([3.1])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "#plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-1,1))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "y_data = np.array(AccM7NL_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.8)\n",
    "\n",
    "y_data = np.array(AccM7NL_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "ax2.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7NL_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "ax1.set_ylim(0, 8e-4)\n",
    "ax1.ticklabel_format(axis='y', style='sci', scilimits=(-3, -3))\n",
    "#ax1.yaxis.set_ticks(np.arange(0.0005, 0.006, 0.002))\n",
    "ax1.set_xticks([])\n",
    "\n",
    "plt.sca(ax2)\n",
    "\n",
    "y_data = np.array(AccMFulls_FA + AccMFulls_FA_MS+AccMFulls_FA_RT)\n",
    "g_pos = np.array([1])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccMFulls_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccMFulls_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_FA + AccM20_FA_MS)\n",
    "g_pos = np.array([1.7])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_FA + AccM7_FA_MS+AccM7_FA_RT)\n",
    "g_pos = np.array([2])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM7_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(AccM7_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "ax2.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM7_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "g_pos = np.array([2.8])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "y_data = np.array(AccM20NL_FA + AccM20NL_FA_MS)\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(AccM20NL_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(AccM20NL_FA + AccM20NL_FA_MS)\n",
    "\n",
    "plt.xticks([1,1.7,2,2.8,3.1],['Full','Mid','Min','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "#ax2.set_ylim(0, 0.00016)\n",
    "\n",
    "# Common x-ticks\n",
    "ax2.set_xticks([1, 1.7, 2, 2.8, 3.1])\n",
    "ax2.set_xticklabels(['Full', 'Mid', 'Min', 'Mid', 'Min'], fontsize=32, rotation=90)\n",
    "\n",
    "# Adding broken axis effect\n",
    "d = .5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12, linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0], [0], transform=ax1.transAxes, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e30ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T10:02:03.661230Z",
     "start_time": "2025-12-23T10:02:03.402967Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1)#, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between Axes\n",
    "\n",
    "y_data = np.array(SSIMFulls_FA + SSIMFulls_FA_MS+SSIMFulls_FA_RT)\n",
    "g_pos = np.array([1])\n",
    "colors = ['black']\n",
    "colors2 = ['gray']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(SSIMFulls_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIMFulls_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='black',s=100,alpha=0.7)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='black',s=100,alpha=0.7)\n",
    "\n",
    "y_data = np.array(SSIMFulls_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color='gray',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_FA+SSIM20_FA_MS)\n",
    "g_pos = np.array([1.7])\n",
    "colors = ['lightseagreen']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=False,scatter_alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7_FA+SSIM7_FA_MS+SSIM7_FA_RT)\n",
    "g_pos = np.array([2])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='mediumaquamarine',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_FA +SSIM20NL_FA_MS)\n",
    "g_pos = np.array([2.8])\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM20NL_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM20NL_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_FA+SSIM7NL_FA_MS+SSIM7NL_FA_RT)\n",
    "g_pos = np.array([3.1])\n",
    "colors = ['burlywood']\n",
    "colors2 = ['peachpuff']\n",
    "\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax1,widths=0.2,scatter=True)\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax2,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(SSIM7NL_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(SSIM7NL_FA_RT)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='s',color='chocolate',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(SSIM7NL_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "ax2.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlim(ax1.get_xlim())\n",
    "#ax1.axhline(0.66, lw=3, ls='--', c='k')\n",
    "ax1.set_xticks([1, 1.7, 2, 2.8, 3.1])\n",
    "ax1.set_xticklabels(['Full', 'Mid', 'Min', 'Mid', 'Min'], fontsize=32, rotation=90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85656efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T08:42:23.482127Z",
     "start_time": "2025-12-23T08:42:23.229173Z"
    }
   },
   "outputs": [],
   "source": [
    "y_data = np.array(PrecFull_SBI_FA+PrecFull_SBI_FA_MS)\n",
    "g_pos = np.array([1])\n",
    "colors = ['mediumturquoise']\n",
    "colors2 = ['paleturquoise']\n",
    "fig,ax = plt.subplots()\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(0.85,1.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(y_data[~np.isnan(y_data)], 77)\n",
    "plt.fill_between(x,y1,y2,color=SBIFit,zorder=10,alpha=0.2,hatch='//')\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(PrecFull_SBI_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_FA+Prec20_SBI_FA_MS)\n",
    "g_pos = np.array([1.2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_SBI_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_FA+Prec7_SBI_FA_MS)\n",
    "g_pos = np.array([1.4])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_SBI_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkcyan',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkcyan',s=100,alpha=0.5)\n",
    "\n",
    "colors = ['sandybrown']\n",
    "colors2 = ['peachpuff']\n",
    "y_data = np.array(PrecFull_NLLS_FA+PrecFull_NLLS_FA_MS)\n",
    "g_pos = np.array([2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "x = np.arange(1.85,2.6,0.05)\n",
    "y1 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_FA)[~np.isnan(PrecFull_NLLS_FA)], 25)\n",
    "y2 = np.ones_like(x)*np.percentile(np.array(PrecFull_NLLS_FA)[~np.isnan(PrecFull_NLLS_FA)], 77)\n",
    "plt.fill_between(x,y1,y2,color=WLSFit,zorder=10,alpha=0.2,hatch='//')#\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(PrecFull_NLLS_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_FA)\n",
    "g_pos = np.array([2.2])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=True)\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec20_NLLS_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_FA+Prec7_NLLS_FA_MS)\n",
    "g_pos = np.array([2.4])\n",
    "BoxPlots(y_data,g_pos,colors,colors2,ax,widths=0.2,scatter=False)\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_FA)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data,y_data,marker='o',color=colors2,s=100,alpha=0.5)\n",
    "\n",
    "\n",
    "y_data = np.array(Prec7_NLLS_FA_MS)\n",
    "x_data = g_pos*np.ones_like(y_data)\n",
    "x_data += stats.t(df=6, scale=0.02).rvs(len(x_data))\n",
    "plt.scatter(x_data[:5],y_data[:5],marker='o',color='darkorange',s=100,alpha=0.5)\n",
    "plt.scatter(x_data[5:],y_data[5:],marker='^',color='darkorange',s=100,alpha=0.5)\n",
    "\n",
    "plt.xticks([1,1.2,1.4,2,2.2,2.4],['Full','Mid','Min','Full','Mid','Min'],fontsize=32,rotation=90)\n",
    "plt.gca().ticklabel_format(axis='y',style='sci',scilimits=(-0.5,3))\n",
    "plt.yticks(fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a2ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:20:25.699510Z",
     "start_time": "2025-12-27T17:20:25.685280Z"
    }
   },
   "source": [
    "# High Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2d314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:23:45.429425Z",
     "start_time": "2025-12-27T17:23:38.470248Z"
    }
   },
   "outputs": [],
   "source": [
    "fdwi = './HCP_data/Pat'+str(1)+'/diff_1k.nii.gz'\n",
    "bvalloc = './HCP_data/Pat'+str(1)+'/bvals_1k.txt'\n",
    "bvecloc = './HCP_data/Pat'+str(1)+'/bvecs_1k.txt'\n",
    "\n",
    "bvalsHCP = np.loadtxt(bvalloc)\n",
    "bvecsHCP = np.loadtxt(bvecloc)\n",
    "gtabHCP = gradient_table(bvalsHCP, bvecsHCP)\n",
    "\n",
    "data, affine, img = load_nifti(fdwi, return_img=True)\n",
    "floor = np.clip(data.min(axis=-1),-np.inf,0)\n",
    "data2 = data + abs(floor)[:,:,:,None] + 1e-5\n",
    "axial_middle = data.shape[2] // 2\n",
    "maskdata, mask = median_otsu(data2, vol_idx=range(10, 50), median_radius=3,\n",
    "                             numpass=1, autocrop=True, dilate=2)\n",
    "\n",
    "# Choose the first point (arbitrary starting point, e.g., the first gradient)\n",
    "selected_indices = [1]\n",
    "distance_matrix = squareform(pdist(bvecsHCP))\n",
    "# Iteratively select the point furthest from the current selection\n",
    "for _ in range(5):  # We need 7 points in total, and one is already selected\n",
    "    remaining_indices = list(set(range(len(bvecsHCP))) - set(selected_indices))\n",
    "    \n",
    "    # Calculate the minimum distance to the selected points for each remaining point\n",
    "    min_distances = np.min(distance_matrix[remaining_indices][:, selected_indices], axis=1)\n",
    "    \n",
    "    # Select the point with the maximum minimum distance\n",
    "    next_index = remaining_indices[np.argmax(min_distances)]\n",
    "    selected_indices.append(next_index)\n",
    "\n",
    "selected_indices = [0]+selected_indices\n",
    "\n",
    "bvalsHCP7 = bvalsHCP[selected_indices]\n",
    "bvecsHCP7 = bvecsHCP[selected_indices]\n",
    "gtabHCP7 = gradient_table(bvalsHCP7, bvecsHCP7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8115b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:24:27.542244Z",
     "start_time": "2025-12-27T17:23:47.122265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(maskdata[:, :, axial_middle, :], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "# Define the function for optimization\n",
    "def optimize_pixel(i, j):\n",
    "    torch.manual_seed(10)  # If required\n",
    "    posterior_samples_1 = Network.sample((1000,), x=DTIFeatures(gtabHCP.bvecs,gtabHCP.bvals,maskdata[i, j,axial_middle, :]),show_progress_bars=False)\n",
    "    return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "# Initialize NoiseEst with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "\n",
    "# Use joblib to parallelize the optimization tasks\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(optimize_pixel)(i, j) for i, j in tqdm(indices)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5152d84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:24:28.826348Z",
     "start_time": "2025-12-27T17:24:28.722896Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "# Assign the optimization results to NoiseEst\n",
    "for i, j, x in results:\n",
    "    NoiseEst[i, j] = x\n",
    "\n",
    "for i, j, x in results:\n",
    "    NoiseEst[i, j,-2] = np.clip(NoiseEst[i, j,-2],0,100)\n",
    "    NoiseEst[i, j,-3] = np.clip(NoiseEst[i, j,-3],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074d738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:24:36.379768Z",
     "start_time": "2025-12-27T17:24:36.038064Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "for i in range(94):\n",
    "    for j in range(104):    \n",
    "        NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1]])\n",
    "MD_SBI = np.zeros([94,104])\n",
    "FA_SBI = np.zeros([94,104])\n",
    "for i in range(94):\n",
    "    for j in range(104):\n",
    "        Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "        MD_SBI[i,j] = np.mean(Eigs)\n",
    "        FA_SBI[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "FA_SBI[np.isnan(FA_SBI)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c62ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:33.856391Z",
     "start_time": "2025-12-27T17:31:33.719016Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MD_SBI)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dff754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:34.485216Z",
     "start_time": "2025-12-27T17:31:34.422357Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(FA_SBI)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9313f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:40.594295Z",
     "start_time": "2025-12-27T17:31:34.989112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the mask where the sum is not zero\n",
    "mask = np.sum(maskdata[:, :, axial_middle, :], axis=-1) != 0\n",
    "\n",
    "# Get the indices where mask is True\n",
    "indices = np.argwhere(mask)\n",
    "\n",
    "# Define the function for optimization\n",
    "def optimize_pixel(i, j):\n",
    "    torch.manual_seed(10)  # If required\n",
    "    posterior_samples_1 = Network.sample((1000,), x=DTIFeatures(gtabHCP.bvecs[selected_indices],gtabHCP.bvals[selected_indices],maskdata[i, j,axial_middle, selected_indices]),show_progress_bars=False)\n",
    "    return i, j, posterior_samples_1.mean(axis=0)\n",
    "\n",
    "# Initialize NoiseEst with the appropriate shape\n",
    "ArrShape = mask.shape\n",
    "\n",
    "# Use joblib to parallelize the optimization tasks\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(optimize_pixel)(i, j) for i, j in tqdm(indices,position=0,leave=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19587663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:26:54.256841Z",
     "start_time": "2025-12-27T17:26:54.190423Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NoiseEst = np.zeros(list(ArrShape) + [7])\n",
    "\n",
    "# Assign the optimization results to NoiseEst\n",
    "for i, j, x in results:\n",
    "    NoiseEst[i, j] = x\n",
    "\n",
    "for i, j, x in results:\n",
    "    NoiseEst[i, j,-2] = np.clip(NoiseEst[i, j,-2],0,100)\n",
    "    NoiseEst[i, j,-3] = np.clip(NoiseEst[i, j,-3],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28e395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:27:02.041294Z",
     "start_time": "2025-12-27T17:27:01.702274Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NoiseEst2 =  np.zeros_like(NoiseEst)\n",
    "for i in range(94):\n",
    "    for j in range(104):    \n",
    "        NoiseEst2[i,j] = np.hstack([mat_to_vals(clip_negative_eigenvalues(vals_to_mat(NoiseEst[i,j]))),NoiseEst[i,j,-1]])\n",
    "MD_SBI7 = np.zeros([94,104])\n",
    "FA_SBI7 = np.zeros([94,104])\n",
    "for i in range(94):\n",
    "    for j in range(104):\n",
    "        Eigs = np.linalg.eigh(vals_to_mat(NoiseEst2[i,j,:6]))[0]\n",
    "        MD_SBI7[i,j] = np.mean(Eigs)\n",
    "        FA_SBI7[i,j] = FracAni(Eigs,np.mean(Eigs))\n",
    "FA_SBI7[np.isnan(FA_SBI7)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0d977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:42.282850Z",
     "start_time": "2025-12-27T17:31:42.223442Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MD_SBI7)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=0.005)\n",
    "plt.axis('off')\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa29af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:43.665619Z",
     "start_time": "2025-12-27T17:31:43.608551Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = gaussian_filter(np.copy(FA_SBI7),sigma=0.5)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "#cbar = plt.colorbar()\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60e26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:28:42.016819Z",
     "start_time": "2025-12-27T17:28:41.344685Z"
    }
   },
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtabHCP,return_S0_hat = True,fit_method='NLLS')\n",
    "tenfit = tenmodel.fit(maskdata[:,:,axial_middle])\n",
    "FAFull = dti.fractional_anisotropy(tenfit.evals)\n",
    "MDFull = dti.mean_diffusivity(tenfit.evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72968a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:28:42.557254Z",
     "start_time": "2025-12-27T17:28:42.017854Z"
    }
   },
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtabHCP7,return_S0_hat = True,fit_method='NLLS')\n",
    "tenfit = tenmodel.fit(maskdata[:,:,axial_middle,selected_indices])\n",
    "FA7 = dti.fractional_anisotropy(tenfit.evals)\n",
    "MD7 = dti.mean_diffusivity(tenfit.evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf93d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:45.567191Z",
     "start_time": "2025-12-27T17:31:45.481966Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MDFull)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd0c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:46.139648Z",
     "start_time": "2025-12-27T17:31:46.053724Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(FAFull)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58ba95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:46.622010Z",
     "start_time": "2025-12-27T17:31:46.529128Z"
    }
   },
   "outputs": [],
   "source": [
    "data = MD_SBI.T-MDFull.T\n",
    "data[~mask.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=np.nanmin(data), vcenter=0, vmax=np.nanmax(data))\n",
    "plt.imshow(data,cmap='seismic',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "ticks = [np.nanmin(data), 0, np.nanmax(data)]  # Adjust the number of ticks as needed\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f373e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:46.899992Z",
     "start_time": "2025-12-27T17:31:46.804424Z"
    }
   },
   "outputs": [],
   "source": [
    "data = FA_SBI.T-FAFull.T\n",
    "data[~mask.T] = np.nan\n",
    "norm = TwoSlopeNorm(vmin=np.nanmin(data), vcenter=0, vmax=1)\n",
    "plt.imshow(data,cmap='seismic',norm=norm)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "ticks = [np.nanmin(data), 0, 1]  # Adjust the number of ticks as needed\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37871adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:47.140668Z",
     "start_time": "2025-12-27T17:31:47.050552Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(MD7)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot',vmin=0,vmax=0.005)\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950f9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:47.410198Z",
     "start_time": "2025-12-27T17:31:47.290062Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.abs(MDFull.T-MD7.T)\n",
    "norm = TwoSlopeNorm(vmin=0,vcenter=0.00075, vmax=0.0015)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "\n",
    "ticks = [0, 0.001]\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data = np.abs(MD_SBI.T-MD_SBI7.T)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd26de0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:47.720317Z",
     "start_time": "2025-12-27T17:31:47.629309Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.copy(FA7)\n",
    "temp[~mask] = math.nan\n",
    "img = plt.imshow(temp.T,cmap='hot')\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "vmin, vmax = img.get_clim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e34f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T17:31:48.154988Z",
     "start_time": "2025-12-27T17:31:48.032858Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.abs(FAFull.T-FA7.T)\n",
    "norm = TwoSlopeNorm(vmin=0,vcenter=0.5, vmax=1)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "\n",
    "ticks = [0, 1]\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data = np.abs(FA_SBI.T-FA_SBI7.T)\n",
    "data[~mask.T] = np.nan\n",
    "plt.imshow(data,cmap='Reds',norm=norm)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1062.67px",
    "left": "35px",
    "top": "65.79px",
    "width": "495.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
